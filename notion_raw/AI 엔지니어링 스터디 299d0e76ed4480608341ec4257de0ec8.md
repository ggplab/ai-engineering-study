# AI 엔지니어링 스터디

## 1. 개요

- 책 제목: AI 엔지니어링
- 목적: 책 1회독
- 방법: 매주 일요일 오후 10시, 밤에 모여서 간단하게 해당 단원 디스커션
- 규칙
    - 출제를 돌아가면서 할 예정!
    - 저를 강사 x → 팀원으로 인정좀 ㅠ_ㅠ 정님 굿
- 인원: 8명 **임정**, **~~김동근~~**, **홍현경**, **이승형**, **최유희**, **김효진**, **김도현, ~~박주원~~**
- 방식
    - 출제자: 문제를 Claude, Gemini, GPT 를 이용하여 질문과 답변을 미리 생성해놓습니다.,
    - 참여자: 오후 10시에부터 문제를 풀기 시작하며, 완료되면 답변과 비교해서 부족한점 등을 파악합니다. 또한, 타 참여자의 답을 보고 보충할 것이 있으면 코멘트를 달아줍니다.
- Ebook(영문): https://drive.google.com/file/d/1KpQL150HjQSUIUrz2I9qwr7Lboa3RtQN/view?usp=sharing
- **Chapter별 구분**
    
    [AI Engineering Chapter 5.pdf](AI%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81%20%EC%8A%A4%ED%84%B0%EB%94%94/AI_Engineering_Chapter_5.pdf)
    
    [AI Engineering Chapter 6.pdf](AI%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81%20%EC%8A%A4%ED%84%B0%EB%94%94/AI_Engineering_Chapter_6.pdf)
    
    [AI Engineering Chapter 7.pdf](AI%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81%20%EC%8A%A4%ED%84%B0%EB%94%94/AI_Engineering_Chapter_7.pdf)
    
    [AI Engineering Chapter 8.pdf](AI%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81%20%EC%8A%A4%ED%84%B0%EB%94%94/AI_Engineering_Chapter_8.pdf)
    
    [AI Engineering Chapter 9.pdf](AI%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81%20%EC%8A%A4%ED%84%B0%EB%94%94/AI_Engineering_Chapter_9.pdf)
    
    [AI Engineering Chapter 10.pdf](AI%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81%20%EC%8A%A4%ED%84%B0%EB%94%94/AI_Engineering_Chapter_10.pdf)
    

| **단원** | **날짜(매주 일요일)** | 페이지(ebook기준) | 출제자 |
| --- | --- | --- | --- |
| 1단원 | 11/9 | ~72페이지 | 임정 |
| 2단원 | 11/16 | ~112페이지 | 임정 |
| !! | 11/23 | 휴식 |  |
| 3단원 | 11/30 | ~157페이지 | 김효진 |
| 4단원 | 12/7 | ~209 | 홍현경 |
| 5단원 | 12/14 | ~252 | 김도현 |
| 6단원 | 12/21 | ~305 | 이승형 |
| 7단원 | 12/28 | ~362 | 최유희 |
| 8단원 | 1/4 | ~404 | @현경 홍  |
| 9단원 | 1/11 | ~448 | @비빔 유 최유희 |
| 10단원 | 1/18 | ~493 | @Do Hyeon Kim 김도현 |

![image.png](AI%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81%20%EC%8A%A4%ED%84%B0%EB%94%94/image.png)

## 2. 자기소개

- 템플릿(3문항, 5분 이내)
    - 간단한 자기소개
    - 스터디 참여하게 된 이유
    - 스터디 종료 후 되고 싶은 나의 상태
- 임정 (완료 ✅)
    - 간단한 자기소개: 3년차 데이터분석 + 3년 데이터강의 진행한 Data Scientist. 스터디와 책을 매우 좋아하며 학습 하는 것을 좋아합니다 :)
    - 스터디 참여하게 된 이유: 본 책의 저자가 <머신러닝 시스템 설계>를 작성한 유명한 저자인데, 이 편이 속편이며,  성윤님이 번역을 맡았다고해서 읽게됨. Data Product를 넘어 AI Product을 잘 기획하고 고려해야하는 사항에 대해서 설계의 능력을 갖추고 싶어서 지원
    - 스터디 종료 후 되고 싶은 나의 상태: AI Product에 대한 기획서를 쓰고 어떤 요구상황과 문제에 맞추어 방법을 제시할 수 있는 사람
- 김동근 (완료 ✅)
    - 간단한 자기소개 : 주니어 → 시니어 넘어가기 직전에 AI를 접하고 정체성 혼란이 오는 BackEnd Developer. 평소 동기들과 카공을 즐기며, 강의보단 책을 선호합니다.
    - 스터디 참여하게 된 이유 : 시대에 따라가려면 시대에 맞춰진 책을 읽어야 따라갈 수 있다고 생각합니다. (개인적인 의견 ;) ) 앞으로의 커리어를 생각해보았을 때 백엔드 하나로는 부족하기에 반드시 데이터 프로덕트를 접해야할것이고, 그를 위해서 미리 데이터 프로덕트 설계의 이해에 대해서 반드시 짚고 넘어가고 싶어서 지원.
    - 스터디 종료 후 되고 싶은 나의 상태 : 추후 프로덕트에 참여하고 나면 반드시 다시 공부해야 할 때가 올텐데 그때마다 일일이 찾아보지 않고, 스터디에서 배운 구조와 설계 원리를 기반으로 빠르게 이해하고 적용할 수 있는 상태가 되고 싶습니다.
- 김도현 (완료 ✅)
    - 간단한 자기소개 : 이어드림스쿨에 참여하면서 통계학 스터디, LLM 스터디, RAG 스터디를 통해 관련 공부를 했습니다.
    - 스터디 참여하게 된 이유 : 지금까지 LLM/RAG 관련 세부 내용을 공부했지만 프로젝트 수행을 위해 좀 더 넓은 시각과 관점에서 공부해야 할 필요성을 느꼈습니다. AI Engineering 책은 실습 코드 위주의 핸즈온이기보다 전체 프로덕션 관점에서 세부 설명이 잘 정리되어 있어 읽어보려고 합니다.
    - 스터디 종료 후 되고 싶은 나의 상태 : 최종 프로젝트를 LLM/RAG 관련 프로젝트로 진행하려고 하는데 이 책을 통해 필요한 도움을 얻었으면 합니다.
- 이승형 (완료 ✅)
    - 간단한 자기소개: rag를 사용한 서비스 개발에 관심을 가지고 공부중입니다.
    - 스터디 참여하게 된 이유: ai에 대한 기초지식을 얻고자. 그냥 가져다 사용하기보다 원리를 알고 사용하고 싶습니다. 그리고 스터디 경험도 없어서 경험하고 싶습니다.
    - 스터디 종료 후 되고 싶은 나의 상태: ai에 대한 기초지식. 상황에 맞는 솔루션을 고를 수 있는 능력.
- 홍현경 (완료 ✅)
    - 간단한 자기소개: 비전공자로 개발자쪽은 이어드림에서 처음 접했고, 어렵지만 흥미가 생겨 계속 이쪽으로 하고 싶습니다.
    - 스터디 참여하게 된 이유: 수업을 듣고 있지만, 강의만으로는 머릿속에 잘 남지 않는다는 생각을 가지고 있었는데 책으로 공부하면 좀 더 이해가 되고 오래 기억할 수 있을 것 같아 스터디에 참여하게 되었습니다.
    - 스터디 종료 후 되고 싶은 나의 상태: 책의 내용을 스스로 이해하고, 실제로 적용할 수 있는 수준으로 성장하고 싶습니다.
- 최유희 (완료 ✅)
    - 간단한 자기소개: 의약/바이오 품질보증 근무를 하다가 이어드림에 참가하게 되었고 데이터 분야에 관심이 생겨 데이터 분석가, 나아가서 데이터 사이언티스트를 희망하고 있습니다
    - 스터디 참여하게 된 이유: 강사님의 수업방식이 굉장히 좋다고 생각하는데, 강사님께서 이 책을 추천해주셨고 스터디도 진행한다고 하셔서 참여하게 되었습니다.
    - 스터디 종료 후 되고 싶은 나의 상태: 전체적인 그림이 제 머리 속에 들어왔으면 좋겠습니다. 그리고 그 전체적인 그림을 기반으로 간
    - 단한 ai product를 만들어볼 수 있게 된다면 좋겠습니다.
- 김효진 (완료 ✅)
    - 간단한 자기소개 : 마케팅 분야에서 활동하였고 데이터 분석에 관심이 생겨 AI실무 기초 역량을 쌓고 있습니다.
    - 스터디 참여하게 된 이유 : 이제는 AI와 데이터 기반의 인사이트를 마케팅 전략 및 프로젝트 실무에 직접 적용하는 전문가로 전환하고 싶습니다. 스터디를 통해 AI 엔지니어링 지식을 체계적으로 다지고, 실무 적용을 위한 Python, SQL 기반 데이터 분석 및 머신러닝·딥러닝 모델링 능력을 향상시켜 현재 진행 중인 스타트업 협업 마지막 프로젝트의 완성도를 높이고 싶어 참여하게 되었습니다.
    - 스터디 종료 후 되고 싶은 나의 상태 : AI 엔지니어링 책에서 배운 지식을 단순히 이해하는 것을 넘어, 데이터 분석 및 AI 모델링 역량을 마케팅 및 비즈니스 문제 해결에 접목할 수 있는 실무 능력을 갖춘 사람이 되고 싶습니다. 궁극적으로는 AI·데이터를 기반으로 현장에서 실제적인 성과 창출을 목표로 프로젝트 리딩 경험을 살려 K-AI(K-data) 를 널리널리 알리고 싶습니다. (미래의 꿈)
- 박주원 (완료 ✅)
    - 간단한 자기소개 : 데이터 사이언스, AI 개발자 지망생입니다. 문제를 데이터로 해결하는 데 관심이 많고, OCR+LLM+RAG 기반 문서 이해 서비스를 직접 설계·구현하며 포트폴리오를 쌓고 있습니다. 강의보다 책·문서 중심의 구조화된 학습을 선호합니다.
    - 스터디 참여하게 된 이유 : 아이디어를 “제품 설계–데이터 파이프라인–배포–평가”까지 끌고 가는 End-to-End 관점을 체득하고 싶어서입니다. 특히 LLM/RAG 시스템에서 프롬프트보다 데이터 모델링, 인덱싱, 관측성(로그·실험), 오프라인/온라인 평가가 핵심이라 생각해, 책을 통해 원리와 설계 패턴을 체계적으로 정리하려고 참여했습니다.
    - 스터디 종료 후 되고 싶은 나의 상태 : 문제정의서·데이터 스키마·아키텍처 다이어그램·실험 계획을 신속히 도출하고, 2주 내 MVP를 재현 가능하게 배포할 수 있는 사람. 팀과 같은 언어로 설계 리뷰를 주고받으며, 테스트·문서화까지 갖춘 “작동하는 데이터 프로덕트”를 일관된 원칙으로 만들 수 있는 상태가 되고 싶습니다.

## 3. AI Engineering 스터디 1-Pager

<aside>
💡

본 문서는 우리 스터디의 방향성을 정의하며, 모두가 함께 읽고 확인합니다.

---

### 1. 스터디 최종 목표

스터디 종료 시, 우리는 다음과 같은 상태가 되는 것을 목표로 함.

1. **[원리 체화 🧠]** 책에서 다루는 AI Engineering의 **핵심 원리**를 자신의 언어로 남에게 설명할 수 있는 상태.
    - (ex. "데이터 중심(Data-Centric) 접근법이 왜 중요한지", "좋은 피처(Feature)란 무엇인지" 등)
2. **[솔루션 탐색 🔍]** 특정 문제 상황에서, 책을 기반으로 **'최적의 솔루션'** 또는 **'표준적인 설계 패턴'**을 제시하고 그 이유를 토론할 수 있는 상태.
3. **[시야 확장 🗺️]** AI 프로덕트의 전체 그림(Big Picture)을 그리고, 각 컴포넌트(데이터, 모델링, 평가, 배포)의 역할과 연결고리를 이해하는 상태.

---

### 2. 스터디 대원칙

- 책의 내용을 소화하여 AI 엔지니어링의 핵심 원리(Principles)를 체화하는 것을 최우선 목표로 함.
- 우리는 **"이 기술/원리가 왜(Why) 필요한가?"** 그리고 "저자가 말하는 최적의 솔루션(Best Practice)은 무엇인가?"를 탐구하고 토론함.

---

### 3. 참여자 구성 및 공통 목표 (Our Members & Goal)

- **A. 공통 목표 (Common Ground)**
    - AI 프로덕트의 전체 생명주기를 이해하고, 각 단계에서 '가장 중요한 원칙'**과 '표준적인 해결책'이 무엇인지 파악함.
    - 공통의 관심사인 **LLM/RAG**는, 책의 원칙을 이해하기 위한 주요 예시(Case Study)로 적극 활용함.
- **B. '개념/원리' 학습 그룹 (Principle Seekers)**
    - 대상: 김동근, 이승형, **홍현경, 최유희**, 김효진 등
    - **특징:** 다수의 AI 초심자. AI/데이터 분야의 기초와 전체적인 그림(Big Picture)을 그리고자 함.
    - **주요 니즈:** AI Engineering의 **기초 지식, 핵심 용어, 그리고 작동 원리**의 명확한 이해.
- **C. '관점/적용' 학습 그룹 (Perspective Builders)**
    - 대상: **임정, 김도현**, 박주원
    - **특징:** 특정 도메인(LLM/RAG, 백엔드, 데이터 분석) 경험이 있으며, 이를 AI 프로덕션의 **넓은 관점**과 연결하고자 함.
    - **주요 니즈:** E2E 시스템의 구조적 이해, **'최적의 솔루션'** 탐색, 기존 지식과 새 지식의 연결.
</aside>

## 4. 스터디 본문

- 문제 출제 방식
    
     **Notebook lm** 혹은 LLM을 이용하여 위 ebook의 해당 단원을 잘라 업로드하여 다음 프롬프트로 문제를 생성! 
    
    - 프롬프트 전문
    
    <aside>
    📌
    
    당신은 AI 엔지니어링 분야의 전문 교수로, 스터디 그룹 학생들이 핵심 개념을 깊이 있게 이해하고 토론할 수 있도록 돕는 역할을 맡았습니다.
    
    1. **출력 형식:** 반드시 아래 형식을 정확히 지켜주세요.
        - '### 💡 스터디 질문' 섹션 아래에 질문 16개를 먼저 모두 나열합니다. 문제마다 makrdown toggle을 이용하여 구분합니다.
        - '### 📚 예시 답안' 섹션 아래에 각 질문에 대한 상세한 모범 답안을 본문 내용에 근거하여 작성합니다. 전체 예시답안은 heading toggle 2로 설정하여 담습니다.
        - 부연설명없이 문제와 답만 제시합니다.
    2. **난이도:** 너무 지엽적이거나 복잡하지 않게, 본문에 제시된 **핵심 개념과 원리**를 이해했는지 확인하는 데 초점을 맞춰주세요.
    3. **질문 유형:** 단순한 용어 정의(O/X, 단답형)가 아닌, "A와 B를 비교 설명하세요", "C의 중요성에 대해 2가지 측면에서 설명하세요", "D가 작동하는 방식을 단계별로 설명하세요"와 같이, 응답자가 자신의 말로 풀어써야 하는 서술형 문제여야 합니다.
    
    [요청 규칙]
    
    첨부된 [pdf 73페이지 부터 112페이지 까지] pdf를 참고하여 아래에 제공되는 자료를 바탕으로, 스터디원들이 반드시 알아야 할 **핵심 서술형 질문 16개**와 그에 대한 **모범 답안**을 작성해 주세요.
    
    </aside>
    
- 1단원
    
    ### 최유희
    
    - 자기회귀(Autoregressive) 언어 모델과 마스킹(Masked) 언어 모델의 훈련 방식과 주요 용도를 비교 설명하세요.
        
        <aside>
        💡
        
        자기 회귀는 직접 라벨링하지 않고 모델이 스스로 추론해서 라벨링 하는 것?ㅎㅎ.. 
        
        </aside>
        
        - 죄송합니다
            - 마스크 언어 모델: 누락된 토큰 전후 컨텍스트를 사용해 시퀀스의 어느 위치에 누락된 토큰을 예측하도록 학습, 기본적을 빈칸을 채울 수 있도록 학습됨 (감정분석, 텍스트 분류처럼 새로운 텍스트를 만들지 않는 작업에 주로 사용, 코드 디버기처럼 모델이 앞뒤 코드를 모두 이해해서 오류를 찾아야 하는 전체적인 컨텍스트 이해가 필요한 작업에도 유용)
            - 자기회귀 모델: 이전 토큰들만 보고 시퀀스의 다음 토큰을 예측하도록 학습됨(텍스트 생성 분야에 주로 사용)
    - 전통적인 지도 학습(Supervision) 방식의 한계는 무엇이었으며, 언어 모델이 '자기 지도 학습(Self-supervision)'을 통해 이 한계를 극복하고 LLM으로 확장될 수 있었던 핵심 원리를 설명하세요.
        
        <aside>
        💡
        
        어텐션 알고리즘?.. 
        
        </aside>
        
        - 분명히 읽었는데.. 죄송합니다 22
            
            레이블이 있는 데이터를 사용해 알고리즘을 학습하는 과정은 비용도 많이 들고 시간도 오래 걸림. 자기 지도 학습은 언어 모델이 레이블링 없이도 텍스트 시퀀스를 통해 학습할 수 있음. 그래서 방대한 양의 학습 데이터를 구축할 수 있기 때문에 이를 통해 언어모델을 LLM으로 확장할 수 있다 . 
            
    - LLM(대형 언어 모델)이 파운데이션 모델(Foundation Model)로 개념이 확장된 이유를 '데이터 모달리티'와 '모델의 목적성'이라는 2가지 측면에서 설명하세요.
        
        <aside>
        💡
        
        모르겠음 
        
        </aside>
        
    
    ### 김도현
    
    - AI 엔지니어링이 최근 몇 년간 폭발적으로 성장하게 된 3가지 핵심 요인을 설명하세요.
        
        <aside>
        💡
        
        Chat-GPT 출시 이후 다양한 파운데이션 모델의 등장 → 파운데이션 모델을 활용한 다양한 애플리케이션 개발
        
        </aside>
        
        <aside>
        ✅
        
        1. 범용 AI 능력
        
        : 거대 언어 모델은 기존 작업을 더 잘 수행하는 성능이 향상되었을 뿐만 아니라 **더 다양한 태스크를 수행**할 수 있다. 이전에는 불가능하다고 생각되던 작업도 파운데이션 모델을 활용하여 수행할 수 있게 되었다. 이에 따라 파운데이션 모델의 유용성과 범용성이 부각되면서 사용자의 수가 증가하고, AI 애플리케이션에 대한 수요도 증가하게 되었다.
        
        1. AI 투자 증가
        
        : Chat-GPT 등장 이후 기업의 AI에 대한 투자가 증가하였다. 많은 기업들이 AI를 자사 제품과 프로세스에 적용하고, 실적 발표에 AI를 언급하고 있다. 이에 따라 AI 애플리케이션 개발이 성장하고 있다.
        
        1. AI 애플리케이션 개발에 대한 낮아진 진입 장벽
        
        : 파운데이션 벤더 업체에서 **API를 제공**하기 때문에 AI 애플리케이션 개발에 AI 모델을 쉽게 사용할 수 있게 되었다. 여기에 더해 AI를 통해 애플리케이션 개발에 도움을 받을 수 있게 되면서 AI 애플리케이션 개발을 이전보다 더 쉽게 할 수 있게 되었다.
        
        </aside>
        
    - 전통적인 ML 엔지니어링과 대비되는 'AI 엔지니어링'의 핵심 정의는 무엇이며, 왜 'Ops'가 아닌 '엔지니어링'이라는 용어를 사용하는 것이 적절한지 설명하세요.
        
        <aside>
        💡
        
        - 전통적인 ML 엔지니어링 - 모델 자체를 개발
        - AI 엔지니어링 - 이미 존재하는 모델을 활용
        - AI 엔지니어링에는 전통적인 ML 엔지니어링에서 사용한 개념만으로는 설명할 수 없는 요인(프롬프트 엔지니어링, 컨텍스틀 구성, 평가방식, 추론 최적화, 데이터셋 엔지니어링, etc)들이 있기 때문에 AI 엔지니어링이라는 용어를 선택함.
        - 이는 또한 현업자 20명에 대한 설문조사를 바탕으로 한 것이기도 하다.
        </aside>
        
    - 기업 환경에서 AI 애플리케이션을 도입할 때, '내부 지향(Internal-facing)' 애플리케이션이 '외부 지향(External-facing)' 애플리케이션보다 더 빠르고 적극적으로 배포되는 경향이 있습니다. 그 이유를 위험성(risk) 측면에서 설명하세요.
        
        <aside>
        💡
        
        - 외부 지향 애플리케이션은 고객에게 제공하는 서비스이기 때문에 비용, 성능, 컴플라이언스 측면에서 고려해야할 사항이 더 까다롭다.
        - 반면에 사내에서 사용하는 애플리케이션 개발의 경우 이러한 고려사항으로부터 비교적 자유롭다.
        - 사내 AI 개발 역량을 준비하는 관점에서 위험이 비교적 적은 내부 지향 애플리케이션을 먼저 개발하는 회사도 있다.
        </aside>
        
    
    ### 홍현경
    
    - AI 애플리케이션을 기획할 때 AI가 수행하는 역할을 'Proactive(능동적)' 방식과 'Reactive(수동적)' 방식으로 구분하여 설명하고, 각각의 방식이 품질 기준(quality bar)과 지연 시간(latency) 요구사항에 어떻게 다른 영향을 미치는지 설명하세요.
        
        <aside>
        💡
        
        구글 노트북으로 찾아봐써요.. 
        
        - 핵심은 **'**사용자의 요청에 즉시 반응하느냐' 아니면 ‘요청 없이 미리 나서서 행동하느냐'의 차이
            - Reactive (수동적) 방식: AI가 사용자의 명확한 요청이나 질문에 대해 응답할 때를 말합니다. AI는 사용자의 입력에 반응하여 결과를 생성
            예시: 챗봇
            - Proactive(능동적) 방식:사용자 요청을 기다리지 않고 사용자에게 정보, 예측 또는 조언을 선제적으로 제공
            예시: Google 지도에서 제공하는 교통 정보 알림
            - 지연 시간 (Latency) 요구사항에 미치는 영향
                
                 Reactive: 신속하게 발생 필요
                
                 Proactive:미리 계산(precomputed)가능. 덜중요
                
            - 품질 기준 (Quality Bar) ****요구사항에 미치는 영향
                
                Reactive: 사용자가 직접 요청한거라 응답이 틀려도 사용자가 상황을 이해하고 요청을 수정할 여지가 있음
                Proactive: 사용자가 요청하지도 않았는데 AI가 나타나서 잘못된 정보나 예측을 제공하면, 사용자는 그 기능을 '성가시거나 방해된다고 여길 수 있어 높아야됨
                
        </aside>
        
    - AI 시스템에 인간의 개입(Human-in-the-Loop)을 점진적으로 줄여나가는 'Crawl-Walk-Run' 3단계 전략에 대해 설명하세요.
        
        <aside>
        💡
        
        1. Crawl (인턴): 인간 개입이 필수적.AI는 제안을 생성하는 보조 역할,  인간이 최종결정
        2. Walk (정직원):AI가 내부 직원과 직접 상호작용. AI는 내부 워크플로우에서 직접 작업을 수행
        3. Run(자율운영시스템) :자동화 수준이 최고로 증가. 
        
        외부 사용자와 직접 상호작용, 인간의 개입 없이 광범위한 작업을 자율적으로 처리
        
        </aside>
        
    - 파운데이션 모델 시대에 AI 스타트업이 확보할 수 있는 3가지 경쟁 우위(moat)는 무엇이며, 이 중 스타트업에게 가장 중요한 '데이터 우위(data advantage)'는 어떻게 확보될 수 있는지 설명하세요.
        
        <aside>
        💡
        
        춘추전국시대라서 다 모름.. 그래서 스타트업이 결정을 빨리할 수 있어서 그냥 시도해보고 버릴건 버리고 취할건 취하는 선택을 빨리함으로써 우위를 차지?
        
        </aside>
        
    
    ### 임정
    
    - AI 제품 개발 시 '0-60은 쉽지만 60-100은 매우 어렵다'는 '마지막 1마일(Last Mile) 문제'가 발생하는 이유를, '데모'와 '제품'의 차이점을 중심으로 설명하세요.
        
        <aside>
        💡
        
        본문책 1.3.2  기대치 설정
        
        - AI 모델의 파라미터는 이미 충분히 커서 General 한 문제를 대부분 풀수 있음. 하지만 다운스트림 태스크(국소적인 문제)로 갈수록 성능 향샹에 어려움을 겪을 수 있음
        - 단순히 오픈소스모델을 가져다 쓰거나 api 이용하여 모델을 개발할때의 데모는 개발 시간 대비 효과가 극대화되지만 제품모드로 들어가면 할루시네이션과 같은 고질적인 문제를 개선하는데 시간을 많이 쓰게됨
        </aside>
        
        <aside>
        ✅
        
        **10. AI 제품 개발 시 '0-60은 쉽지만 60-100은 매우 어렵다'는 '마지막 1마일(Last Mile) 문제'가 발생하는 이유를, '데모'와 '제품'의 차이점을 중심으로 설명하세요.**
        
        파운데이션 모델은 기본 성능이 뛰어나기 때문에, 주말 동안에도 멋진 '데모'를 만드는 것은 매우 쉽습니다.
        
        하지만 이 데모를 수익성 있는 '제품'으로 만드는 것은 완전히 다른 차원의 문제입니다. '마지막 1마일 문제'는 바로 이 지점에서 발생합니다.
        
        - **데모 (0-60):** 초기 데모는 80%의 경험을 빠르게 달성할 수 있습니다. 이는 개발자가 성공을 과신하게 만들 수 있습니다.
        - **제품 (60-100):** 나머지 20%를 채우는 데는 훨씬 더 많은 시간이 걸립니다. LinkedIn의 사례에서 80% 달성에 1개월이 걸렸지만, 95%를 넘기기까지 추가로 4개월이 더 걸렸습니다. 이 구간에서는 AI의 **환각(hallucinations) 현상을 처리**하고, 다양한 엣지 케이스(product kinks)를 해결하며, 신뢰성을 1%씩 어렵게 올려야 하기 때문입니다.
        </aside>
        
    - AI 엔지니어링(AIE)이 전통적인 ML 엔지니어링(MLE)과 구별되는 3가지 주요 차이점을 (1) 모델 개발 방식, (2) 모델 규모 및 자원, (3) 평가의 복잡성 측면에서 설명하세요.
        
        <aside>
        💡
        
        (1) 모델 개발 방식: MLE은 모델을 파인튜닝(하이퍼파라미터 튜닝)하는데 시간을 투자하는 반면, AI 모델은 자체적으로 모델을 만들거나, 파인튜닝, 프롬프트엔지니어링 3가지 개요에 대해서 나눠서 기여한다.
        (2) 모델 규모 및 자원: 모델 자체의 규모가 매우 커져서 이를 수행하는 고성능 연산장치(GPU)가 필요하고 모델을 탑재하는 GPU 자체의 RAM 크기가 커야한다.
        
        (3) 평가의 복잡성: MLE 측면에서는  회귀라면 MSE,MAPE,MAE를 분류라면 f1-score, AUC-ROC를 정량적인 측정으로도 충분하지만 AI 모델은 나오는 결과물이 이미지,자연어 등에 대해서 다양하고, 정성적인 평가가 필요한 부분이기 때문에 평가가 MLE과 달리 더 복잡해진다.
        
        </aside>
        
        <aside>
        ✅
        
        **11. AI 엔지니어링(AIE)이 전통적인 ML 엔지니어링(MLE)과 구별되는 3가지 주요 차이점을 (1) 모델 개발 방식, (2) 모델 규모 및 자원, (3) 평가의 복잡성 측면에서 설명하세요.**
        
        AIE와 MLE는 다음과 같은 3가지 핵심 영역에서 큰 차이를 보입니다.
        
        1. **모델 개발 방식 (Adapt vs. Train):**
            - **MLE:** 애플리케이션을 위해 **모델을 처음부터 훈련**해야 했습니다.
            - **AIE:** 다른 누군가(예: OpenAI)가 훈련한 **기존 모델을 활용(적응)**합니다. AIE는 모델링 및 훈련보다 '모델 적응(adaptation)'에 중점을 둡니다.
        2. **모델 규모 및 자원 (Scale & Compute):**
            - **AIE:** 훨씬 더 크고, 더 많은 계산 리소스를 소비하며, 더 높은 지연 시간을 유발하는 모델을 다룹니다.
            - **결과:** 이로 인해 AIE에서는 효율적인 훈련 및 **추론 최적화(inference optimization)**가 훨씬 더 중요해졌으며, GPU 및 대규모 클러스터 작업 능력이 중요해졌습니다.
        3. **평가의 복잡성 (Open-ended Evaluation):**
            - **MLE:** 전통적인 ML 작업은 대부분 '닫힌(close-ended)' 출력을 가집니다. (예: '스팸' 또는 '아님'). 정답이 명확하여 평가가 비교적 쉽습니다.
            - **AIE:** 파운데이션 모델은 '열린(open-ended)' 출력을 생성합니다. (예: 에세이 작성). 하나의 프롬프트에도 수많은 정답이 가능하므로, 정답 목록(ground truth)을 만드는 것이 불가능하며 **평가가 훨씬 더 어렵습니다**.
        </aside>
        
    - AI 엔지니어링에서 모델을 특정 작업에 적응시키는 두 가지 주요 접근 방식, 즉 (1) 프롬프트 기반 기법과 (2) 파인튜닝 기법의 작동 방식과 장단점을 비교 설명하세요.
        
        <aside>
        💡
        
        (1) 프롬프트 기반
        
        (장점): 쉽고 누구나 적용할 수 있다.
        
        (단점): 도메인이 뚜렷한(의학, 세무, 법학)등에 대한 다운스트림 태스크에 최적화가 불가능한 정도이다.
        
        (2) 파인튜닝
        
        (장점): 프롬프트 기반의 단점을 그대로 극복한다. 파운데이션 모델을 확보하여 일반적인 성능을 끌어내고, 다운스트림 태스크에 대하여 전문화, 시킬 수 있다.
        
        (단점): 프롬프트기반과 달리 파라미터의 업데이트가 필요하기 때문에 컴퓨터 리소스가 든다. 파인튜닝을 하기 위한 데이터셋의 구비가 필수적이며 이는 비용의 증가로 이어진다.
        
        </aside>
        
        <aside>
        ✅
        
        **12. AI 엔지니어링에서 모델을 특정 작업에 적응시키는 두 가지 주요 접근 방식, 즉 (1) 프롬프트 기반 기법과 (2) 파인튜닝 기법의 작동 방식과 장단점을 비교 설명하세요.**
        
        모델 적응 기법은 모델 가중치(weights)를 업데이트하는지 여부에 따라 나뉩니다.
        
        - **프롬프트 기반 기법 (Prompt-based Techniques):**
            - **작동 방식:** 모델 가중치를 변경하지 않습니다. 대신, 모델에 입력되는 프롬프트(지침 및 컨텍스트)를 정교하게 설계하여 원하는 행동을 유도합니다.
            - **장점:** 시작하기 쉽고 적은 데이터로도 가능하며, 다양한 모델을 빠르게 실험해 볼 수 있습니다.
            - **단점:** 복잡한 작업이나 엄격한 성능 요구사항을 맞추기에는 한계가 있을 수 있습니다.
        - **파인튜닝 (Finetuning):**
            - **작동 방식:** 모델 가중치를 **업데이트**합니다.  특정 작업에 대한 고품질 데이터셋을 사용하여 모델 자체를 변경(추가 학습)합니다.
            - **장점:** 모델의 품질, 지연 시간, 비용을 크게 개선할 수 있습니다. 모델이 훈련 중에 접하지 못한 새로운 작업을 학습시킬 수 있습니다.
            - **단점:** 더 복잡하고 더 많은 데이터가 필요합니다.
        </aside>
        
    
    ## 김효진
    
    - 'Pre-training'과 'Finetuning'은 모두 모델 가중치를 변경하는 작업입니다. 이 두 용어의 개념적 차이와 리소스 요구량의 차이를 설명하세요.
        
        <aside>
        💡
        
        둘 다 가중치를 바꾼다.
        
        Pre-training은….대규모 비지도(또는 자기지도) 학습 단계로, 모델이 언어·패턴·지식의 기본 구조를 스스로 익히는 과정이다. 인터넷 전체 같은 방대한 데이터를 사용하며, 수조 개의 파라미터를 가진 모델을 수주~수개월 동안 수천 대의 GPU로 학습시킨다
        
        막대한 데이터·시간·GPU 필요 → 대형 연구소/기업 중심
        
        Finetuning은 이미 학습된 모델을 특정 목적()에 맞게 다시 세밀하게 조정하는 단계, 실습때 해본적 있습니다!
        
        상대적으로 적은 자원으로 가능 → 기업·개인도 수행 가능
        
        </aside>
        
    - AI 엔지니어링 워크플로우가 전통적인 ML 엔지니어링보다 풀스택(Full-Stack) 엔지니어링에 더 가까워지는 이유는 무엇이며, 이로 인해 개발 프로세스 순서(예: 제품, 데이터, 모델)가 어떻게 변화했는지 설명하세요.
        
        <aside>
        💡
        
        ㅠㅠ……….모범답안으로 대체하겠습니다. 읽었는데 이해가 잘 안가네요ㅠㅠㅠㅠ
        
        ---
        
        </aside>
        
        <aside>
        ✅
        
        - **풀스택에 가까워지는 이유:** AIE는 '모델 개발' 자체보다 '애플리케이션 개발'과 **'인터페이스'**를 강조합니다. 이는 Python 중심의 전통적인 MLE와 달리, JavaScript API(예: LangChain.js, Vercel AI SDK)에 대한 지원이 증가하는 현상에서도 나타납니다. 이로 인해 웹 개발 또는 풀스택 배경을 가진 엔지니어들이 AIE 분야로 더 많이 유입되고 있습니다.
        </aside>
        
        - **개발 프로세스의 변화:** 가장 큰 변화는 강력한 모델이 '이미 준비되어 있다'는 것입니다.
            - **전통적인 MLE:** [데이터 수집] → [모델 훈련] → [제품 개발] 순서였습니다.
            - **AI 엔지니어링:** [제품(데모) 우선 개발] → [사용자 데이터 확보] → [모델 조정/개선] 순서로 바뀌었습니다.
        
        이 새로운 워크플로우는 아이디어를 빠르게 데모로 만들고, 피드백을 받아 반복(iterate)할 수 있는 풀스택 엔지니어에게 유리합니다
        
        ---
        
    
    ## 이승형
    
    - AIE가 MLE보다 '평가(Evaluation)'를 훨씬 더 어렵고 중요하게 만드는 근본적인 이유는 무엇이며, 이것이 모델 성능 비교(예: Gemini vs. GPT-4 사례)에 어떤 영향을 미치는지 설명하세요.
        
        
    - AI 엔지니어링 스택의 3가지 레이어(애플리케이션 개발, 모델 개발, 인프라)를 설명하고, ChatGPT 등장 이후 어떤 레이어에서 가장 큰 성장이 나타났는지 이유와 함께 설명하세요.
        
        
    
    ## 모범답안
    
    **1. 자기회귀(Autoregressive) 언어 모델과 마스킹(Masked) 언어 모델의 훈련 방식과 주요 용도를 비교 설명하세요.**
    
    두 모델은 토큰을 예측하는 방식에서 근본적인 차이가 있습니다.
    
    - **자기회귀 언어 모델 (Autoregressive LM):**
        - **훈련 방식:** 이전 토큰들(context)만을 바탕으로 **다음 토큰**을 예측하도록 훈련됩니다.  예를 들어, "My favorite color is"가 주어지면 "blue"를 예측합니다.
        - **주요 용도:** 한 번에 하나씩 순차적으로 토큰을 생성할 수 있어, 챗봇이나 기사 작성과 같은 **텍스트 생성(Text Generation)** 작업에 주로 사용됩니다.
    - **마스킹 언어 모델 (Masked LM):**
        - **훈련 방식:** 문장 중간의 일부 토큰을 무작위로 가리고(masking), **앞뒤 주변 토큰들**을 모두 활용하여 가려진 **누락 토큰**을 예측하도록 훈련됩니다.  (예: "My favorite [MASK] is blue" -> "color" 예측)
        - **주요 용도:** 문맥을 양방향으로 이해해야 하는 비생성(non-generative) 작업, 예컨대 **감성 분석, 텍스트 분류, 코드 디버깅** 등에 유용합니다.
    
    **2. 전통적인 지도 학습(Supervision) 방식의 한계는 무엇이었으며, 언어 모델이 '자기 지도 학습(Self-supervision)'을 통해 이 한계를 극복하고 LLM으로 확장될 수 있었던 핵심 원리를 설명하세요.**
    
    - **지도 학습의 한계:** 지도 학습은 '레이블이 지정된 데이터'를 필요로 합니다. 예를 들어, 사기 탐지 모델을 만들려면 수많은 거래 내역에 '사기', '정상'이라는 레이블을 인간이 직접 달아야 합니다. 이 레이블링 작업은 **비용이 매우 비싸고 시간도 오래 걸리는 데이터 병목 현상**을 유발했습니다.
    - **자기 지도 학습의 원리:** 자기 지도 학습은 이 병목 현상을 해결했습니다. 언어 모델링의 경우, **입력 데이터(텍스트) 자체에서 레이블을 추론**할 수 있습니다. 예를 들어, "I love street food"라는 문장만 있으면, <BOS>, I, love"를 입력(context)으로, "street"을 출력(label)으로 하는 학습 샘플을 자동으로 생성할 수 있습니다.
    - **LLM으로의 확장:** 이 방식 덕분에 책, 블로그, 웹사이트 등 레이블이 없는 방대한 텍스트 데이터를 학습에 모두 활용할 수 있게 되었습니다.  이는 모델이 수십억 개의 파라미터를 가진 LLM으로 확장(scale up)될 수 있게 만든 결정적인 계기가 되었습니다.
    
    **3. LLM(대형 언어 모델)이 파운데이션 모델(Foundation Model)로 개념이 확장된 이유를 '데이터 모달리티'와 '모델의 목적성'이라는 2가지 측면에서 설명하세요.**
    
    - **데이터 모달리티 (Data Modality):** LLM은 기본적으로 텍스트(Text) 데이터에 국한됩니다. 반면, 파운데이션 모델은 텍스트를 넘어 **이미지, 비디오, 오디오 등 여러 데이터 양식(Multimodal)을 함께 이해**합니다. 예를 들어 GPT-4V는 텍스트와 이미지를 동시에 입력받아 처리할 수 있습니다.
    - **모델의 목적성 (Generality):** 과거의 ML 모델과 LLM은 종종 특정 작업(예: 번역 전용, 감성 분석 전용)을 위해 개발되었습니다. 하지만 파운데이션 모델은 매우 큰 규모와 방대한 데이터 학습을 통해 **범용성(General-purpose)**을 갖추게 되었습니다. 이 모델들은 특정 작업에 국한되지 않고 다양한 작업을 즉시 수행할 수 있으며 , RAG나 파인튜닝 등을 통해 특정 애플리케이션에 맞게 조정(adapt)될 수 있습니다.
    
    **4. AI 엔지니어링이 최근 몇 년간 폭발적으로 성장하게 된 3가지 핵심 요인을 설명하세요.**
    
    AI 엔지니어링은 다음 세 가지 요인이 복합적으로 작용하여 급성장했습니다.
    
    1. **범용 AI 역량의 등장:** 파운데이션 모델은 기존 작업(예: 번역)을 더 잘할 뿐만 아니라, 이전에는 불가능했던 새로운 작업(예: 고품질 이미지 생성, 복잡한 추론)까지 가능하게 했습니다. 이로 인해 AI의 수요와 사용자 기반이 폭발적으로 증가했습니다.
    2. **AI 투자 급증:** ChatGPT의 성공은 AI에 대한 막대한 투자를 유도했습니다. AI 애플리케이션 개발 비용이 저렴해지고 시장 출시가 빨라지면서 ROI(투자 수익)가 매력적으로 변했고, 기업들은 경쟁적으로 AI를 도입하기 시작했습니다.
    3. **낮은 진입 장벽:** 'MaaS(Model as a Service)' 형태의 API(예: OpenAI API)가 보편화되면서, 개발자들이 인프라 구축 없이도 강력한 모델에 즉시 접근할 수 있게 되었습니다. 또한 프로그래밍 언어가 아닌 **평범한 영어(자연어)**로 모델을 제어(프롬프트 엔지니어링)할 수 있게 되어, AI 비전공자나 코딩 경험이 없는 사람도 AI 앱을 개발할 수 있게 되었습니다.
    
    **5. 전통적인 ML 엔지니어링과 대비되는 'AI 엔지니어링'의 핵심 정의는 무엇이며, 왜 'Ops'가 아닌 '엔지니어링'이라는 용어를 사용하는 것이 적절한지 설명하세요.**
    
    - **AI 엔지니어링의 정의:** AI 엔지니어링은 **미리 준비된(readily available) 파운데이션 모델을 기반으로(on top of) 애플리케이션을 구축하는 프로세스**를 의미합니다. 이는 모델을 '처음부터 개발'하는 전통적인 ML 엔지니어링과는 구별됩니다. AI 엔지니어링은 이미 존재하는 강력한 모델을 '활용'하고 '조정(adapt)'하는 데 중점을 둡니다.
    - **'엔지니어링' 용어의 적절성:** 'Ops'(MLOps, LLMOps 등)는 주로 모델의 운영 및 배포 측면을 강조합니다. 하지만 파운데이션 모델 기반 작업의 핵심은 모델을 원하는 대로 작동하도록 **'조정(tweaking)'**하는 것입니다. 즉, 프롬프트 엔지니어링, RAG(검색 증강 생성), 파인튜닝 등을 통해 모델의 동작을 설계하고 개선하는 **'엔지니어링'** 활동이 중심이 됩니다.
    
    **6. 기업 환경에서 AI 애플리케이션을 도입할 때, '내부 지향(Internal-facing)' 애플리케이션이 '외부 지향(External-facing)' 애플리케이션보다 더 빠르고 적극적으로 배포되는 경향이 있습니다. 그 이유를 위험성(risk) 측면에서 설명하세요.**
    
    기업들은 AI 도입 시 위험성이 낮은 애플리케이션을 선호하는 경향이 있으며, 이것이 내부 지향 앱이 선호되는 주된 이유입니다.
    
    - **위험 최소화:** 내부 지향 애플리케이션(예: 내부 문서 요약, 직원용 지식 관리 봇)은 직원들만 사용합니다.  만약 AI가 잘못된 답변(환각)을 생성하거나 실수를 하더라도, 그 영향이 기업 내부로 한정되며 통제하기 쉽습니다.
    - **높은 외부 위험:** 반면, 외부 지향 애플리케이션(예: 고객 응대 챗봇, 외부 공개용 추천 알고리즘)은 고객에게 직접 노출됩니다. 여기서 발생하는 오류는 **데이터 프라이버시 침해, 규정 준수(compliance) 문제, 또는 치명적인 브랜드 이미지 손상**과 같은 심각한 위험을 초래할 수 있습니다.
    
    따라서 기업들은 위험을 최소화하면서 AI 엔지니어링 전문성을 쌓기 위해, 통제 가능한 내부 애플리케이션을 먼저 배포하고 안정화하는 전략을 선택합니다.
    
    **7. AI 애플리케이션을 기획할 때 AI가 수행하는 역할을 'Proactive(능동적)' 방식과 'Reactive(수동적)' 방식으로 구분하여 설명하고, 각각의 방식이 품질 기준(quality bar)과 지연 시간(latency) 요구사항에 어떻게 다른 영향을 미치는지 설명하세요.**
    
    - **Reactive (수동적) 방식:**
        - **설명:** 사용자의 명시적인 요청이나 특정 행동에 **반응**하여 AI가 응답을 생성하는 방식입니다.  (예: 사용자가 챗봇에게 질문을 입력할 때)
        - **특징:** 사용자가 요청 후 기다리고 있으므로, **지연 시간(latency)이 매우 중요**합니다. 사용자가 AI의 핵심 기능에 의존하는 경우가 많아 정확도도 중요하지만, 때로는 실수가 허용되기도 합니다.
    - **Proactive (능동적) 방식:**
        - **설명:** 사용자가 요청하지 않았음에도 AI가 유용하다고 판단하는 기회에 **먼저** 응답(알림, 제안 등)을 보여주는 방식입니다.  (예: 구글맵의 선제적인 교통 상황 알림)
        - **특징:** 미리 응답을 계산해 둘 수 있으므로 **지연 시간은 상대적으로 덜 중요**합니다.  하지만 사용자가 요청하지 않은 정보이므로, **품질 기준(quality bar)이 매우 높아야** 합니다. 품질이 낮으면 사용자는 이를 방해나 스팸으로 간주할 수 있습니다.
    
    **8. AI 시스템에 인간의 개입(Human-in-the-Loop)을 점진적으로 줄여나가는 'Crawl-Walk-Run' 3단계 전략에 대해 설명하세요.**
    
    'Crawl-Walk-Run'은 AI 자동화 수준을 점진적으로 높여나가는 Microsoft의 프레임워크입니다.
    
    1. **Crawl (기어가기):** AI 시스템의 초기 단계로, **인간의 개입이 필수적**입니다. 예를 들어, AI가 고객 응대 답변 초안을 생성하면, 인간 상담원이 이를 검토하고 수정한 뒤 고객에게 발송합니다.
    2. **Walk (걷기):** AI의 성능이 검증되면, **내부 직원과의 상호작용을 허용**합니다. AI가 단순 요청에 대해서는 내부 직원에게 직접 응답하고, 복잡한 문제만 인간에게 라우팅합니다.
    3. **Run (달리기):** AI의 신뢰도가 충분히 높아지면, **외부 사용자와의 직접적인 상호작용**을 포함한 완전 자동화 단계로 나아갑니다. 이 단계에서는 AI가 인간의 개입 없이 대부분의 요청을 처리합니다.
    
    이 전략은 AI의 품질이 향상됨에 따라 점진적으로 자동화 수준을 높여 위험을 관리하는 방식입니다.
    
    **9. 파운데이션 모델 시대에 AI 스타트업이 확보할 수 있는 3가지 경쟁 우위(moat)는 무엇이며, 이 중 스타트업에게 가장 중요한 '데이터 우위(data advantage)'는 어떻게 확보될 수 있는지 설명하세요.**
    
    AI 분야의 3가지 일반적인 경쟁 우위는 **기술(Technology), 데이터(Data), 그리고 ~~유통~~(Distribution)**입니다.
    
    파운데이션 모델 시대에는 대부분의 회사가 유사한 핵심 기술(예: OpenAI API)을 사용하고, 유통망은 대기업(예: Google, Microsoft)이 장악하고 있습니다. 따라서 **데이터 우위**가 스타트업에게 가장 중요한 차별화 요소가 됩니다.
    
    스타트업은 다음과 같은 '데이터 플라이휠(Data Flywheel)'을 통해 이 우위를 확보할 수 있습니다.
    
    1. 시장에 빠르게 제품을 출시합니다.
    2. 사용자가 제품을 사용하는 과정에서 **고유한 사용 데이터(usage data)**를 수집합니다.
    3. 이 데이터를 분석하여 사용자의 행동 패턴과 제품의 문제점을 파악합니다.
    4. 이 인사이트를 바탕으로 데이터 수집 및 훈련 프로세스를 개선하여 **제품을 지속적으로 향상**시킵니다.
    5. 개선된 제품은 더 많은 사용자를 유치하고, 이는 다시 더 많은 고유 데이터를 생성하는 선순환을 만듭니다.
    
    파운데이션 모델은 기본 성능이 뛰어나기 때문에, 주말 동안에도 멋진 '데모'를 만드는 것은 매우 쉽습니다.
    
    하지만 이 데모를 수익성 있는 '제품'으로 만드는 것은 완전히 다른 차원의 문제입니다. '마지막 1마일 문제'는 바로 이 지점에서 발생합니다.
    
    - **데모 (0-60):** 초기 데모는 80%의 경험을 빠르게 달성할 수 있습니다. 이는 개발자가 성공을 과신하게 만들 수 있습니다.
    - **제품 (60-100):** 나머지 20%를 채우는 데는 훨씬 더 많은 시간이 걸립니다. LinkedIn의 사례에서 80% 달성에 1개월이 걸렸지만, 95%를 넘기기까지 추가로 4개월이 더 걸렸습니다. 이 구간에서는 AI의 **환각(hallucinations) 현상을 처리**하고, 다양한 엣지 케이스(product kinks)를 해결하며, 신뢰성을 1%씩 어렵게 올려야 하기 때문입니다.
    
    **11. AI 엔지니어링(AIE)이 전통적인 ML 엔지니어링(MLE)과 구별되는 3가지 주요 차이점을 (1) 모델 개발 방식, (2) 모델 규모 및 자원, (3) 평가의 복잡성 측면에서 설명하세요.**
    
    AIE와 MLE는 다음과 같은 3가지 핵심 영역에서 큰 차이를 보입니다.
    
    1. **모델 개발 방식 (Adapt vs. Train):**
        - **MLE:** 애플리케이션을 위해 **모델을 처음부터 훈련**해야 했습니다.
        - **AIE:** 다른 누군가(예: OpenAI)가 훈련한 **기존 모델을 활용(적응)**합니다. AIE는 모델링 및 훈련보다 '모델 적응(adaptation)'에 중점을 둡니다.
    2. **모델 규모 및 자원 (Scale & Compute):**
        - **AIE:** 훨씬 더 크고, 더 많은 계산 리소스를 소비하며, 더 높은 지연 시간을 유발하는 모델을 다룹니다.
        - **결과:** 이로 인해 AIE에서는 효율적인 훈련 및 **추론 최적화(inference optimization)**가 훨씬 더 중요해졌으며, GPU 및 대규모 클러스터 작업 능력이 중요해졌습니다.
    3. **평가의 복잡성 (Open-ended Evaluation):**
        - **MLE:** 전통적인 ML 작업은 대부분 '닫힌(close-ended)' 출력을 가집니다. (예: '스팸' 또는 '아님'). 정답이 명확하여 평가가 비교적 쉽습니다.
        - **AIE:** 파운데이션 모델은 '열린(open-ended)' 출력을 생성합니다. (예: 에세이 작성). 하나의 프롬프트에도 수많은 정답이 가능하므로, 정답 목록(ground truth)을 만드는 것이 불가능하며 **평가가 훨씬 더 어렵습니다**.
    
    **12. AI 엔지니어링에서 모델을 특정 작업에 적응시키는 두 가지 주요 접근 방식, 즉 (1) 프롬프트 기반 기법과 (2) 파인튜닝 기법의 작동 방식과 장단점을 비교 설명하세요.**
    
    모델 적응 기법은 모델 가중치(weights)를 업데이트하는지 여부에 따라 나뉩니다.
    
    - **프롬프트 기반 기법 (Prompt-based Techniques):**
        - **작동 방식:** 모델 가중치를 변경하지 않습니다. 대신, 모델에 입력되는 프롬프트(지침 및 컨텍스트)를 정교하게 설계하여 원하는 행동을 유도합니다.
        - **장점:** 시작하기 쉽고 적은 데이터로도 가능하며, 다양한 모델을 빠르게 실험해 볼 수 있습니다.
        - **단점:** 복잡한 작업이나 엄격한 성능 요구사항을 맞추기에는 한계가 있을 수 있습니다.
    - **파인튜닝 (Finetuning):**
        - **작동 방식:** 모델 가중치를 **업데이트**합니다.  특정 작업에 대한 고품질 데이터셋을 사용하여 모델 자체를 변경(추가 학습)합니다.
        - **장점:** 모델의 품질, 지연 시간, 비용을 크게 개선할 수 있습니다. 모델이 훈련 중에 접하지 못한 새로운 작업을 학습시킬 수 있습니다.
        - **단점:** 더 복잡하고 더 많은 데이터가 필요합니다.
    
    **13. 'Pre-training'과 'Finetuning'은 모두 모델 가중치를 변경하는 작업입니다. 이 두 용어의 개념적 차이와 리소스 요구량의 차이를 설명하세요.**
    
    두 용어 모두 모델 가중치를 변경하는 '훈련(Training)'의 단계이지만, 시작점과 목적, 리소스 소모량에서 큰 차이가 있습니다.
    
    - **Pre-training (사전 훈련):**
        - **개념:** 모델 가중치가 무작위로 초기화된 상태, 즉 **처음부터(from scratch)** 모델을 훈련하는 것을 의미합니다. LLM의 경우, 방대한 텍스트로 '다음 단어 맞추기' 같은 범용적인 작업을 학습합니다.
        - **리소스:** 전체 훈련 단계 중 **가장 많은 리소스(데이터 및 컴퓨팅)**를 소모합니다. InstructGPT의 경우 전체 자원의 98%가 사전 훈련에 사용되었습니다.
    - **Finetuning (미세 조정):**
        - **개념:** **이전에 훈련된 모델**의 가중치를 가져와서 특정 작업에 맞게 계속 훈련하는 것을 의미합니다.  (예: 사전 훈련된 GPT를 의료 데이터로 파인튜닝)
        - **리소스:** 모델이 이미 사전 훈련을 통해 일정 수준의 지식을 갖고 있으므로, 일반적으로 사전 훈련보다 **훨씬 적은 데이터와 컴퓨팅 리소스**를 필요로 합니다.
    
    **14. AI 엔지니어링 워크플로우가 전통적인 ML 엔지니어링보다 풀스택(Full-Stack) 엔지니어링에 더 가까워지는 이유는 무엇이며, 이로 인해 개발 프로세스 순서(예: 제품, 데이터, 모델)가 어떻게 변화했는지 설명하세요.**
    
    - **풀스택에 가까워지는 이유:** AIE는 '모델 개발' 자체보다 '애플리케이션 개발'과 **'인터페이스'**를 강조합니다. 이는 Python 중심의 전통적인 MLE와 달리, JavaScript API(예: LangChain.js, Vercel AI SDK)에 대한 지원이 증가하는 현상에서도 나타납니다. 이로 인해 웹 개발 또는 풀스택 배경을 가진 엔지니어들이 AIE 분야로 더 많이 유입되고 있습니다.
    - **개발 프로세스의 변화:** 가장 큰 변화는 강력한 모델이 '이미 준비되어 있다'는 것입니다.
        - **전통적인 MLE:** [데이터 수집] → [모델 훈련] → [제품 개발] 순서였습니다.
        - **AI 엔지니어링:** [제품(데모) 우선 개발] → [사용자 데이터 확보] → [모델 조정/개선] 순서로 바뀌었습니다.
    
    이 새로운 워크플로우는 아이디어를 빠르게 데모로 만들고, 피드백을 받아 반복(iterate)할 수 있는 풀스택 엔지니어에게 유리합니다.
    
    **15. AIE가 MLE보다 '평가(Evaluation)'를 훨씬 더 어렵고 중요하게 만드는 근본적인 이유는 무엇이며, 이것이 모델 성능 비교(예: Gemini vs. GPT-4 사례)에 어떤 영향을 미치는지 설명하세요.**
    
    - **평가가 어려운 이유:** 근본적인 이유는 파운데이션 모델의 **'열린(open-ended)' 특성** 때문입니다.
        - 전통적인 MLE 작업(예: 사기 탐지)은 '참/거짓'처럼 정답(ground truth)이 명확합니다.
        - 하지만 AIE 작업(예: 챗봇 응답)은 하나의 질문에 대해 수많은 좋은 답변이 존재할 수 있으므로, 정답 목록을 만드는 것이 불가능합니다.
    - **성능 비교에 미치는 영향 (Gemini 사례):** 평가가 어렵기 때문에 '어떻게 평가했는가'가 모델의 성능 수치를 좌우합니다. 2023년 구글은 Gemini가 MMLU 벤치마크에서 GPT-4보다 낫다고 발표했습니다.
        - 하지만 이는 Gemini에게는 32개의 예시(CoT@32)를 주고, GPT-4에게는 5개의 예시만 주는 등 **서로 다른 프롬프트 엔지니어링 기법**을 사용한 결과였습니다.
        - 동일하게 5-shot으로 비교했을 때는 GPT-4의 성능이 더 높았습니다. 이는 프롬프트 기법(평가 방법)의 작은 차이가 모델 성능 수치를 크게 왜곡할 수 있음을 보여줍니다.
    
    **16. AI 엔지니어링 스택의 3가지 레이어(애플리케이션 개발, 모델 개발, 인프라)를 설명하고, ChatGPT 등장 이후 어떤 레이어에서 가장 큰 성장이 나타났는지 이유와 함께 설명하세요.**
    
    AI 스택은 3개의 계층으로 구성됩니다.
    
    1. **애플리케이션 개발 (Application Development):** 최상위 레이어로, AI 인터페이스, 프롬프트 엔지니어링, 컨텍스트 구성(RAG 등), 평가를 다룹니다.
    2. **모델 개발 (Model Development):** 중간 레이어로, 모델링, 훈련, 파인튜닝, 추론 최적화, 데이터셋 엔지니어링 등을 다룹니다.
    3. **인프라 (Infrastructure):** 가장 낮은 레이어로, 모델 서빙, 컴퓨팅 및 데이터 관리, 모니터링 등을 포함합니다.
    
    **가장 큰 성장이 나타난 레이어:** GitHub 리포지토리 분석에 따르면, 2023년(Stable Diffusion 및 ChatGPT 등장 이후)에 **'애플리케이션(Applications)'**과 **'애플리케이션 개발(AI Engineering)'** 레이어에서 가장 폭발적인 증가가 나타났습니다.
    
    **이유:** 강력한 파운데이션 모델이 API 등을 통해 '미리 준비된' 상태가 되면서, 개발자들이 인프라나 모델 개발에 대한 부담 없이 **즉시 애플리케이션을 만들 수 있게 되었기 때문**입니다. 반면, 서빙이나 모니터링 같은 핵심 인프라 요구사항은 기존과 크게 달라지지 않아 성장이 상대적으로 더뎠습니다.
    
- 2단원
    
    ### 💡 스터디 질문
    
    - 1 모델 규모(Model Size)를 나타내는 세 가지 핵심 지표(파라미터 수, 학습 토큰 수, FLOPs)와 각각이 모델의 어떤 측면을 대변하는지 설명하세요.
        
        <aside>
        💡
        
        1. 파라미터 수는 진행중인 모델을 학습하고 실행하는데 필요한 컴퓨터 자원(용량)을 추정할 수 있음.
        
        파라미터 수가 0인 값이 높다는 의미는 0은 곱해도 0이기 때문에 모델이 그부분을 계산하지 않아도 되서 사용하지 않는 파라미터가 많지 않게됨. 모델이 전체 구조 대비 실제로 활용되는 부분이 적은 ‘희소한 모델’이라고 함. 전체 연산량이 줄어들어 모델이 커도 그보다 더 적은 자원으로 모델을 돌려볼 수 있음.
        
        대표 모델로는 MoE가 있음(이 모델은 수업때 들은 기억은 있는데 진행한 프로젝트에서는 실행해보지 않아서 한 번 해봐야 체감할 수 있을 것 같음)
        
        2. 학습 토큰 수는 모델이 실제로 학습한  토큰의 총량(실제로 읽고 학습한 양)을 의미함.
        
        토큰=단어를 쪼갠 최소 단위(LLM에서 최소 단위)
        
        토큰을 많이 읽을수록 계산해야할 양도 같이 늘어나고..컴퓨팅 자원이 많이 드니까.. 앞으로 자주 실습해보려면 돈 마니 벌어서 GPU 사야될 것 같아요😭
        
        3. FLOPs (Floating Point Operations, 부동소수점 연산 횟수)는 얼마나 많은 연산을 했는지 나타내는 전체 계산량을 의미함.
        
        모델을 만들기 위해 얼마나 큰 계산(연산)량을 돌렸는지를 보여주는 지표
        
        * 참고사항: FLOP/s랑 FLOPs로 표기되는 사례가 있는데
        
        - FLOPs : 부동소수점 연산 횟수
        
        - FLOP/s (/s=per second): 초당 몇개의 FLOPs(부동소수점 연산 횟수)을 처리하는지 나타내는 성능 단위
        
        </aside>
        
    - 2 모델 개발 예산이 고정되어 있을 때, 컴퓨팅 최적 모델(Compute-Optimal Model)을 구축하기 위한 스케일링 법칙(Scaling Law)의 핵심 원칙을 설명하세요.
        
        <aside>
        💡
        
        고정된 예산 내에서 최고 성능을 내기 위해서 모델의 파라미터를 키우는 것과 학습 토큰 수를 늘리는 것을 균형 있게 병행하는 것
        
        * 참고사항
        
        1) 친칠라 스케일링 법칙(Chinchilla Scaling Law) : 
        
        - 2022년 DeepMind 발표, **파라미터 수 대비 약 20배**의 학습 토큰이 최적
        
              즉, 모델 크기를 2배로 늘리면 훈련 데이터양도 **2배로 늘려야** 가장 효율적(1:1 스케일링 비율)
        
        - 2023년 이후, 훈련 목적, 모델 구조, 사용 환경(추론 비용)에 따라 최적 비율이 달라질 수 있다고 규칙 해석 확장
        
               훈련만 고려 시 1:20 비율이 훈련 예산 대비 효율적
        
               추론까지 고려 시: 훈련은 한 번만 하는데 추론(실제 사용)은 수십억 번 반복되기 때문에 훈련 예산을 조금 더 사용하더라도 모델 크기를 더 작게 만들고, 대신 더 많은 데이터로 더 오래 학습시키는 것이 총비용 면에서 가장 효율적인 전략이라는 결론 제시
        
        </aside>
        
    - 3 사전 훈련된 모델(Pre-trained Model)이 일반적으로 가지는 두 가지 주요 문제점을 설명하고, 사후 훈련(Post-Training)이 이 문제들을 어떻게 해결하는지 설명하세요.
        
        <aside>
        💡
        
        **사전 학습 모델 문제점:** 
        
        1) 자기 지도 학습은 대화가 아닌 단어(토큰) 완성을 잘하도록 학습
        
        - 질문에 답하지 않고 문장을 그냥 이어 쓰는 문제가 나타남
        - 사용자 의도와 상관없이 반말·존댓말 등 어투가 제멋대로 생성됨
        - ‘요약해줘·정리해줘’ 같은 지시를 수행하지 못하고 원문을 그대로 늘어놓음
        - 대화 맥락을 이해하지 못해 앞뒤 흐름이 끊기는 응답이 나옴
        
        2) 인터넷에서 수집한 데이터로 학습하여 잘못된 정보 반영
        
        - 인종·성별 고정관념이 무의식적으로 드러나는 편향 문제
        - 존재하지 않는 정보나 사실을 만들어내는 할루시네이션 발생
        - 웹 데이터 특성상 공격적 표현이나 부적절한 내용이 섞일 위험
        
        **사후 학습 모델 해결방안:**
        
        1) 지도 파인튜닝(Supervised Fine-Tuning, SFT): 자기지도학습의 한계를 해결하는 단계
        
        - 사람이 직접 만든 “좋은 답변 예시”로 모델을 다시 학습시킨 후, 질문에 정확한 대답/ 지시 수행/ 대화 흐름 유지하는 능력 강화
        - 즉, “텍스트 이어쓰기 모델”을  “대화 가능한 모델”로 바꿔주는 과정
        
        2) 선호도 파인튜닝(Preference Fine-Tuning, RLHF/DPO 등): 편향·유해성·잘못된 정보 문제를 해결하는 단계
        
        - 사람이 평가한 ‘더 좋은/바람직한 응답’을 기준으로 모델 행동을 조정
        - 위험하거나 편향된 답변은 점수를 낮게 줘서 억제, 안전하고 사실 기반, 사람 친화적인 응답을 선택하도록 학습
        - 즉, 모델을 “안전하고 책임감 있게” 만들기 위한 단계
        </aside>
        
    - 4 지도 미세 조정(Supervised Finetuning, SFT)이 필요한 이유와, SFT를 위한 고품질 데모 데이터(Demonstration Data)를 구축할 때 고려해야 할 두 가지 주요 사항을 설명하세요.
        
        사전 학습된 모델의 문제점을 보완하기 위해 필요함. 특히, 단어 완성에 최적화 되어 있는 모델을 고품질 지시 데이터로 학습시켜 적절한 응답을 생성하도록 유도하기 위해 필요하다. 
        
        고품질 데모 데이터를 구축할 때 고려해야 할 두 가지 주요 사항 
        
        1. 질의 응답, 요약, 번역과 같이 모델이 처리하기 원하는 모든 요청 범위를 포함해야한다. (업무 예시를 써줄것)
        2. 비판적 사고, 정보 수집, 사용자의 요청의 적절성에 대한 판단이 필요한 복잡한 프롬프트가 포함될 수 있다.(단순 답변을 넘어서 사람처럼 생각하거 답할 수 있게)
    - 5 선호도 미세 조정(Preference Finetuning)의 초기 성공적인 알고리즘인 RLHF(Reinforcement Learning from Human Feedback)의 두 가지 주요 구성 요소와 목표를 설명하세요.
        
        선호도 파인튜닝의 목표: AI 모델이 사람의 선호도에 따라 행동하도록 만드는 것 
        
        RLHF의 구성 요소
        
        1. 파운 데이션 모델의 출력에 점수를 매기는 보상 모델을 학습한다.
        2. 보상 모델이 최대 점수를 줄 응답을 생성하도록 파운데이션 모델을 최적화한다. 
    - 6 언어 모델에서 '탐욕적 샘플링(Greedy Sampling)' 방식이 분류(Classification) 작업에는 효과적일 수 있으나, 텍스트 생성 작업에는 적합하지 않은 이유를 비교하여 설명하세요.
        
        Greedy sampling: 항상 가능성이 높은 결과를 선택하는 샘플링 방법 
        1. 언어 모델의 경우, 어떤 질문을 하든 가장 확률이 높은 단어를 고르게 된다면 답변이 매번 비슷하게 될것.
        
        2. 분류 모델의 경우, 하나의 정답을 골라내는 것이기 때문에 가능성이 높은 결과를 선택하는 것이 효과적이다.
        
    - 7 언어 모델에서 사용하는 토큰 샘플링 전략 중, Top-K 샘플링과 Top-P 샘플링이 작동하는 방식과 각각의 이점을 비교 설명하세요.
        
        Top-K 샘플링 :확률이 가장 높은 **상위** *K***개의 토큰**만 선택하여 샘플링.선택되는 토큰의 개수(*K*)가 **고정**됨.계산 워크로드 감소
        
        - **K 값**이 작으면 → 모델이 덜 창의적이고 예측 가능한 말을 많이 함
        - K 값이 크면 → 선택지가 많아져서 다양하고 창의적인 말이 나올 수 있음
        
        Top-P 샘플링 :확률을 누적하여 합(P)이 임계값 *P*를 초과하는 최소한의 토큰 집합을 동적으로 선택하여 샘플링.선택되는 토큰의 개수가 문맥에 따라 동적으로 변함.출력의 문맥적 적절성 향상.
        
        Top-P 샘플링은 실제로 잘 작동하는 것으로 입증되어 인기가 높아지고 있는 전략입니다. 이러한 샘플링 전략들은 모델의 출력을 제어하고 예측 가능성(낮은 온도, Top-K/P)과 창의성(높은 온도, Top-K/P) 사이의 균형을 맞추는 데 사용
        
    - 8 AI 모델이 본질적으로 '확률적(Probabilistic)'이라는 특성이 창의적인 작업과 일반적인 작업에 미치는 긍정적 및 부정적 영향을 각각 설명하세요.
        
        확률적(Probabilistic)이라는 특성은 모델이 응답을 생성하는 방식의 핵심이며, 이는 AI 응용 프로그램의 성능과 신뢰성에 광범위한 영향을 미침.
        
        창의적인 작업: 창의성 및 다양성 증대.무궁무진한 아이디어를 구상하고 이전에 본 적 없는 디자인을 생성/ 출력이 너무 무작위적이거나 일관성이 떨어질 수 있음
        
        일반적인 작업:무한한 출력 생성 능력.이는 번역, 요약, 코딩과 같은 작업들을 완성/일관성부족. 약간 다른 입력에 대해 극적으로 다른 대답 생성. 할루시네이션(사실이 아닌 내용을 지어냄)
        
        확률적 특성은 창의적인 응용 분야에서는 강력한 이점으로 작용하여 모델의 독창성과 다양성을 높이지만, 사실성 및 신뢰성이 요구되는 일반적인 응용 분야에서는 환각 및 일관성 부족이라는 주요 문제를 야기.
        
    - 9 AI 모델의 확률적 특성으로 인해 발생하는 두 가지 주요 문제(비일관성 및 환각)를 정의하고, 이들이 사용자 경험에 미치는 부정적인 영향을 설명하세요.
        - 비일관성
            - 같은 입력 또는 비슷한 입력에 대해 파운데이션 모델이 다른 출력을 내는 것
            - 이는 일관된 답변을 필요로 하는 사용자들에게 불편함을 줄 수 있다. 예를 들어, LLM을 활용하여 학생의 답을 평가하려고 하는데, 같은 입력 또는 비슷한 입력에 대해 LLM의 평가가 상이하면 일관된 평가를 하는데 문제가 발생한다.
        - 환각
            - LLM이 사실과 다른 답변을 마치 사실인 것처럼 답변하는 현상
            - 창의성이 중요하지 않고 정확한 사실이 중요한 작업의 경우 환각 문제는 사용자에게 치명적인 문제를 안겨줄 수 있다. 예를 들어 법률 관련 작업물에 환각이 발생하고 이를 그대로 사용하면 경우에 따라 법적인 처벌을 받거나 재판에 불리해질 수 있다.
    - 10 환각(Hallucination)이 발생하는 근본적인 원인 두 가지를 설명하고, 환각을 완화하기 위해 제시된 딥마인드(DeepMind)의 두 가지 기술적 접근 방식을 설명하세요.
        - **가설1. 자기 기만 가설** - 모델이 입력 데이터(프롬프트)와 자신이 생성한 데이터(predicted tokens)를 구분하지 못해서 환각이 발생할 수 있다. 만약 입력 데이터가 사실이고, 모델이 생성한 시퀀스가 거짓인 경우 모델은 다음 토큰을 예측할 때 자신이 이전에 생성한 토큰이 마치 사실인 것처럼 가정해서 다음 토큰을 생성한다. 이러한 과정에서 환각이 발생할 수 있다.
            
            **해결방법 제안**
            
            1. 강화 학습을 통해 모델이 사용자가 제시한 입력 프롬프트와 모델이 생성한 시퀀스를 구분할 수 있도록 학습한다.
            2. SFT과정에서 학습 데이터에 사실과 반사실적 데이터를 포함한다.
        - **가설2. 내부 지식 불일치 가설** - 모델이 학습한 내부 지식과 레이블러의 지식이 불일치하는 경우 환각이 발생할 수 있다. 예를 들어, SFT 과정에서 레이블러가 맞다고 생각하는 지식을 모델이 사전 학습 과정에서 학습하지 않은 경우, 파인튜닝 과정에서 모델에게 알고 있지 않은 답변을 하도록 훈련시키는 것과 같은 문제가 발생한다(환각을 발생시키도록 훈련하는 것처럼 보임).
            
            **해결방법 제안**
            
            1. 검증 - 각 응답에 대해 모델이 응답의 근거를 출처로 표시하도록 요청
            2. 보상 모델을 사용한 강화학습 - 환각을 발생시킬 때 더 큰 불이익을 주는 보상 모델로 모델을 학습
        - 추가적으로 신뢰할만한 외부 데이터베이스의 문서를 context로 사용하는 RAG나 프롬프트 엔지니어링 기법을 사용하여 환각을 완화시킬 수 있다. 4장에서 환각을 어떻게 감지하고 측정하는지 설명한다고 한다.
    - 11 AI 애플리케이션에서 구조화된 출력(Structured Outputs)이 필요한 두 가지 주요 시나리오를 제시하고, 프롬프팅(Prompting)이 구조화된 출력을 보장하지 못하는 근본적인 이유를 설명하세요.
        1. **시멘틱 파싱**:  출력 자체를  컴퓨터가 이해할 수 있는 형식으로 구조화
            
            **예시 1: SQL 쿼리로 변환**
            
            - 자연어: "2020년에 출시된 모든 영화를 찾아줘"
            - 구조화된 출력:
            
            ```sql
            SELECT * FROM movies
            WHERE release_year = 2020
            ```
            
            **예시 2: AI 에이전트의 MCP 함수 호출**
            
            1. **자연어 입력**
                - 사용자: "내 구글 드라이브에서 'Q3 보고서' 파일 찾아줘"
            2. **시맨틱 파싱 (의도 파악 및 구조화)**
                
                ```json
                {
                  "tool": "google_drive_search",
                  "parameters": {
                    "query": "Q3 보고서"
                  }
                }
                ```
                
            3. **MCP 호출 실행**
                - 파싱된 구조화된 명령을 실제 MCP 서버로 전달
            4. **결과 반환 및 응답 생성**
            
        2. 다운스트림 애플리케이션에서 사용: 다른 프로그램에서 사용되도록 출력을 구조화 
            
            **사용자 질문**: "이번 달 매출 상위 3개 제품은?"
            
            **자연어 출력**:
            
            ```
            이번 달 매출 상위 제품은 다음과 같습니다:
            1. 노트북 - 약 500만원
            2. 스마트폰 - 대략 450만원
            3. 태블릿 - 450만원 정도입니다.
            ```
            
            ### 해결: 구조화된 출력
            
            **구조화된 JSON 출력**:
            
            ```json
            {
              "top_products": [
                {"rank": 1, "name": "노트북", "revenue": 5000000},
                {"rank": 2, "name": "스마트폰", "revenue": 4500000},
                {"rank": 3, "name": "태블릿", "revenue": 4500000}
              ],
              "currency": "KRW",
              "period": "2025-11"
            }
            ```
            
            **시멘틱 파싱 VS 다운스트림 애플리케이션 사용**
            
            시맨틱 파싱: 입력 → 실행
            
            - 목적: 자연어를 즉시 실행 가능한 명령으로 변환
            
            다운스트림 사용: 출력 → 전달
            
            목적: AI의 분석/생성 결과를 다른 시스템이 사용하도록 구조화
            
    - 12 구조화된 출력을 보장하기 위한 네 가지 주요 접근 방식(프롬프팅, 제약된 샘플링, 테스트 시 컴퓨팅, 미세 조정) 중, 제약된 샘플링(Constrained Sampling)의 작동 방식을 로짓 벡터(Logit Vector) 개념을 활용하여 설명하세요.
        
        **로짓 벡터**: 모델이 다음 토큰을 생성하기 전 각 토큰에 대해 계산한 원시 점수(raw score)를 담은 벡터, 가장 점수가 높은 토큰이 선택됨.
        **제약된 샘플링**: 모델이 다음 토큰을 선택하기 전 토큰이 선택될 기준(필터)를 통과하지 못한 토큰은 점수를 크게 낮춤.
         
        
        **현재까지 생성된 텍스트**
        
        `{"name":`
        
        **모델이 계산한 원본 로짓 (일부만 표시)**
        
        | 토큰 | 로짓 값 | 설명 |
        | --- | --- | --- |
        | `"` | 12.5 | 문자열 시작 (JSON 규칙상 올바름) |
        | `123` | 8.2 | 숫자 (JSON 규칙 위반!) |
        | `{` | 6.1 | 객체 시작 (JSON 규칙 위반!) |
        | `null` | 5.8 | null 값 (JSON 규칙상 가능하지만 부적절) |
        | `true` | 4.2 | boolean (JSON 규칙 위반!) |
        | `홍길동` | 9.5 | 따옴표 없는 문자열 (JSON 규칙 위반!) |
        
        **필터링 후 로짓**
        
        | 토큰 | 원본 로짓 | 필터링 후 | 상태 |
        | --- | --- | --- | --- |
        | `"` | 12.5 | 12.5 | ✓ 허용 |
        | `123` | 8.2 | -∞ | 마스킹 |
        | `{` | 6.1 | -∞ | 마스킹 |
        | `null` | 5.8 | -∞ | 마스킹 |
        | `true` | 4.2 | -∞ | 마스킹 |
        | `홍길동` | 9.5 | -∞ | 마스킹 |
        
        **최종 결과**
        
        선택된 토큰: `"` (확률 100%)
        
    - 13 모델 학습 시 발생하는 메모리 병목 현상(Memory Bottlenecks)을 해결하기 위한 '양자화(Quantization)' 기법의 정의와, 이것이 메모리 및 계산 속도에 미치는 영향을 설명하세요.
        
        <aside>
        ✔️
        
        파라미터의 일부 소수점을 버려 정확도를 포기하는 대신 속도와 경량화를 추구함. 파라미터가 조단위 이상으로 커지는 이 시점에 양자화를 통한 경량화는 필수적이며 PEFT와 함께 고성능GPU가 아니더라도 모델링을 할 수 있게 기여함.
        
        </aside>
        
        <aside>
        ✅
        
        **정의:**
        
        양자화(Quantization)는 **모델의 값을 더 낮은 정밀도 형식(lower-precision format)으로 변환**하는 모든 기술을 포괄하는 용어입니다. 엄밀히 말해 정수 형식으로 변환하는 것만 양자화이지만, 실제로는 FP32(32비트)를 FP16, BF16, 또는 8비트 정수 등으로 변환하는 것을 의미합니다.
        
        **영향:**
        
        1. **메모리 절감:** 파라미터당 필요한 비트 수를 줄여서 모델의 메모리 점유 공간(memory footprint)이 비례적으로 감소합니다. 예를 들어, 16비트에서 8비트로 양자화하면 메모리 요구량이 절반으로 줄어듭니다. 이는 특히 훈련 시 모델 가중치뿐만 아니라 경사(gradient) 및 옵티마이저 상태(optimizer states)까지 저장해야 할 때 메모리 병목 현상을 완화하는 데 매우 중요합니다.
        2. **계산 속도 향상:** 정밀도가 낮아지면 데이터를 처리하는 데 필요한 시간이 줄어들어 **계산 속도가 빨라집니다**. 이는 추론 지연 시간(inference latency)과 훈련 시간을 단축시키는 효과를 가져옵니다. 또한, 메모리 절감을 통해 더 큰 배치 크기(batch size)를 허용하여 모델이 더 많은 입력을 병렬로 처리할 수 있게 됩니다.
        </aside>
        
    - 14 BF16(Bfloat16)과 FP16(Float16)이 모두 16비트를 사용함에도 불구하고, BF16이 FP16보다 범위(Range)는 더 크고 정밀도(Precision)는 낮은 이유를 해당 포맷의 비트 구성을 바탕으로 설명하세요.
        
        <aside>
        ✔️
        
        ? 이런게있엇어?
        
        </aside>
        
        <aside>
        ✅
        
        - **BF16 (Bfloat16):** BF16은 **지수부(범위)**에 더 많은 비트(8비트)를 할당하고, **가수부(정밀도)**에 더 적은 비트(7비트)를 할당합니다. 따라서 FP16이 표현할 수 없는 **더 큰 값**들을 표현할 수 있어 범위가 넓습니다. 하지만 가수부 비트가 적기 때문에 **정밀도(precision)는 낮습니다**.
        - **FP16 (Float16):** FP16은 **지수부**에 5비트를 할당하고, **가수부**에 10비트를 할당합니다. 이는 BF16보다 더 많은 비트를 정밀도에 사용하여 더 정밀하게 숫자를 표현할 수 있지만, 지수부 비트가 적어 **표현할 수 있는 값의 범위는 더 좁습니다**. 예를 들어, FP16에서는 범위를 벗어나는 큰 값들이 무한대(INF)로 반올림될 수 있습니다.
            
            ![image.png](AI%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81%20%EC%8A%A4%ED%84%B0%EB%94%94/image%201.png)
            
        </aside>
        
    - ~~15 크로스 엔트로피(Cross Entropy)와 퍼플렉시티(Perplexity)가 언어 모델 평가에 사용되는 방식에서, 퍼플렉시티를 낮추는 것이 모델 성능에 긍정적인 영향을 미치는 이유를 '불확실성'의 개념을 활용하여 설명하세요.~~
        
        <aside>
        ✔️
        
        ? 이런게잇었어2
        
        </aside>
        
        <aside>
        ✅
        
        - **크로스 엔트로피와 퍼플렉시티의 관계:**
        언어 모델은 훈련 데이터를 기반으로 해당 데이터의 확률 분포를 학습하고, 크로스 엔트로피(Cross Entropy)를 최소화하도록 훈련됩니다. **퍼플렉시티(Perplexity, PPL)**는 크로스 엔트로피의 지수 함수(exponentiation) 형태로, 이는 **모델이 텍스트를 예측할 때 느끼는 '불확실성(uncertainty)'의 척도**로 사용됩니다.
        - **성능과의 관계:**
        퍼플렉시티는 모델이 다음 토큰을 예측할 때 평균적으로 선택해야 하는 **균등하게 가능한 선택지(unique values)**의 개수를 나타냅니다. 따라서:
            1. **PPL이 높다**는 것은 모델의 예측이 **불확실하고**, 다음 토큰에 대해 고려해야 할 가능한 선택지가 많다는 것을 의미합니다.
            2. **PPL이 낮다**는 것은 모델의 예측이 **더 확실하고**, 훈련 데이터를 더 잘 학습했음을 의미합니다.
        
        퍼플렉시티가 낮을수록 모델은 **주어진 문맥에서 다음 토큰을 더 정확하게 예측할 가능성이 높아지며**, 이는 하류 작업(downstream tasks) 성능 향상으로 이어지는 중요한 대리 지표가 됩니다.
        
        </aside>
        
    - 16 언어 모델의 출력 확률을 나타내는 로그 확률(Logprobs)이 애플리케이션 구축 및 평가에 유용하지만, 상용 모델 제공업체들이 Logprobs API 노출을 제한하는 이유를 설명하세요.
        
        <aside>
        ✔️
        
        각 단어의 예측 확률을 표현하면 그 자체로 모델의 추론방향성이 노출되기때문
        
        </aside>
        
        <aside>
        ✅
        
        로그 확률(Logprobs)은 모델이 생성한 각 토큰에 대해 모델이 얼마나 **확신(confidence)하는지**를 측정하는 데 사용됩니다. 이는 다음과 같은 이유로 유용합니다:
        
        1. **평가 및 디버깅:** 모델의 유창성(fluency)이나 사실적 일관성(factual consistency)과 같은 측정을 위해 텍스트의 퍼플렉시티를 평가하는 데 사용될 수 있습니다.
        2. **분류 작업의 확신도:** 분류 작업에서 모델이 특정 클래스에 대해 높은 로그 확률을 보인다면, 이는 해당 예측에 대한 모델의 높은 확신도를 나타냅니다.
        3. **애플리케이션 구축:** 로그 확률을 사용하여 다중 출력 중 가장 확률이 높은 시퀀스를 선택하는 등 테스트 시 컴퓨팅(Test Time Compute) 기법에 활용됩니다.
        
        **API 노출 제한 이유:**
        
        대부분의 모델 제공업체(예: Anthropic, OpenAI)가 로그 확률 API 노출을 제한하거나 그 범위를 축소하는 주된 이유는 **보안(security) 문제**와 관련이 있습니다.
        
        - **모델 복제 위험:** 모델이 노출하는 로그 확률 정보를 활용하면, 외부에서 해당 모델의 내부 작동 방식과 통계적 지식을 더 쉽게 파악하고 **모델을 복제(replicate)하거나 모방(mimic)하는 것이 용이**해질 수 있습니다.
        </aside>
        
    
    ---
    
    ## 📚 예시 답안
    
    1. **모델 규모(Model Size)를 나타내는 세 가지 핵심 지표(파라미터 수, 학습 토큰 수, FLOPs)와 각각이 모델의 어떤 측면을 대변하는지 설명하세요.**
    
    세 가지 핵심 지표와 그것이 대변하는 모델의 측면은 다음과 같습니다:
    
    - **파라미터 수 (Number of parameters):** 이 지표는 **모델의 학습 능력(learning capacity) 또는 잠재력**을 나타내는 대리 지표입니다. 파라미터 수가 많을수록 모델은 더 복잡한 패턴과 지식을 저장할 수 있습니다.
    - **학습 토큰 수 (Number of training tokens):** 이 지표는 모델이 **얼마나 많은 양의 정보를 학습했는지**를 나타내는 대리 지표입니다. 예를 들어, 데이터셋에 1조 개의 토큰이 있고 모델이 이를 두 번 학습했다면 학습 토큰 수는 2조 개가 됩니다.
    - **FLOPs (Floating Point Operations):** 이 지표는 모델 학습에 필요한 **계산량 또는 훈련 비용**을 나타내는 대리 지표입니다. 이는 모델을 훈련하는 데 필요한 컴퓨팅 자원의 양을 측정하는 데 사용됩니다.
    1. **모델 개발 예산이 고정되어 있을 때, 컴퓨팅 최적 모델(Compute-Optimal Model)을 구축하기 위한 스케일링 법칙(Scaling Law)의 핵심 원칙을 설명하세요.**
    
    컴퓨팅 최적 모델은 고정된 컴퓨팅 예산(FLOPs) 내에서 **최상의 성능**을 달성할 수 있는 모델 크기(파라미터 수)와 데이터셋 크기(토큰 수)의 조합을 찾는 것을 목표로 합니다. 스케일링 법칙은 이 세 가지 요소(성능, 모델 크기, 데이터 크기) 사이의 관계를 나타냅니다.
    
    핵심 원칙은 다음과 같습니다:
    
    - **자원 균형의 중요성:** 스케일링 법칙에 따르면, 제한된 컴퓨팅 예산 내에서 모델 성능을 최대화하려면 **파라미터 수와 학습 토큰 수를 균형 있게 증가**시켜야 합니다.
    - **컴퓨팅 최적 비율:** 과거에는 모델 크기를 먼저 키우고 나서 데이터를 채우는 경향이 있었지만, 스케일링 법칙은 특정 예산에서 **파라미터 수와 토큰 수에 할당되는 자원이 모두 최적화**되어야 함을 제시합니다. 이는 모델이 더 많은 데이터를 볼수록 성능이 향상되며, 데이터의 양도 모델 크기만큼 중요함을 의미합니다.
    1. **사전 훈련된 모델(Pre-trained Model)이 일반적으로 가지는 두 가지 주요 문제점을 설명하고, 사후 훈련(Post-Training)이 이 문제들을 어떻게 해결하는지 설명하세요.**
    
    사전 훈련(Pre-training)은 주로 자기 지도 학습(self-supervision) 방식으로 이루어지며, 모델은 이 과정에서 방대한 세계 지식을 습득하지만 두 가지 주요 문제점을 가집니다:
    
    1. **텍스트 완성(Completion)에 최적화된 행동:** 자기 지도 학습은 모델을 텍스트 완성(다음 토큰 예측)에 최적화시키기 때문에, 사용자가 대화(Conversing)나 특정 지침을 따르도록 요청했을 때 모델은 적절한 응답 대신 문장을 완성하려 할 수 있습니다.
    2. **안전하지 않거나 편향된 출력:** 사전 훈련 데이터가 인터넷에서 무차별적으로 수집된 경우, 모델의 출력은 인종차별적이거나, 성차별적이거나, 무례하거나, 또는 단순히 잘못된 내용(hallucinations)을 포함할 수 있습니다.
    
    **사후 훈련(Post-Training)을 통한 해결:**
    
    사후 훈련은 **모델을 인간의 선호도(human preferences)에 맞춰 정렬(align)**시키는 것을 목표로 합니다.
    
    - **문제 1 해결 (행동 정렬):** 지도 미세 조정(SFT)을 통해 모델에 **명시적인 지침(instruction)과 응답 쌍**을 학습시켜, 단순히 텍스트를 완성하는 것이 아니라 사용자의 요청에 적절하게 응답하는 방법을 가르칩니다.
    - **문제 2 해결 (안전 및 정렬):** 선호도 미세 조정(Preference Finetuning)을 통해 인간의 선호도(안전, 유용성 등)를 반영하는 보상 모델(Reward Model)을 훈련하고, 이를 바탕으로 모델이 유해하거나 편향된 응답을 피하도록 최적화합니다.
    1. **지도 미세 조정(Supervised Finetuning, SFT)이 필요한 이유와, SFT를 위한 고품질 데모 데이터(Demonstration Data)를 구축할 때 고려해야 할 두 가지 주요 사항을 설명하세요.**
    
    **SFT가 필요한 이유:**
    
    사전 훈련된 모델은 일반적으로 텍스트 완성(completion)에 최적화되어 있으므로, 사용자의 요청을 대화(conversing)나 질문/답변으로 인식하지 못합니다. SFT는 고품질의 주석이 달린 데이터(annotated data)를 사용하여 모델을 인간의 사용 패턴과 선호도에 맞춰 **행동을 다듬고 정렬**하는 데 필수적입니다. SFT를 통해 모델은 질문-답변, 요약, 번역 등 다양한 유형의 요청을 처리하는 방법을 학습합니다.
    
    **고품질 데모 데이터 구축 시 고려 사항 (두 가지):**
    
    1. **다양한 요청 유형의 포괄성 (Coverage):** 모델이 처리해야 할 모든 요청 유형(예: 질문 응답, 요약, 번역, 분류 등)을 데모 데이터가 포함해야 합니다. 요청 유형이 다양할수록 모델은 광범위한 작업에 효과적으로 응답하는 방법을 학습합니다.
    2. **주석 품질 및 전문성 (Quality & Expertise):** 데모 데이터의 응답은 비판적 사고, 정보 수집, 사용자 요청의 적절성에 대한 판단을 요구할 수 있으므로, **고품질의 주석 작업자(labelers) 또는 도메인 전문가**가 필요합니다. 이는 일반적인 데이터 라벨링과 달리 복잡한 지침에 대한 적절한 응답을 생성해야 하기 때문입니다.
    3. **선호도 미세 조정(Preference Finetuning)의 초기 성공적인 알고리즘인 RLHF(Reinforcement Learning from Human Feedback)의 두 가지 주요 구성 요소와 목표를 설명하세요.**
    
    RLHF (Reinforcement Learning from Human Feedback)는 사전 훈련 및 지도 미세 조정 이후에 모델을 인간의 선호도에 맞추기 위해 사용되는 알고리즘입니다.
    
    **두 가지 주요 구성 요소:**
    
    1. **보상 모델 훈련 (Reward Model Training):** 이 모델은 **파운데이션 모델의 출력에 점수를 매기는 역할**을 합니다. 인간 주석 작업자(labelers)에게 두 개 이상의 응답을 비교하여 선호도를 순위로 매기도록 요청한 비교 데이터(comparison data)를 사용하여 훈련됩니다.
    2. **파운데이션 모델 최적화 (Foundation Model Optimization):** 보상 모델이 부여하는 **점수(reward)를 최대화하도록 파운데이션 모델을 최적화**합니다. 이를 통해 모델은 인간이 선호하는 응답을 생성하도록 학습됩니다.
    
    **목표:**
    
    RLHF의 궁극적인 목표는 **모델을 인간의 선호도와 의도에 밀접하게 정렬**하여, 모델이 더 유용하고 안전하며 지침을 잘 따르는 응답을 생성하도록 만드는 것입니다.
    
    1. **언어 모델에서 '탐욕적 샘플링(Greedy Sampling)' 방식이 분류(Classification) 작업에는 효과적일 수 있으나, 텍스트 생성 작업에는 적합하지 않은 이유를 비교하여 설명하세요.**
    - **분류(Classification) 작업에서의 효과:**
    분류 작업(예: 스팸 탐지)에서는 가능한 결과가 고정되어 있으며, 가장 높은 확률을 가진 결과(예: 스팸일 확률 90%)를 선택하는 것이 합리적이고 정확합니다. 탐욕적 샘플링은 **가장 확률이 높은 단일 결과를 항상 선택**하기 때문에, 결정론적이고 일관된 결과가 필요한 분류 작업에 적합합니다.
    - **텍스트 생성(Text Generation) 작업에서의 부적합성:**
    텍스트 생성 작업에서 탐욕적 샘플링을 사용하면 모델은 매 단계에서 **가장 흔하거나 예측 가능한 토큰만 반복적으로 선택**하게 됩니다. 이는 다음 토큰 예측이 단기적으로는 최적일 수 있지만, 전체 시퀀스로 봤을 때는 반복적이고 **지루하며 창의성이 없는 출력**을 생성하게 만듭니다. 생성 AI의 중요한 속성인 다양성과 창의성을 떨어뜨리기 때문에 생성 작업에는 적합하지 않습니다.
    1. **언어 모델에서 사용하는 토큰 샘플링 전략 중, Top-K 샘플링과 Top-P 샘플링이 작동하는 방식과 각각의 이점을 비교 설명하세요.**
    
    언어 모델은 다음 토큰을 생성하기 위해 어휘집(vocabulary) 전체에 대한 확률 분포를 계산합니다. 이 분포에서 어떤 토큰을 선택할지 결정하는 것이 샘플링 전략입니다.
    
    | 구분 | 작동 방식 | 이점 |
    | --- | --- | --- |
    | **Top-K 샘플링** | **확률이 가장 높은 상위 K개의 토큰**을 미리 선택하고, 선택된 이 K개 토큰들 중에서만 샘플링을 수행합니다. K 값은 고정된 숫자입니다 (예: 50~500). | 1. **계산량 감소:** 상위 K개의 로짓에 대해서만 소프트맥스(softmax)를 수행하여 계산 부하를 줄일 수 있습니다. 2. **예측 가능성 제어:** K 값이 작을수록 텍스트가 더 예측 가능하고 일관성이 높아집니다. |
    | **Top-P 샘플링** | **누적 확률이 P(%)를 초과하는 최소한의 토큰 집합**을 선택하고, 이 토큰 집합 내에서만 샘플링을 수행합니다. P 값은 고정된 백분율입니다 (예: 90%). | 1. **상황 적합성 개선:** 각 문맥에 따라 관련성 높은 토큰의 개수가 유동적으로 변하기 때문에, **출력이 문맥적으로 더 적절**하게 됩니다. 2. **다양성 유지:** 문맥상 매우 다양한 토큰들이 높은 확률을 가질 때는 더 많은 토큰을 고려할 수 있습니다. |
    1. **AI 모델이 본질적으로 '확률적(Probabilistic)'이라는 특성이 창의적인 작업과 일반적인 작업에 미치는 긍정적 및 부정적 영향을 각각 설명하세요.**
    
    AI 모델은 출력을 생성할 때 확률을 기반으로 샘플링하기 때문에, 같은 질문에도 매번 다른 답변을 생성할 수 있습니다.
    
    **1. 창의적인 작업에 미치는 긍정적 영향:**
    
    - **창의성 극대화:** 확률적 특성은 모델이 일반적인 경로를 넘어 탐색하고 "상자 밖에서 생각"할 수 있게 합니다.
    - **아이디어 생성:** 제한 없는 아이디어를 생성하고, 이전에 본 적 없는 디자인을 만들어내는 등 창의적인 전문가의 훌륭한 조력자 역할을 합니다.
    
    **2. 일반적인 작업에 미치는 부정적 영향:**
    
    - **불일치성(Inconsistency):** 반복적으로 동일한 질문을 했을 때 모델의 답변이 달라지면 (예: 에세이 점수를 다르게 매기는 경우), 사용자는 혼란을 느끼고 시스템에 대한 신뢰도가 떨어지게 됩니다.
    - **환각(Hallucination):** 비록 확률이 0이 아니면 아무리 터무니없거나 잘못된 내용이라도 AI에 의해 생성될 수 있으며, 사실 관계를 기반으로 해야 하는 작업(예: 법률 조사, 의학 정보)에서는 치명적인 오류와 피해를 초래할 수 있습니다.
    1. **AI 모델의 확률적 특성으로 인해 발생하는 두 가지 주요 문제(불일치 및 환각)를 정의하고, 이들이 사용자 경험에 미치는 부정적인 영향을 설명하세요.**
    
    **1. 불일치성 (Inconsistency):**
    
    - **정의:** 동일한 입력(프롬프트)에 대해 AI 모델이 실행할 때마다 다른 출력을 생성하는 현상입니다.
    - **부정적 영향:** 인간은 AI와의 상호 작용에서도 일관성을 기대하는데, 불일치성은 **사용자 경험에 혼란**을 야기하고, AI 시스템이 **신뢰할 수 없다**는 인상을 주어 사용자가 모델을 잘못된 응답을 제공하는 "말 그대로 다른 사람"처럼 느끼게 만듭니다.
    
    **2. 환각 (Hallucination):**
    
    - **정의:** AI 모델이 사실과 일치하지 않거나, 주어진 입력이나 지식 기반으로 뒷받침되지 않는 정보를 자신 있게 만들어내는 현상입니다.
    - **부정적 영향:** 환각은 **사실성(factuality)에 의존하는 작업에 치명적**입니다. 사용자가 법률이나 의학 같은 고위험 분야에서 부정확하거나 거짓된 정보를 신뢰하게 만들어 실제 소송 패배나 위험한 행동 유도로 이어지는 등 **재앙적인 실패**를 초래할 수 있습니다.
    1. **환각(Hallucination)이 발생하는 근본적인 원인 두 가지를 설명하고, 환각을 완화하기 위해 제시된 딥마인드(DeepMind)의 두 가지 기술적 접근 방식을 설명하세요.**
    
    **환각의 근본적인 원인 (두 가지):**
    
    1. **훈련 데이터의 제약 (Training Data Limitations):** 모델이 훈련 데이터 내의 패턴에 지나치게 의존하거나, 데이터가 부족하거나 (특히 희소하거나 새로운 정보의 경우), 혹은 훈련 데이터 자체가 오류나 허위 정보를 포함할 때 환각이 발생할 수 있습니다.
    2. **확률 기반의 생성 과정 (Probabilistic Generation):** 언어 모델은 다음 토큰을 예측할 때 가장 그럴듯한(plausible) 시퀀스를 생성하도록 최적화되어 있지, **사실적으로 정확한(factually correct) 시퀀스를 생성하도록 보장되지는 않습니다**. 낮은 확률이라도 사실과 다른 토큰을 생성할 수 있으며, 일단 잘못된 가정을 하면 그 이후의 토큰들은 이 가정에 근거하여 눈덩이처럼 오류를 키워나갈 수 있습니다.
    
    **환각 완화를 위한 딥마인드의 기술적 접근 방식 (두 가지):**
    
    1. **강화 학습 기법 활용:** 사용자 제공 프롬프트(관찰)와 모델이 생성한 토큰(행동)을 구분하도록 모델을 훈련시키는 강화 학습(Reinforcement Learning) 기법을 사용합니다.
    2. **지도 학습 기법 활용:** 훈련 데이터에 **사실적 신호(factual signals)와 반(反)사실적 신호(counterfactual signals)**를 모두 포함하여 모델을 지도 학습(Supervised Learning) 방식으로 훈련시킵니다.
    3. **AI 애플리케이션에서 구조화된 출력(Structured Outputs)이 필요한 두 가지 주요 시나리오를 제시하고, 프롬프팅(Prompting)이 구조화된 출력을 보장하지 못하는 근본적인 이유를 설명하세요.**
    
    **구조화된 출력이 필요한 두 가지 시나리오:**
    
    1. **정확한 응답 및 검증이 필수적인 작업:** 출력이 유효한 정규식(regex)이거나, 미리 정의된 유효한 클래스(valid classes) 중 하나여야 하는 분류(classification) 작업과 같이 **정확한 형식이 요구**되는 경우입니다.
    2. **다운스트림 애플리케이션 사용:** AI의 출력이 다른 애플리케이션(다운스트림 시스템)에 의해 사용될 때, 해당 애플리케이션이 **특정 형식(예: 특정 키를 가진 JSON 문서)**으로 입력을 파싱(parse)해야 하는 경우입니다.
    
    **프롬프팅이 보장하지 못하는 근본적인 이유:**
    
    모델의 **지침 준수 능력(instruction-following capability)에 전적으로 의존**하며, 이 능력은 모델 자체와 지침의 명확성에 따라 달라지기 때문입니다. 모델이 지침을 아무리 잘 따르더라도, **유효하지 않은 출력(invalid model outputs)이 몇 퍼센트라도 발생할 수 있으며**, 이는 많은 애플리케이션에서 허용될 수 없는 위험입니다. 즉, 프롬프팅만으로는 모델이 항상 지정된 문법이나 형식(예: 완벽한 JSON)을 따를 것이라는 **보장(guarantee)이 없습니다**.
    
    1. **구조화된 출력을 보장하기 위한 네 가지 주요 접근 방식(프롬프팅, 제약된 샘플링, 테스트 시 컴퓨팅, 미세 조정) 중, 제약된 샘플링(Constrained Sampling)의 작동 방식을 로짓 벡터(Logit Vector) 개념을 활용하여 설명하세요.**
    
    제약된 샘플링(Constraint Sampling)은 텍스트 생성을 특정 제약 조건에 맞게 유도하는 기술입니다.
    
    **작동 방식:**
    
    1. **로짓 벡터 생성:** 모델이 입력을 처리한 후, 어휘집 내의 모든 가능한 토큰에 해당하는 **로짓 벡터(Logit Vector)**를 출력합니다. 로짓 값은 확률에 해당하지만, 아직 확률 분포로 변환되지 않은 값입니다.
    2. **필터링 적용:** 제약된 샘플링은 이 로짓 벡터에 제약 조건(예: 출력은 '빨강', '파랑', '초록' 중 하나여야 함)을 적용하여, **제약 조건을 충족하는 토큰에 해당하는 로짓만 남기고 나머지는 필터링**합니다.
    3. **샘플링:** 필터링된 유효한 토큰들의 로짓을 사용하여 소프트맥스(Softmax)를 수행하고 확률을 계산한 후, **오직 이 유효한 토큰들 사이에서만 다음 토큰을 샘플링**합니다.
    4. **문법 준수:** 이 과정은 각 단계에서 어떤 토큰이 허용되는지 지정하는 문법(grammar, 예: JSON 문법)을 기반으로 이루어지며, 이를 통해 모델이 문법을 벗어난 토큰을 생성하는 것을 원천적으로 방지합니다.
    5. **모델 학습 시 발생하는 메모리 병목 현상(Memory Bottlenecks)을 해결하기 위한 '양자화(Quantization)' 기법의 정의와, 이것이 메모리 및 계산 속도에 미치는 영향을 설명하세요.**
    
    **정의:**
    
    양자화(Quantization)는 **모델의 값을 더 낮은 정밀도 형식(lower-precision format)으로 변환**하는 모든 기술을 포괄하는 용어입니다. 엄밀히 말해 정수 형식으로 변환하는 것만 양자화이지만, 실제로는 FP32(32비트)를 FP16, BF16, 또는 8비트 정수 등으로 변환하는 것을 의미합니다.
    
    **영향:**
    
    1. **메모리 절감:** 파라미터당 필요한 비트 수를 줄여서 모델의 메모리 점유 공간(memory footprint)이 비례적으로 감소합니다. 예를 들어, 16비트에서 8비트로 양자화하면 메모리 요구량이 절반으로 줄어듭니다. 이는 특히 훈련 시 모델 가중치뿐만 아니라 경사(gradient) 및 옵티마이저 상태(optimizer states)까지 저장해야 할 때 메모리 병목 현상을 완화하는 데 매우 중요합니다.
    2. **계산 속도 향상:** 정밀도가 낮아지면 데이터를 처리하는 데 필요한 시간이 줄어들어 **계산 속도가 빨라집니다**. 이는 추론 지연 시간(inference latency)과 훈련 시간을 단축시키는 효과를 가져옵니다. 또한, 메모리 절감을 통해 더 큰 배치 크기(batch size)를 허용하여 모델이 더 많은 입력을 병렬로 처리할 수 있게 됩니다.
    3. **BF16(Bfloat16)과 FP16(Float16)이 모두 16비트를 사용함에도 불구하고, BF16이 FP16보다 범위(Range)는 더 크고 정밀도(Precision)는 낮은 이유를 해당 포맷의 비트 구성을 바탕으로 설명하세요.**
    
    FP32를 포함하여 부동 소수점 형식(Floating-Point formats)은 일반적으로 부호(sign), 범위(range, 지수부), 정밀도(precision, 가수부)로 구성됩니다. BF16과 FP16은 모두 16비트를 사용하지만, 비트 할당 방식이 다릅니다.
    
    - **BF16 (Bfloat16):** BF16은 **지수부(범위)**에 더 많은 비트(8비트)를 할당하고, **가수부(정밀도)**에 더 적은 비트(7비트)를 할당합니다. 따라서 FP16이 표현할 수 없는 **더 큰 값**들을 표현할 수 있어 범위가 넓습니다. 하지만 가수부 비트가 적기 때문에 **정밀도(precision)는 낮습니다**.
    - **FP16 (Float16):** FP16은 **지수부**에 5비트를 할당하고, **가수부**에 10비트를 할당합니다. 이는 BF16보다 더 많은 비트를 정밀도에 사용하여 더 정밀하게 숫자를 표현할 수 있지만, 지수부 비트가 적어 **표현할 수 있는 값의 범위는 더 좁습니다**. 예를 들어, FP16에서는 범위를 벗어나는 큰 값들이 무한대(INF)로 반올림될 수 있습니다.
    1. **크로스 엔트로피(Cross Entropy)와 퍼플렉시티(Perplexity)가 언어 모델 평가에 사용되는 방식에서, 퍼플렉시티를 낮추는 것이 모델 성능에 긍정적인 영향을 미치는 이유를 '불확실성'의 개념을 활용하여 설명하세요.**
    - **크로스 엔트로피와 퍼플렉시티의 관계:**
    언어 모델은 훈련 데이터를 기반으로 해당 데이터의 확률 분포를 학습하고, 크로스 엔트로피(Cross Entropy)를 최소화하도록 훈련됩니다. **퍼플렉시티(Perplexity, PPL)**는 크로스 엔트로피의 지수 함수(exponentiation) 형태로, 이는 **모델이 텍스트를 예측할 때 느끼는 '불확실성(uncertainty)'의 척도**로 사용됩니다.
    - **성능과의 관계:**
    퍼플렉시티는 모델이 다음 토큰을 예측할 때 평균적으로 선택해야 하는 **균등하게 가능한 선택지(unique values)**의 개수를 나타냅니다. 따라서:
        1. **PPL이 높다**는 것은 모델의 예측이 **불확실하고**, 다음 토큰에 대해 고려해야 할 가능한 선택지가 많다는 것을 의미합니다.
        2. **PPL이 낮다**는 것은 모델의 예측이 **더 확실하고**, 훈련 데이터를 더 잘 학습했음을 의미합니다.
    
    퍼플렉시티가 낮을수록 모델은 **주어진 문맥에서 다음 토큰을 더 정확하게 예측할 가능성이 높아지며**, 이는 하류 작업(downstream tasks) 성능 향상으로 이어지는 중요한 대리 지표가 됩니다.
    
    1. **언어 모델의 출력 확률을 나타내는 로그 확률(Logprobs)이 애플리케이션 구축 및 평가에 유용하지만, 상용 모델 제공업체들이 Logprobs API 노출을 제한하는 이유를 설명하세요.**
    
    **Logprobs의 유용성:**
    
    로그 확률(Logprobs)은 모델이 생성한 각 토큰에 대해 모델이 얼마나 **확신(confidence)하는지**를 측정하는 데 사용됩니다. 이는 다음과 같은 이유로 유용합니다:
    
    1. **평가 및 디버깅:** 모델의 유창성(fluency)이나 사실적 일관성(factual consistency)과 같은 측정을 위해 텍스트의 퍼플렉시티를 평가하는 데 사용될 수 있습니다.
    2. **분류 작업의 확신도:** 분류 작업에서 모델이 특정 클래스에 대해 높은 로그 확률을 보인다면, 이는 해당 예측에 대한 모델의 높은 확신도를 나타냅니다.
    3. **애플리케이션 구축:** 로그 확률을 사용하여 다중 출력 중 가장 확률이 높은 시퀀스를 선택하는 등 테스트 시 컴퓨팅(Test Time Compute) 기법에 활용됩니다.
    
    **API 노출 제한 이유:**
    
    대부분의 모델 제공업체(예: Anthropic, OpenAI)가 로그 확률 API 노출을 제한하거나 그 범위를 축소하는 주된 이유는 **보안(security) 문제**와 관련이 있습니다.
    
    - **모델 복제 위험:** 모델이 노출하는 로그 확률 정보를 활용하면, 외부에서 해당 모델의 내부 작동 방식과 통계적 지식을 더 쉽게 파악하고 **모델을 복제(replicate)하거나 모방(mimic)하는 것이 용이**해질 수 있습니다.
- 3단원
    
    ### 💡 문제 출제
    
    - **문제 1:** 언어 모델의 '혼잡도(Perplexity)'는 '교차 엔트로피(Cross Entropy)'와 어떤 관계이며, 이 지표가 근본적으로 무엇을 측정하는지 설명하세요.
        
        <aside>
        💡
        
        혼잡도(Perplexity, PPL)는 엔트로피와 교차 엔트로피(Cross Entropy, CE)에의 지수함수
        
        두 지표 모두 언어 모델이 다음에 올 단어(또는 토큰)를 얼마나 잘 예측하는지를 측정
        
        - 혼잡도(Perplexity) : 다음 토큰을 예측할때의 불확실성을 측정
        - 교차 엔트로피(Cross Entropy) : 모델이 다음 토큰을 예측하기 얼마나 어려운지 측정
        - 교차 엔트로피 & 혼잡도 간단 예시 정리
        
               문장: "오늘은 날씨가 매우 _ _ _."
        
               정답 단어: "좋다"
        
               모델의 예측 확률 예시: 좋다: 0.60 / 춥다: 0.20 / 덥다: 0.10 / 흐리다: 0.10
        
               1) 교차 엔트로피(Cross Entropy)
        
                정답 “좋다”에 0.60(60%) 을 줬으므로 모델이 정답을 꽤 자신 있게 예측한 상태
        
                → 교차 엔트로피는 낮음 (정답 확률이 높을수록 CE는 낮아짐)
        
               2) 혼잡도(Perplexity, PPL)
        
                교차 엔트로피를 바탕으로 계산됨
        
                정답 확률이 0.60으로 높기 때문에 → 혼잡도도 낮음 (헷갈리지 않았다는 뜻)
        
        **결론: 정답 단어에 높은 확률을 줄수록 → 교차 엔트로피↓, 혼잡도↓ → 모델이 잘 예측한 것!**
        
        </aside>
        
    - **문제 2:** '정확한 평가(Exact Evaluation)' 방법론 중 '기능적 정확성(Functional Correctness)'은 무엇이며, 이 방식이 코드 생성이나 Text-to-SQL 같은 태스크에 특히 유용한 이유를 설명하세요.
        
        <aside>
        💡
        
        기능적 정확성 평가 : 시스템이 의도한 기능을 제대로 수행하는지 평가하는 것
        
        예시) 입력을 넣었을 때 기대한 출력이 정확히 나오는가? → 이게 바로 기능적 정확성
        
        - 코드 생성에 유용한 이유 : 코드 스타일, 구조, 길이는 달라도 실행 결과가 맞으면 정답
        
        ```python
        # for문으로 만든 코드
        def sum_even(nums):
            total = 0
            for n in nums:
                if n % 2 == 0:
                    total += n
            return total
            
        # 리스트 컴프리헨션으로 만든 코드
        def sum_even(nums):
            return sum([n for n in nums if n % 2 == 0])
        #-------------------------------------------------------
        # 입력:
        sum_even([1,2,3,4,5,6])
        # 출력:
        12
        ```
        
        - Text-to-SQL에 유용한 이유 : 문자열 그대로 비교하면 전부 다른 쿼리지만 실행하면 똑같은 결과 → 기능적으로 동일 → 정답
        
        문제: 40살 이상인 사람의 이름을 조회하라.
        
        테이블: `users(name, age)`
        
        ```sql
        SELECT name FROM users WHERE age >= 40;    # 조건 왼쪽 기준
        SELECT name FROM users WHERE 40 <= age;    # 조건을 뒤집어쓴 버전
        SELECT name FROM users WHERE (age >= 40);  # 불필요한 괄호 포함
        ```
        
        **결론: 코드도 SQL도 겉모양은 달라질 수 있지만 실행 결과가 맞으면 정답이므로 기능적 정확성이 가장 정확한 평가 방식**
        
        </aside>
        
    - **문제 3:** '어휘적 유사성(Lexical Similarity)'과 '의미론적 유사성(Semantic Similarity)'은 텍스트를 비교하는 방식에서 어떤 근본적인 차이가 있는지 설명하세요.
        
        <aside>
        💡
        
        **어휘적 유사성(Lexical Similarity):**  두 텍스트가 겉으로 얼마나 비슷하게 생겼는지(형태적 유사성)를 측정. 이를 위해 텍스트를 더 작은 토큰(단어·문자 등)으로 나누어 그 겹치는 정도를 비교. 이 방식은 의미는 고려하지 않고, 문자나 단어가 얼마나 일치하는지만 판단함.
        → 예: “고양이”와 “고양잇과”는 철자가 비슷해 유사도가 높지만, “고양이”와 “냥이”는 의미는 같아도 철자가 다르므로 유사도가 낮게 나옴.
        
        **의미론적 유사성(Semantic Similarity):** 두 텍스트가 의미적으로 얼마나 가까운지를 평가. 단어·문장을 벡터(임베딩) 형태로 숫자로 변환한 후, 그 거리나 방향을 비교해 의미적 유사성을 계산. 즉, 형태가 다르더라도 뜻이 같으면 높은 유사도를 갖음.
        → 예: “학생이 시험을 봤다”와 “시험이 학생에 의해 치러졌다”는 표현은 다르지만 의미가 같아 높은 유사도를 가진다. 마찬가지로 “고양이”와 “냥이”도 의미적으로 유사도가 높게 측정됨.
        
        </aside>
        
    - **문제 4:** '임베딩(Embedding)'이란 무엇이며, CLIP과 같은 다중 모드 임베딩 모델이 텍스트와 이미지를 어떻게 '공동 임베딩 공간(joint embedding space)'으로 매핑하는지 그 목적을 설명하세요.
        
        <aside>
        💡
        
        - 임베딩 : 컴퓨터가 처리할 수 있도록 데이터를 수치(벡터)로 표현하여 커.
            
             좋은 임베딩 알고리즘은 더 유사한 텍스트들이 더 가까운 임베딩을 가지도록 벡터를 생성하는 것
            
        - CLIP과 같은 다중 모드 임베딩 모델의 작동 방식
        :서로 다른 데이터 양식(이미지, 텍스트)을 하나의 공동 임베딩 공간에 매핑함으로써, 이질적인 데이터 간의 의미적 유사성을 계산하고 교차 검색을 가능하게 하여 더 강력한 AI 애플리케이션의 기반을 마련.
            
            마치 다른 언어로 쓰인 두 권의 책을 같은 도서관의 같은 주제 코너에 배치하여, 내용의 유사성을 언어가 아닌 주제로 찾을 수 있게 하는 것과 같음
            
            - 공동 임베딩 공간(Joint Embedding Space)
                
                서로 다른 데이터 양식 간의 비교 및 결합을 가능하게 하는 다중 모드 임베딩 공간
                
        </aside>
        
    - **문제 5:** 'AI 심사위원(AI as a Judge)' 접근 방식이 기존의 인간 평가자에 비해 가지는 주요 이점 2가지를 설명하세요.
        
        <aside>
        💡
        
        1. 속도, 비용 효율성 및 유연성 (Fast, Cheap, and Flexible)
        
        - AI 심사위원은 인간 평가에 비해 훨씬 빠르고 사용하기 쉬우며 상대적으로 저렴
        - AI 모델에게 정확성, 반복성, 유해성, 환각(hallucinations) 등 어떤 기준으로든 출력을 평가하도록 요청할 수 있음→ 사람이 다양한 의견을 제시할 수 있는 것과 유사
        - 결정 설명 능력 : 자신의 판단에 대한 이유를 설명할 수 있음
        1. 참조 데이터 불필요 및 프로덕션 적용 용이성
        - 정답표(Reference Data)가 없어도 평가할 수 있음
            
            (기존 정답표: 모델이 낸 답 ⟶ 정답표와 비교 ⟶ 맞으면 1점 / 틀리면 0점)
            
            ⇒ 실제 서비스에서 나온 응답도 바로 평가하고 모델 개선에 활용 가능
            
        
        결론 :
        AI 심사위원은 사람보다 더 일관되고 흔들림 없는 평가를 제공하며, 정답이 없어도 기준 기반으로 평가할 수 있어 실제 서비스에서도 활용하기 쉽다
        
        </aside>
        
    - **문제 6:** 코드 생성 벤치마크(예: HumanEval)에서 사용하는 `pass@k` 메트릭은 모델의 성능을 어떻게 측정하는지 (k=3을 예시로) 설명하세요.
    
    <aside>
    💡
    
    </aside>
    
    - **문제 7:** '비교 평가(Comparative Evaluation)'와 'A/B 테스팅'은 사용자가 응답을 경험하고 피드백을 제공하는 방식에서 어떻게 다른지 설명하세요.
    
    <aside>
    💡
    
    비교평가: 
    - 동시노출 : 사용자가 두개의 응답을 동시에 경험함
    a/b테스팅 : 
    - 분리된 노출 : 사용자가 한번에 하나의 응답만을 경험함.
    
    </aside>
    
    - **문제 8:** '혼잡도(Perplexity)'는 모델이 텍스트를 얼마나 잘 예측하는지 측정합니다. 이 원리를 이용해 **(1) 데이터 오염(Data Contamination)**과 **(2) 비정상적 텍스트**를 탐지하는 방법을 각각 설명하세요.
    
    <aside>
    💡
    
    </aside>
    
    - **문제 9:** AI 심사위원 사용 시 발생할 수 있는 편향 중, '자기 편향(Self-bias)'과 '첫 위치 편향(Position-bias)'이 각각 무엇인지 설명하세요.
    
    <aside>
    💡
    
    자기 편향 - AI 평가자가 자기가 생성한 응답을 다른 모델이 생성한 응답보다 더 높게 평가하는 편향. 
    
    첫 위치  편향 - 평가 대상이 짝을 이루고 있거나 여러 선택지가 있을 때 AI 평가자가 첫번째로 나오는 대상 또는 선택지를 더 높게 평가하는 편향
    
    </aside>
    
    - **문제 10:** 응답의 주관적인 품질을 평가할 때, '점수 부여(pointwise) 평가' 방식보다 '쌍대 비교(pairwise comparison)' 방식이 더 선호되는 이유를 설명하세요.
    
    <aside>
    💡
    
    주관적 품질을 평가할 때 점수 부여 방식은 각 모델의 응답을 독립적으로 평가한 뒤 점수를 가지고 비교대조한다. 그러나 이러한 방법으로 각 모델의 점수를 구체화하여 비교하는 것보다 두 모델의 응답에 대해 상대적 비교를 통한 선호도 평가가 더 쉽다고 한다. 그러나 모든 질의에 대해 이렇게 선호도를 바탕으로 평가할 수는 없다. 때로는 구체적인 기준에 따라 정확성을 평가해야 하는 과제도 있다.
    
    </aside>
    
    - **문제 11:** 'AI 심사위원'의 '장황함 편향(Verbosity-bias)'이란 무엇이며, 이 편향이 어떻게 부정확한 응답을 긍정적으로 평가하는 왜곡을 발생시킬 수 있는지 설명하세요.
    
    <aside>
    💡
    
    AI 평가자가 응답의 품질과 관계 없이 더 긴 응답에 대해 높이 평가하는 것.
    
    → 간결하고 정확한 답보다 장황하고 틀린 답을 옳다고 잘못 평가할 수 있다.
    
    </aside>
    
    - **문제 12:** AI 심사위원이 평가 대상 모델보다 '약한 모델'이어도 되는 근거는 무엇이며, RLHF에 사용되는 '보상 모델(Reward Model)'이 어떻게 이 원리를 활용하는지 설명하세요.
    
    <aside>
    💡
    
    일반적으로 LLM은 텍스트를 생성하는 것보다 주어진 텍스트를 분류/평가하는 과제를 더 쉽게 수행한다. 이를 근거로  약한 모델을 AI 평가자로 사용할 수 있다고 한다. (한편, flagship 모델로 평가하면 비용이 많이 발생한다.)
    
    특화된 평가자에서 보상 모델은 (프롬프트, 응답) 쌍이 주어지면 응답의 정확성에 대해 0 ~ 1 값으로 평가한다. 보상 모델은 이러한 방식의 평가 과제에 대해 특화된 소형 모델이다. 특화된 평가자 모델은 특정 평가 과제에 대해 대형 범용모델보다 더 신뢰할 수 있는 예측을 할 수 있다고 한다.
    
    </aside>
    
    - **문제 13:** 파운데이션 모델 평가는 기존 ML 모델 평가보다 더 어렵습니다. 그 주된 이유 두 가지를 **(1) 모델의 응답 특성(예: 개방형)**과 **(2) 모델의 지능 수준** 관점에서 설명하세요.
    
    <aside>
    💡
    
    1. 파운데이션 모델은 학습한 데이터 분포를 바탕으로 주어진 입력 토큰 다음에 나타날 토큰을 예측한다. 그러나 언어 모델의 특성 상 예측 토큰 정확도 뿐만 아니라 생성된 텍스트의 문맥적 의미를 평가할 수 있어야 한다(정답이 여러 개일 수 있음). 이러한 점에서 개방형 모델은 그 응답을 평가할 때 주관적 고려 요소가 있으므로 기존 ML 모델을 평가하는 것보다 훨씬 더 까다롭다.
    2. 모델의 지능 수준 관점에서는 만약 최신 Gemini-3 모델이 수학 논문에 대해 정리한 내용을 평가한다고 할 때 모델의 출력에 대해 평가할 수 있는 사람은 많지 않을 것이다. 왜냐하면 일반적인 사람들은 대학원 수준의 수학에 대해 잘 아는 사람이 없기 때문이다. 이렇게 파운데이션 모델이 고도의 추론과 전문지식에 관한 내용을 출력할 때 이를 평가하기 위해서는 비슷한 수준 또는 그 이상의 지식과 자료가 필요할 수 있다. 이러한 검증을 할 수 있는 사람 많지 않다. 모델이 똑똑하고 전문적일 수록 이를 평가하기는 쉽지 않다.
    </aside>
    
    - **문제 14:** '비교 평가' 시스템에서 'Elo'나 'Bradley-Terry'와 같은 평가 알고리즘(Rating Algorithm)은 수집된 쌍대 비교 결과를 어떻게 처리하여 모델의 최종 순위를 결정하는지 설명하세요.
    
    <aside>
    💡
    
    한 모델이 다른 하나의 모델과 match에서 이긴 횟수를 확률로 바꿔 점수로 사용한다. 이러한 점수들을 종합하여 모든 모델들의 점수를 순위로 매겨 최종 순위를 결정한다.
    
    </aside>
    
    - **문제 15:** 크라우드소싱을 통한 '비교 평가'(예: 챗봇 아레나)는 **(1) 확장성** 측면과 **(2) 표준화 및 품질 관리** 측면에서 어떤 한계점을 가지는지 설명하세요.
    
    <aside>
    💡
    
    1. 비교 평가에서 새로운 모델이 추가되는 경우 기존 모델의 순위를 바꿀 수 있다. 그리고 비공개 모델을 평가해야 하는 경우 비교 데이터를 직접 수집해서 비교를 하거나 비교 업체에 비공개 평가를 의뢰하는 식으로 진행해야 한다.
    2. 불특정 다수의 다양한 사람들이 익명의 모델에 대해 평가하기 때문에 표준화 및 품질 문제가 발생한다. 전문적으로 어떤 응답이 적절한지 평가할 능력이 없는 사용자가 선호도를 평가하는 경우, 악의적이고 유해한 응답을 선호하는 사용자가 평가하는 경우 등 모델 성능 평가를 일관되게 유지하기 어려운 문제가 있다.
    </aside>
    
    - **문제 16:** '비교 평가'는 모델의 상대적 순위를 알려주지만, "이 모델이 우리 용도에 충분히 좋은가?"라는 질문에는 답하기 어렵습니다. 그 이유를 '절대적 성능' 관점에서 설명하세요.
    
    <aside>
    💡
    
    두 모델 중 어떤 모델이 더 좋은 모델인지는 알 수 있지만 절대적인 성능을 파악하기는 어렵다. (예: 두 모델 다 성능이 떨어질 경우)
    
    </aside>
    
    ---
    
    ### 📝 예시 답안
    
    - **문제 1:** 언어 모델의 '혼잡도(Perplexity)'는 '교차 엔트로피(Cross Entropy)'와 어떤 관계이며, 이 지표가 근본적으로 무엇을 측정하는지 설명하세요.
        
        <aside>
        💡
        
        **답안:** 
        
        '혼잡도(Perplexity, PPL)'는 **'교차 엔트로피(Cross Entropy)'의 지수 값**입니다. 이 지표는 모델이 다음 토큰을 예측할 때 갖는 '불확실성(uncertainty)'의 양을 측정합니다. 즉, 모델이 평균적으로 몇 개의 가능한 토큰 중에서 고민하는지를 나타내며, 값이 낮을수록 모델이 텍스트를 더 정확하게 예측한다는 의미입니다.
        
        </aside>
        
    - **문제 2:** '정확한 평가(Exact Evaluation)' 방법론 중 '기능적 정확성(Functional Correctness)'은 무엇이며, 이 방식이 코드 생성이나 Text-to-SQL 같은 태스크에 특히 유용한 이유를 설명하세요.
        
        <aside>
        💡
        
        **답안:** 
        
        '기능적 정확성'은 모델의 생성물이 의도한 기능을 올바르게 수행했는지 여부를 평가하는 것입니다. 이 방식은 생성된 코드나 SQL 쿼리를 **실제로 실행**하여 유닛 테스트를 통과하는지, 또는 쿼리 결과가 예상된 값과 일치하는지 등을 자동으로 검증할 수 있기 때문에 해당 태스크들에 특히 유용합니다 .
        
        </aside>
        
    - **문제 3:** '어휘적 유사성(Lexical Similarity)'과 '의미론적 유사성(Semantic Similarity)'은 텍스트를 비교하는 방식에서 어떤 근본적인 차이가 있는지 설명하세요.
        
        <aside>
        💡
        
        **답안:** 
        
        '어휘적 유사성'은 두 텍스트가 **표면적으로 얼마나 비슷하게 보이는지** (예: 겹치는 단어, n-그램 수)를 측정합니다 . 반면, '의미론적 유사성'은 두 텍스트의 **'의미(semantics)'가 얼마나 가까운지**를 측정합니다. 예를 들어 "What's up?"과 "How are you?"는 어휘적으로는 매우 다르지만 의미론적으로는 매우 가깝습니다.
        
        </aside>
        
    - **문제 4:** '임베딩(Embedding)'이란 무엇이며, CLIP과 같은 다중 모드 임베딩 모델이 텍스트와 이미지를 어떻게 '공동 임베딩 공간(joint embedding space)'으로 매핑하는지 그 목적을 설명하세요.
        
        <aside>
        💡
        
        **답안:** 
        
        '임베딩'은 텍스트와 같은 원본 데이터의 '의미(meaning)'를 포착하도록 설계된 숫자 벡터 표현입니다. CLIP과 같은 '다중 모드 임베딩' 모델의 목적은 텍스트와 이미지처럼 서로 다른 유형의 데이터를 하나의 '공동 임베딩 공간'으로 매핑하는 것입니다. 이를 통해 "낚시하는 남자"라는 텍스트의 임베딩이 실제 낚시하는 남자의 이미지 임베딩과 벡터 공간상에서 가까워지도록 하여, 텍스트 기반 이미지 검색 등을 가능하게 합니다 .
        
        </aside>
        
    - **문제 5:** 'AI 심사위원(AI as a Judge)' 접근 방식이 기존의 인간 평가자에 비해 가지는 주요 이점 2가지를 설명하세요.
        
        <aside>
        💡
        
        **답안:**
        
        - **속도와 비용:** AI 심사위원은 인간 평가자보다 훨씬 빠르고 저렴하게 대규모의 응답을 평가할 수 있습니다.
        - **참조 데이터 불필요:** 참조(정답) 데이터 없이도 모델의 응답 품질을 평가할 수 있어, 참조 데이터를 만들기 어려운 실제 프로덕션 환경에서도 유용합니다. (또한, AI 심사위원은 평가에 대한 '설명'이나 '이유'를 함께 제공할 수 있습니다.)
        </aside>
        
    - **문제 6:** 코드 생성 벤치마크(예: HumanEval)에서 사용하는 `pass@k` 메트릭은 모델의 성능을 어떻게 측정하는지 (k=3을 예시로) 설명하세요.
        
        <aside>
        💡
        
        **답안:** 
        
        `pass@k`는 모델이 특정 문제에 대해 `k`개의 코드 샘플을 생성하도록 했을 때, 이 `k`개의 샘플 중 하나라도 모든 유닛 테스트를 통과하면 해당 문제를 '해결'한 것으로 간주하는 평가 메트릭입니다. 예를 들어 `pass@3`은, 모델이 3개의 코드 샘플을 생성하고 그 3개 중 단 하나라도 유닛 테스트를 통과하면 성공으로 봅니다. 최종 점수는 전체 문제 중 성공적으로 해결한 문제의 비율로 계산됩니다.
        
        </aside>
        
    - **문제 7:** '비교 평가(Comparative Evaluation)'와 'A/B 테스팅'은 사용자가 응답을 경험하고 피드백을 제공하는 방식에서 어떻게 다른지 설명하세요.
        
        <aside>
        💡
        
        **답안:** 
        
        A/B 테스팅은 사용자가 한 번에 하나의 모델 후보(A 또는 B)만 경험하고 그에 대한 암시적 피드백(예: 클릭률)을 수집하는 방식입니다. 반면, 비교 평가는 사용자(또는 평가자)에게 두 개 이상의 모델 응답을 동시에 제시하고 어느 것이 더 나은지 직접 선택하도록(명시적 피드백) 하는 방식입니다.
        
        </aside>
        
    - **문제 8:** '혼잡도(Perplexity)'는 모델이 텍스트를 얼마나 잘 예측하는지 측정합니다. 이 원리를 이용해 **(1) 데이터 오염(Data Contamination)**과 **(2) 비정상적 텍스트**를 탐지하는 방법을 각각 설명하세요.
        
        <aside>
        💡
        
        **답안:**
        
        - **데이터 오염 탐지:** 모델은 훈련 중에 이미 보았던(암기한) 텍스트에 대해 매우 낮은 혼잡도(PPL)를 보입니다. 만약 모델이 특정 벤치마크 데이터에 대해 비정상적으로 낮은 혼잡도를 보인다면, 이는 해당 벤치마크가 모델의 훈련 데이터에 포함되었을 가능성(오염)을 시사합니다 .
        - **비정상적 텍스트 탐지:** 혼잡도는 예측 불가능한 텍스트일수록 높게 나타납니다. 따라서 횡설수설하는 텍스트나 비정상적인 아이디어(예: "우리 집 개는 양자물리학을 가르친다")를 포함한 텍스트는 높은 혼잡도 값을 가지므로, 이를 탐지하는 데 혼잡도를 사용할 수 있습니다.
        </aside>
        
    - **문제 9:** AI 심사위원 사용 시 발생할 수 있는 편향 중, '자기 편향(Self-bias)'과 '위치 편향(Position-bias)'이 각각 무엇인지 설명하세요.
        
        <aside>
        💡
        
        **답안:**
        
        - **자기 편향 (Self-bias):** AI 심사위원 모델이 다른 모델이 생성한 응답보다 자기 자신이 생성한 응답을 더 선호하는(높은 점수를 주는) 경향입니다.
        - **위치 편향 (Position-bias):** 두 개의 응답을 비교 평가할 때, 응답의 품질과 상관없이 첫 번째 위치에 제시된 응답을 선호하는 경향입니다. 이는 인간의 '최신 편향(recency bias)'과는 반대되는 경향입니다.
        </aside>
        
    - **문제 10:** 응답의 주관적인 품질을 평가할 때, '점수 부여(pointwise) 평가' 방식보다 '쌍대 비교(pairwise comparison)' 방식이 더 선호되는 이유를 설명하세요.
        
        <aside>
        💡
        
        **답안:** 
        
        주관적인 품질에 대해 '절대적인 점수'(예: 1~5점)를 일관되게 매기는 것은 인간(또는 AI) 평가자에게 매우 어려운 작업입니다. 한 평가자가 5점을 준 응답과 다른 평가자가 7점을 준 응답을 비교하기 어렵습니다. 반면, 두 개의 응답을 나란히 놓고 '어느 것이 더 나은지'를 판단하는 '상대적인 비교'는 훨씬 더 쉽고 일관되게 수행할 수 있기 때문에 쌍대 비교 방식이 더 선호됩니다.
        
        </aside>
        
    - **문제 11:** 'AI 심사위원'의 '장황함 편향(Verbosity-bias)'이란 무엇이며, 이 편향이 어떻게 부정확한 응답을 긍정적으로 평가하는 왜곡을 발생시킬 수 있는지 설명하세요.
        
        <aside>
        💡
        
        **답안:** 
        
        '장황함 편향'은 AI 심사위원이 응답의 실제 품질이나 정확성과 관계없이 더 길고 장황한(verbose) 응답을 더 좋다고 평가하는 경향입니다. 이 편향은 평가 결과를 왜곡시킬 수 있는데, 한 연구에서는 AI 심사위원이 사실적 오류가 포함된 긴 응답을, 오류 없이 정확하지만 짧은 응답보다 선호하는 현상을 발견했습니다. 이는 길이와 품질을 혼동하여 부정확한 응답에 더 높은 점수를 주게 만듭니다.
        
        </aside>
        
    - **문제 12:** AI 심사위원이 평가 대상 모델보다 '약한 모델'이어도 되는 근거는 무엇이며, '보상 모델(Reward Model)'이 어떻게 이 원리를 활용하는지 설명하세요.
        
        <aside>
        💡
        
        **답안:**
        
        - **근거:** 응답을 '생성'하는 것(예: 노래 작곡)이 응답을 '판단'하는 것(예: 노래가 좋은지 평가)보다 더 어려운 작업으로 간주되기 때문입니다. 따라서 더 약한 모델도 더 강한 모델의 출력을 판단할 수 있습니다.
        - **활용:** '보상 모델(Reward Model)'은 (프롬프트, 응답) 쌍을 입력받아 응답이 얼마나 좋은지 점수를 출력하도록 전문화된 모델입니다. 이러한 모델(예: Cappy)은 종종 평가 대상인 거대 모델보다 크기가 훨씬 작지만(예: 360M 파라미터), 특정 기준(예: 정확성)에 대해 효과적인 평가를 수행할 수 있습니다.
        </aside>
        
    - **문제 13:** 파운데이션 모델 평가는 기존 ML 모델 평가보다 더 어렵습니다. 그 주된 이유 두 가지를 **(1) 모델의 응답 특성(예: 개방형)**과 **(2) 모델의 지능 수준** 관점에서 설명하세요.
        
        <aside>
        💡
        
        **답안:**
        
        - **모델의 응답 특성:** 파운데이션 모델은 정답이 하나로 정해지지 않은 '개방형(Open-ended)' 응답을 생성합니다. 기존 ML 모델(예: 분류)은 출력이 미리 정의된 범주로 한정되어 정답과 비교하기 쉽지만, 파운데이션 모델은 다양한 정답 표현이 가능해 참조 데이터와 비교하기 어렵습니다.
        - **모델의 지능 수준:** 모델이 지능화될수록 평가가 더 어려워집니다. 1학년 수학 문제와 박사 수준의 수학 문제를 평가하는 난이도가 다르듯이, 모델이 생성하는 정교한 요약이나 분석은 평가자(인간 또는 AI)가 그 내용을 완전히 이해하고 사실 확인까지 해야 하므로 훨씬 더 시간 소모적입니다 .
        </aside>
        
    - **문제 14:** '비교 평가' 시스템에서 'Elo'나 'Bradley-Terry'와 같은 평가 알고리즘(Rating Algorithm)은 수집된 쌍대 비교 결과를 어떻게 처리하여 모델의 최종 순위를 결정하는지 설명하세요.
        
        <aside>
        💡
        
        **답안:** 
        
        이 알고리즘들은 수집된 수많은 '쌍대 비교 결과'(예: 모델 A가 모델 B를 이김, 모델 C가 모델 A를 이김 등)를 통계적으로 취합하여, 각 모델의 상대적인 강점을 나타내는 '단일 점수(Score)'를 계산하는 역할을 합니다. 이 계산된 점수를 기준으로 전체 모델의 순위를 매길 수 있습니다.
        
        </aside>
        
    - **문제 15:** 크라우드소싱을 통한 '비교 평가'(예: 챗봇 아레나)는 **(1) 확장성** 측면과 **(2) 표준화 및 품질 관리** 측면에서 어떤 한계점을 가지는지 설명하세요.
        
        <aside>
        💡
        
        **답안:** 
        
        - **확장성 병목 현상:** 평가해야 할 모델의 수가 증가함에 따라 필요한 비교 쌍의 수가 기하급수적으로(quadratically) 증가합니다. 57개의 모델을 비교하는 데 244,000건의 비교가 사용되었음에도 쌍당 평균 153건에 불과할 정도로, 모든 모델을 충분히 비교하기 어렵습니다.
        - **표준화 및 품질 관리의 부재:** 평가자들이 사용하는 프롬프트가 표준화되어 있지 않고, 무엇이 '더 나은' 응답인지에 대한 기준도 제각각입니다. 이로 인해 사실 확인 없이 그럴듯하게 들리는 응답을 선호하거나, "안녕"과 같은 너무 단순한 프롬프트를 사용하여 모델 간의 변별력을 떨어뜨리는 등 노이즈가 많은 피드백이 수집될 수 있습니다.
        </aside>
        
    - **문제 16:** '비교 평가'는 모델의 상대적 순위를 알려주지만, "이 모델이 우리 용도에 충분히 좋은가?"라는 질문에는 답하기 어렵습니다. 그 이유를 '절대적 성능' 관점에서 설명하세요.
        
        <aside>
        💡
        
        **답안:** 
        
        비교 평가는 모델 간의 '상대적인 순위'는 알려주지만, 각 모델의 '절대적인 성능'이나 '업무 적합성(good enough)'을 알려주지 않기 때문입니다 . 예를 들어, 모델 B가 모델 A보다 낫다고 해도, 
        
        (1) 두 모델 모두 사용 불가능할 정도로 나쁘거나, 
        
        (2) 두 모델 모두 이미 충분히 좋을 수 있습니다. 또한 "51%의 선호도"가 실제 비즈니스 메트릭(예: 고객 문제 해결률)에 얼마나 큰 향상을 가져올지 알 수 없으므로, 추가 비용을 정당화하기 어렵습니다.
        
        </aside>
        
    
- 4단원
    
    ### 💡 문제 출제
    
    - **문제 1 :** 모델의 도메인별 역량(Domain-Specific Capability)을 평가하는 데 있어, 대부분의 공개 벤치마크가 다지선다형 질문(MCQs)과 같은 폐쇄형 작업(close-ended tasks)을 선호하는 주된 이유는 무엇입니까?
        
        <aside>
        💡
        
        1. **용이한 검증 및 재현성:** MCQs는 모델의 응답이 예상되는 정답과 일치하는지 **쉽게 확인하고 재현**할 수 있게 해줍니다. 이는 자동화된 평가 시스템을 구축하는 데 유리
        
        2. **지식 및 추론 능력 평가:** MCQs는 모델이 특정 도메인에 대한 지식(knowledge)을 보유하고 있는지, 그리고 **추론(reasoning)** 능력을 가지고 있는지를 평가하는 데 가장 적합
        
        3. **무작위 기준선(Random Baseline) 대비 용이한 평가:** 질문이 네 가지 옵션 중 하나를 고르는 형태라면, 모델의 무작위 기준선 정확도는 25%가 됩니다. MCQs는 모델 성능을 이 **무작위 기준선과 비교하여 평가하기 쉬움**
        
        다만, 이러한 폐쇄형 벤치마크는 **생성 역량**을 평가하는 데는 이상적이지 않습니다. MCQs는 모델이 좋은 응답을 생성하는 능력이 아니라, 주어진 옵션 중에서 좋은 응답과 나쁜 응답을 구별하는 능력(분류)을 테스트하기 때문
        
        따라서, 수학, 과학 지식, 일반 상식, 법률 지식 등 **지식 기반(knowledge-based)** 또는 **추론 기반(reasoning-based)** 역량을 평가할 때는 MCQs가 널리 사용되지만, 요약, 번역, 에세이 작성과 같은 **생성 능력**을 평가할 때는 적합하지 않음
        
        </aside>
        
    - **문제 2:** 코드 생성 능력 평가에 사용되는 주요 지표인 Pass@k는 무엇을 의미하며, 이 점수가 k 값에 따라 어떻게 변화합니까?
        
        <aside>
        💡
        
        **Pass@k**는 코드 생성 능력 평가에 사용되는 주요 지표입니다.
        
        - **Pass@k**는 모델이 생성한 *k*개의 코드 샘플 중 **해당 문제의 모든 테스트 케이스(test case)를 통과한 문제의 비율**을 의미
        - 예를 들어, 10개의 문제가 있고 *k*=3으로 모델이 5문제를 해결했다면, 해당 모델의 Pass@3 점수는 50%가 됨
        - 코드 생성 능력과 같은 코딩 관련 역량은 일반적으로 기능적 정확성(Functional Correctness)을 사용하여 평가
        
        **k 값에 따른 점수 변화**
        
        - 모델이 생성하는 코드 샘플의 수, 즉 *k* 값이 많아질수록, 모델이 각 문제를 해결할 수 있는 가능성이 더 커짐
        - 따라서, 기대치(in expectation)로 볼 때 **Pass@k 점수는** *k* **값이 커질수록 더 높아져야 합니다**. 이는 Pass@1 점수가 Pass@3 점수보다 낮아야 하며, Pass@3 점수는 Pass@10 점수보다 낮아야 함을 의미
        </aside>
        
    - **문제 3 :** 자연어 생성(NLG) 작업에서 유창성(Fluency)과 일관성(Coherence)이 과거에 중요했지만, 오늘날 파운데이션 모델 평가에서 그 중요성이 낮아진 이유를 설명하십시오.
        
        <aside>
        💡
        
        </aside>
        
    - **문제 4 :** 사실적 일관성(Factual Consistency)을 검증하는 두 가지 설정, 지역 사실적 일관성(Local Factual Consistency)과 글로벌 사실적 일관성(Global Factual Consistency)의 차이점을 컨텍스트 기준으로 설명하십시오.
        
        <aside>
        💡
        
        국소적(지역) 사실 일관성(Local Factual Consistency)
        
        - AI가 답변을 만들 때 참고하라고 미리 제공한 자료 = 컨텍스트(context)에 의해 지지되는지를 평가함
        - 만약 컨텍스트 안의 내용과 다르면 사실적으로 *일관되지 않은(output inconsistent)* 것으로 봄
        - 예시) 컨텍스트: “하늘은 보라색이다.”
        
                        모델 출력: “하늘은 파랗다.”
        
                  → 컨텍스트와 모순 → 지역 사실 불일치❌ 
        
                        모델 출력: “하늘은 보라색이다.”
        
                  → 컨텍스트와 일치 → 지역 사실 일관성 ✔
        
        전역적(글로벌) 사실 일관성(Global Factual Consistency)
        
        - 모델의 출력이 “일반적으로 받아들여지는 사실(open knowledge)”과 같은지를 평가함
        - 컨텍스트가 없으면  외부 자료를 찾아 사실을 확인해야 하므로 사실 검증 과정이 더 어렵고 훨씬 복잡해짐
        - 예시) 모델 출력: “하늘은 파랗다.”
        
                        → 일반적으로 사실 → 글로벌 사실 일관성 ✔
        
        </aside>
        
    - **문제 5 :** 모델의 환각(Hallucination)을 측정하기 위한 두 가지 정교한 AI 심사위원 기술인 SelfCheckGPT와 SAFE(Search-Augmented Factuality Evaluator)의 기본 작동 원리를 비교 설명하십시오.
        
        <aside>
        💡
        
        SelfCheckGPT
        
        - 같은 질문을 모델에게 여러 번 물어보고 답변이 서로 얼마나 일치하는지 확인하는 방식
        - 만약 답변이 반복할 때마다 내용이 들쑥날쑥하다면,
            
            → 모델이 해당 사실을 정확히 모르고 추측했다는 신호
            
            → 즉, 환각(Hallucination) 가능성이 높다고 판단함
            
        - 외부 지식 없이 모델의 내부 일관성만으로 검증하는 방법
        
        SAFE (Search-Augmented Factuality Evaluator)
        
        - 모델의 답변을 작은 사실 단위로 쪼갠 뒤 각각을 확인하기 위해 검색 엔진에 쿼리를 보내고, 검색 결과를 바탕으로 “이 사실이 진짜 맞는지”를 AI가 다시 판정하는 구조
        
              즉, 모델이 말한 내용을 인터넷을 통해 직접 검증하는 방식
        
        - 외부 지식을 활용하기 때문에 정확도가 높은 반면 검색 과정이 있어 비용·시간이 증가함
        </aside>
        
    - **문제 6 :** 정치적 또는 종교적 편향(Biases toward a political or religious ideology)이 모델의 출력에 미치는 영향을 설명하십시오.
        
        <aside>
        💡
        
        AI 모델은 인터넷, 문서, SNS 등 사람이 만든 데이터를 기반으로 학습하기 때문에 그 데이터에 포함된 정치적·종교적 편향이 모델의 출력에도 영향을 주게 되고 모델의 중립성·공정성·신뢰성에을 해칠 수 있음
        
        ① 특정 정치·종교 관점을 더 긍정적으로 표현
        
        ② 논쟁적 주제에서 균형 잡힌 답변을 못할 수 있음
        
        ③ 사용자에게 왜곡된 세계관을 전달할 수 있음
        
        ④ 실제 모델별로 성향이 다를 수도 있음
        
        </aside>
        
    - **문제 7 :** Google의 IFEval (Instruction-Following Evaluation) 벤치마크가 명령어 따르기 능력을 평가하는 주요 방식은 무엇입니까?
        
        <aside>
        💡
        
        IFEval (Instruction-Following Evaluation)
        
        1. 평가 초점: 모델이 예상된 형식에 맞는 출력을 생성할 수 있는지에 초점을 맞춤
        2. 평가 도구: 자동으로 검증할 수 있는 25가지 유형의 지시를 정의했음 > 즉, 객관적인 기준을 만들어 사람의 주관적인 판단 없이 컴퓨터가 스스로, 자동으로 채점될 수 있게 테스트를 만든 것
        3. 평가 결과: 지시 이행률, 정확하게 따른 지시의 비율을 구체적으로 분석함 > 모델이 어떤 규칙에 강하고 어떤 규칙에 약한지를 파악(ex: 길이 제약에 강하지만, JSON 형식 생성에는 약함)
        </aside>
        
    - **문제 8 :** 모델 선택 시 모델 품질, 지연 시간(Latency), 그리고 비용(Cost)을 균형 있게 고려해야 하는 이유를 설명하십시오.
        
        <aside>
        💡
        
        이 세가지 요소는 트레이드 오프 관계에 잇기 때문에 ‘품질이 높음(좋은 결과물) > 지연시간이 늘어남 + 더 많은 컴퓨터 자원이 필요해서 비용이 늘어남’ 하나를 높이려면 다른 하나를 희생해야하는 경우가 많음. 
        
        비약적으로 비유해보자면 ‘박사채용 > 인건비가 너무 비싸고 채용에 시간이 오래걸림, 학사채용 > 박사 인력대비 많은 인력 + 비용 절약 > 복잡하거나 전문적인 문제가 생겼을 때 해결 능력이 떨어질 수 있음’ 
        
        따라서 ‘서비스의 목적’에 맞춰 세가지 요소가 가장 잘 만나는 지점을 찾아야 함! 
        
        </aside>
        
    - **문제 9 :** 기업이 상용 API를 사용하는 대신 오픈 소스 모델을 직접 호스팅(Self-hosting)하는 것을 선호하는 주요 이유 두 가지는 무엇입니까?
        
        <aside>
        💡
        
        **결국에는 어떤 모델이 가장 좋은지? 는 중요하지 않음, 내 결과물에 가장 적합한 모델이 무엇인지가 중요** 
        
        **그래서 모델을 직접 호스팅할지 모델 API를 사용할지에 대한 답은 활용 사례에 따라 다름, 고려해야할 상황이 총 7가지가 있는데 내가 읽어봤을 때 기업이 오픈 소스 모델을 선호하는 두가지의 이유는 아래와 같음.** 
        
        1. 데이터 프라이버시 : 기업은 매우 민감한 정보를 다룰 때가 많은데 상용 api를 쓴다는 건 데이터를 외부 서버로 전송한다는 뜻임. 엄격한 데이터 프라이버시 정책으로 조직 외부에 데이터를 전송할 수 없는 기업은 외부 api 사용 불가능
        2. 데이터 계보와 저작권: ai 관련 지적재산권법이 명확해질떄까지는 오픈소스 모델을 쓰거나 독점 모델(내부에서 직접 개발한 모델)을 선택하거나 아니면 둘다 안쓰거나 하는 중 > 기존의 저작권법은 인간의 창작물을 보호하는 것을 전제로 함. 근데 ai가 만들어 낸 것들 모두 인간의 창작물이 아니므로 그 결과물 때문에 저작권 침해 소송이 걸렸을 때 누가 책임을 져야하는지 법적으로 정해지지 않은 상태임, 법이 불확실하기 때문에 소송 위험을 최소화하는 방향으로 움직임 그래서 보수적인 선택을 하는 것. 
        </aside>
        
    - **문제 10 :** 모델 선택 시 공개 벤치마크(Public Benchmarks)를 신뢰할 수 없는 주요 이유 두 가지를 설명하십시오.
        
        <aside>
        💡
        
        1. 벤치마크 평가 시 컴퓨팅 자원이 많이 필요로 하기 때문에 평가 시 모든 벤치마크 성능을 확인하는 데 제약이 있다. 따라서 공개 벤치마크로는 파운데이션 모델의 광범위한 능력과 취약점을 모두 파악하는 데 한계가 있다.
        2. 벤치마크 선정의 어려움 - 모델마다 서로 다른 다양한 벤치마크 평가 결과가 있다. 개발자는 벤치마크를 매우 신중하게 선택하지만 현실적으로 모델마다 서로 다른 벤치마크 평가 결과가 존재한다. 사용자 입장에서는 다양한 기준으로 모델을 서로 비교대조할 수 있는지 명확하게 파악하기 어려운 문제가 있다.
        </aside>
        
    - **문제 11 :** 공개 벤치마크의 데이터 오염(Data Contamination)을 감지하는 두 가지 기술적 방법(N-gram 중복을 넘어)을 설명하십시오.
        
        <aside>
        💡
        
        1. n-gram 중복
        
        : 모델이 학습한 train set에 test set의 하나의 샘플의 13개 토큰 이상 동일한 시퀀스가 있는 경우, 데이터 리키지가 발생한 것으로 간주된다.
        
        1. Perplexity
        
        : 모델이 특정 test set 샘플에 대해 퍼플렉서티가 매우 낮다면 모델은 학습 과정에서 해당 샘플을 이미 학습했을 확률이 매우 높다고 생각할 수 있다.
        
        </aside>
        
    - **문제 12 :** 평가 파이프라인 설계의 첫 번째 단계인 시스템의 모든 구성 요소 평가에서, 턴 기반 평가(Turn-based Evaluation)와 태스크 기반 평가(Task-based Evaluation)가 서로 어떻게 다르며, 사용자 관점에서 더 중요한 평가는 무엇입니까?
        
        <aside>
        💡
        
         턴 기반 평가는 어플리케이션의 턴별 출력물의 품질을 평가하는 것이다. 예를 들면 RAG 어플리케이션을 개발하는데 1) pdf파일에서 마크다운 형식으로 표(table) 데이터를 잘 추출했는지, 2) 청킹 결과 토큰 개수에 일관성이 있는지, 3) retrieval 성능이 양호한지, etc 이와같이 세부 과정별로 나온 결과물의 품질을 평가한다. 
        
         반면에 태스크 기반 평가(작업 기반 평가)는 어플리케이션이 특정 과제를 완수했는지에 대해 평가한다(ex- 클로드가 코드 오류를 몇번의 시도만에 해결했는지). 따라서 서비스를 이용하는 사용자 관점에서는 작업 기반 평가가 더 직관적이고 중요하다고 할 수 있다.
        
        </aside>
        
    - **문제 13 :** 평가 파이프라인 설계의 평가 가이드라인 작성 단계에서, 명확한 채점 기준표(Scoring Rubrics)를 작성하고 예시를 포함하는 것이 가장 중요한 이유는 무엇입니까?
        
        <aside>
        💡
        
        </aside>
        
    - **문제 14 :** 평가 파이프라인에서 데이터 슬라이싱(Data Slicing)을 수행하여 심슨의 역설(Simpson’s paradox)을 피해야 하는 이유를 설명하십시오.
        
        <aside>
        💡
        
        - 데이터를 전체로만 묶어서 평가할 경우, 각 그룹의 샘플 크기 불균형으로 인해 심슨의 역설이 발생할 수 있음
        - 세부 그룹별로 보면 모델 B가 우수한데, 전체 평균으로는 모델 A가 더 우수한 것처럼 결과가 역전되는 현상
        - 따라서 데이터 슬라이싱을 통해 데이터를 세부 하위 그룹으로 쪼개서 평가함으로써, 특정 그룹에서의 성능 저하를 감지하고 모든 경우에 실제로 우수한 모델을 선택해야 함
        </aside>
        
    - **문제 15 :** 시스템 평가 시 A/B 테스팅이 필요한 이유를 비즈니스 목표와의 관계 측면에서 설명하십시오.
        
        <aside>
        💡
        
        - 비즈니스 목표(예: 구매율 증가)는 AI 모델의 성능뿐만 아니라 프로모션, 신제품 출시 등 외부 요인의 영향도 많이 받음
        - 단순히 지표가 올랐다고 해서 모델 성능이 좋다고 단정할 수 없음
        - A/B 테스팅은 사용자 절반에게는 기존 시스템, 나머지에는 새 모델을 노출하여 외부 변수를 동일하게 통제함. 이를 통해 비즈니스 성과가 순수하게 AI 모델 덕분인지 인과관계를 정확히 평가할 수 있음
        </aside>
        
    - **문제 16 :** OpenAI가 통계적 유의성(95% 신뢰도)을 위해 제시한 평가 샘플 크기 추정치에 대한 경험적 규칙(rule of thumb)을 설명하십시오.
        
        <aside>
        💡
        
        </aside>
        
    
    ---
    
    ## 📝 예시 답안
    
    **답안 1 :** MCQs는 검증 및 재현이 용이하며, 지식 및 추론 능력을 평가하는 데 적합하고, 무작위 기준선 대비 평가가 가능하기 때문에 선호된다.
    
    **답안 2 :** Pass@k는 모델이 생성한 k개의 코드 샘플 중 문제의 모든 테스트를 통과한 문제 비율이다. k가 커질수록 정답을 맞출 기대 확률이 높아지므로 pass@1 < pass@3 < pass@10 형태로 증가한다.
    
    **답안 3 :** LLM의 생성 성능이 향상되어 텍스트가 인간과 거의 구분되지 않기 때문에 유창성과 일관성의 중요성이 낮아졌다. 다만 약한 모델이나 저자원 언어에서는 여전히 유용하다.
    
    **답안 4 :** 지역 사실적 일관성은 출력이 **제공된 컨텍스트 내부의 근거**를 갖는지 평가한다. 글로벌 사실적 일관성은 출력이 **외부 공개 지식(Open Knowledge)**과 부합하는지 평가한다.
    
    **답안 5 :** SelfCheckGPT는 하나의 질문에 대해 여러 응답을 생성해 서로 불일치하는지를 분석하여 환각을 추정한다. SAFE는 응답을 문장 단위로 분해하여 검색으로 사실을 확인하고, AI가 문장이 검색 결과와 일치하는지 판단한다.
    
    **답안 6 :** 정치·종교적 편향은 모델이 특정 이념을 지지하는 방식으로 출력하도록 유도할 수 있다. 예: GPT-4는 더 좌파적·자유주의적, Llama는 더 권위주의적 경향이 있다는 연구 결과가 있다.
    
    **답안 7 :** IFEval은 길이·키워드·JSON 형식·불릿 개수 등 자동 검증 가능한 25가지 유형의 명령어를 모델이 정확히 따르는지 측정해 점수를 산출한다.
    
    **답안 8 :** 모델이 아무리 고품질이어도 지연 시간 또는 비용이 과도하면 실제 서비스에서 활용 가치가 떨어진다. 따라서 비용·속도 조건이 좋은 경우 낮은 품질 모델을 선택하는 사례도 있다.
    
    **답안 9 :** ① 데이터 프라이버시 보호
    
           ② API 제공업체의 약관·속도 제한에 종속되지 않고 모델을 자유롭게 수정·제어·투명
    
                하게 운영하기 위해
    
    **답안 10 :** ① 데이터 오염 가능성으로 인해 점수가 실제 능력을 반영하지 않을 수 있다.
    
             ② 벤치마크 선택 및 점수 집계 과정이 불투명한 경우가 많아 신뢰하기 어렵다.
    
    **답안 11 :**  ① N-gram 중복 분석 — 평가 샘플의 13-토큰 연속 시퀀스가 훈련 데이터에 
    
                      존재하면 오염 가능성을 의심한다.
    
             ② 퍼플렉시티 분석 — 모델이 평가 데이터에서 비정상적으로 낮은 퍼플렉시티를 
    
                 보이면 사전 노출을 의심할 수 있다.
    
    **답안 12 :** 턴 기반 평가는 메시지 단위 품질을 평가하고, 태스크 기반 평가는 전체 대화를 통해 사용자의 목표가 달성되었는지를 평가한다. 사용자 관점에서는 태스크 기반 평가가 더 중요하다.
    
    **답안 13 :**  가이드라인이 모호하면 점수도 모호해져 신뢰할 수 없는 평가가 된다. 좋은 응답의 정의를 예시와 함께 명확히 규정함으로써 평가 일관성을 확보할 수 있다.
    
    **답안 14 :** 데이터를 하위 그룹으로 나누어 성능을 평가하면 특정 입력 그룹에서의 성능 편차를 파악할 수 있고, 심슨의 역설(집계 성능과 그룹별 성능이 반대로 나타나는 현상)을 방지할 수 있다.
    
    **답안 15 :** 변경된 시스템이 비즈니스 지표 향상을 **직접 야기했는지** 확인하기 위해 A/B 테스팅이 필요하다. 외부 요인(예: 프로모션, 시즌 효과)과 분리하여 인과 관계를 측정할 수 있다.
    
    **답안 16 :** 점수 차이가 3배 줄어들수록 필요한 평가 샘플 수는 10배 증가한다는 경험적 규칙이 존재한다.
    
- 5단원
    
    ### 💡 문제 출제
    
    - 1. 프롬프트 엔지니어링이 모델 적응 기술로서 파인튜닝(finetuning)과 비교하여 갖는 근본적인 차이점은 무엇이며, 이 기술이 갖는 장점은 무엇입니까?
        
        (1) 프롬프트 엔지니어링
        
        - 모델이 원하는 결과를 생성하도록 지시를 정교하게 다듬는, 가장 쉽고 일반적인 모델 조정 기법
        - 모델의 가중치를 변경하지 않고 모델의 응답을 조정(새로운 지시를 줄 뿐 모델의 뇌를 건드리지 않음
        - 필요 자원: 잘 만든 프롬프트. 따라서 자원이 많이 필요하지 않고 사용하기에 쉽다.
        
        (2) 파인튜닝
        
        - 모델의 뇌를 업데이트함, 가중치가 미세하게 조정되어서 모델의 지식과 행동 양식이 영구적으로 바뀜
        - 필요 자원: 고성능의 GPU(비용), 시간
    - 2. 효과적인 프롬프트를 구성하는 세 가지 주요 구성 요소를 설명하고, 이 중 '작업 설명(Task description)'에 포함되어야 하는 구체적인 내용을 상세히 설명하십시오.
        
        참고: https://do-gang.tistory.com/entry/%ED%94%84%EB%A1%AC%ED%94%84%ED%8A%B8-%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81-%EA%B8%B0%EB%B2%95-%EC%A0%95%EB%A6%AC-26%EA%B0%80%EC%A7%80
        
        (1) 작업 설명: 모델이 무엇을 해야하는지, 어떤 역할을 맡아야 하는지를 정의하는 부분
        
        - 역할 부여: 응답할 때 누구처럼 말해야 하는지를 정의 (ex: 선생님처럼)
        - 명확한 목표/작업 정의: 모델이 수행해야 할 주된 행동을 간결하게 정의 (ex: 주어진 문장을 500자 이내로 요약해)
        - 출력 형식/제약 조건: 결과가 어떤 형태여야 하는지 지정 (ex: 답변은 한국어로 작성)
        - 맥락/배경 정보: 이 작업이 왜 필요한지, 어떤 상황에서 사용될 것인지에 대한 배경 지식 제공 (ex: 수업 자료로 사용될 예정)
        - 주의사항: 모델이 반드시 지켜야할 규칙을 긍정적인 단어로 표현, 부정적인 지시보다 긍정적인 지시가 모델의 행동에 더 직접적인 영향을 줌 (ex: 항상 친근한 말투를 사용하세요)
        
        (2) 작업 수행 방법에 대한 예시: 모델이 어떤 식으로 답변해야 하는지에 대한 예시를 제공하는 부분 
        
        (3) 작업: 모델이 수행해야 할 구체적인 작업, 응답할 질의나 요약할 책 등이 이에 해당
        
    - 3. 모델의 '로버스트니스(robustness)'가 프롬프트 엔지니어링에 미치는 영향에 대해 설명하고, 강력한 모델을 사용하는 것이 이와 관련하여 어떤 이점을 제공하는지 두 가지 측면에서 논의하십시오.
        - 모델의 Robustness: 모델이 예상치 못한 다양한 환경/입력 조건에서도 일관되고 안정적인 성능을 유지하는 능력
        
        >> 모델의 Robustness 수준이 프롬프트 엔지니어링의 필요성과 효율성을 결정(ex: 로버스트니스가 낮을수록 프롬프트가 약간만 바껴도 출력이 완전히 달라짐 > 더 많은 시행착오가 필요, 엔지니어링 노력이 많이 듬)
        
        - 이점 1: 시행착오 감소, 강력한 모델은 프롬프트의 미묘한 차이에도 결과가 크게 바뀌지 않는다
        - 이점 2: 강한 지시수행 능력, 강력한 모델은 지시 수행 능력 자체도 우수해서 복잡한 프롬프트도 한번에 이해하고 따를 가능성이 높음.
    - 4. 인컨텍스트 러닝(In-Context Learning, ICL)이란 무엇이며, 이것이 모델의 행동 학습에 있어 기존의 학습 방식(예: 파인튜닝)과 어떻게 근본적으로 다른지 설명하십시오.
        - (답안) 인컨텍스트 러닝은 지속적으로 모델에게 프롬프트를 이용하여 새로운 지식을 부여하는 방법. 기존 베이스 모델의 학습(Pretraining)이나 파인튜닝은 파라미터를 변하게하지만 ICL은 프롬프트를 이용하기 때문에 파라미터를 업데이트 하지 않음.
    - 5. 제로샷 러닝(zero-shot learning)과 달리 퓨샷 러닝(few-shot learning)이 도메인 특정 사용 사례에서 여전히 큰 이점을 가질 수 있는 이유를 구체적인 예시를 들어 설명하십시오.
        - 제로샷러닝은 특정 결과물에 대한 예시를 보여주지 않기 때문에 LLM이 알아서 생성하게됨. 하지만 특정 사례에서는 구조화된 결과물이 요구됨. 예를 들어 법률에서 판례를 검토한다면 판례번호, 사례, 결과 등에 대한 구조화된 결과물을 보여주는 것이 변호사가 지난 사례를 검토하는데 도움이 되는 것임
    - 6. 프롬프트 구조화에서 시스템 프롬프트(System Prompt)를 사용하는 것이 사용자 프롬프트(User Prompt)를 사용하는 것보다 모델 성능을 향상시키는 두 가지 잠재적 요인을 설명하십시오.
        - 시스템 프롬프트는 사용자 프롬프트보다 더 우선시되는 규칙. 특정 업무를 위한 LLM의 역할, 절차 등을 명시해두면 재사용성이 좋아지며 상황에 맞는 사용자 프롬프트만 넣어주어 모델이 더 잘 대답할 수 있게 됨.
        - 또한 시스템 프롬프트는 먼저 LLM에게 주입되며(순차적) 모델이 먼저 인지할 수 도록 하여 성능향상을 기대할 수 있음. LLM은 시스템 프롬프트에 더 주목하도록 학습되어 있을 수 있어 성능 향상을 역시 기대할 수 있음
    - 7. '건초 더미 속의 바늘(Needle in a Haystack, NIAH)' 테스트를 통해 밝혀진 컨텍스트 효율성(Context Efficiency)의 특징을 설명하고, 이 결과가 긴 프롬프트를 작성할 때 어떤 실질적인 시사점을 제공하는지 서술하십시오.
        
        <aside>
        💡
        
        테스트의 목표는 AI에게 아주 긴 글(건초 더미)을 준 다음, 그 속에 숨겨진 단 하나의 중요한 정보(바늘)를 찾아내서 정확하게 대답하게 하는 것
        
        - 중요 정보의 위치 배치 :AI는 긴 정보의 맨 앞과 맨 뒤에 있는 바늘은 잘 찾지만,    중간에 있는 바늘은 놓치는 경향이 있다. (U자형 성능 곡선)
        
        → 가장 중요한 지시나 단서는 프롬프트의 맨 앞 또는 맨 끝에 배치해야 합니다.
        
        - 컨텍스트 길이 효율성 평가:전체 정보(건초 더미)의 길이가 너무 길어지면, 전반적으로 핵심 정보를 찾는 능력이 떨어집니다.프롬프트는 꼭 필요한 내용으로만 구성하여 길이를 적절하게 유지해야함.
        </aside>
        
    - 8. 프롬프트 엔지니어링 모범 사례 중 하나인 '페르소나(persona) 채택'의 중요성을 설명하고, 페르소나 채택이 모델의 응답에 미치는 긍정적인 변화를 예시와 함께 서술하십시오.
        
        <aside>
        💡
        
        - 페르소나 채택은 모델이 응답을 생성할 때 사용해야 하는 관점을 이해하도록 도와 이를 통해 모델은 올바른 행동 지침을 따르고 원하는 관점을 유지하도록 유도.
        - 예시: 모델에게 '초등학교1학년 교사' 페르소나를 요청하면, 모델은 해당 연령대의 학생이 작성한 에세이의 기대치에 맞춰 평가를 수행합니다.
            
            페르소나 없이 일반적인 기준으로 평가할 때 5점 만점에 2점을 받을 수 있는 에세이가, 1학년 교사 페르소나를 채택할 경우 노력이나 순진한 관점을 반영하여 4점을 받을 수 있음
            
            결론적으로, 페르소나 채택은 모델이 단순히 사실을 나열하는 것을 넘어 올바른 관점을 적용하도록 유도하여 원하는 결과물을 얻는 데 도움
            
        </aside>
        
    - 9. 모델에게 충분한 컨텍스트(Context)를 제공하는 것이 응답 품질 측면에서 중요한 이유 두 가지를 상세히 설명하십시오.
        
        <aside>
        💡
        
        1. 전반적인 응답 성능 및 품질 향상
        - 모델은 제공된 관련 정보를 활용하여 더 정확하고 유용한 출력을 생성할 수 있음.
            
            →모델의 성능을 향상
            
        1. 환각(Hallucination) 완화 및 신뢰성 유지
        - 모델에게 필요한 정보가 제공되지 않으면, 모델은 내부 지식 의존→ 신뢰x→ 사실과 다른 환각으로 이어질 수 o
        - 컨텍스트를 제공→ 관련성 높고 정확한 외부 정보를 사용하여 응답을 구성하도록 유도하여 응답의 사실적 일관성과 신뢰성을 높일 수 있음
        </aside>
        
    - 10. 프롬프트 분해(Prompt Decomposition)의 개념을 정의하고, 이 기법이 성능 향상 외에 모니터링, 디버깅, 병렬화 측면에서 애플리케이션 개발에 제공하는 이점을 각각 설명하십시오.
        - 프롬프트 분해
        
        : 복잡한 작업에 대해 하나의 프롬프트를 적용하지 않고, 작업을 하위 작업으로 분류한 뒤 각 sub-task에 대해 고유한 프롬프트를 적용하는 것.
        
        1. 모니터링 - 하위 작업마다 중간 결과물을 확인할 수 있기 때문에 세부적인 모니터링이 가능해진다.
        2. 디버깅 - 문제가 발생하는 특정 sub-task에 대해서만 선택적으로 디버깅을 할 수 있다.
        3. 병렬화 - 각각의 sub-task를 병렬로 실행할 수 있는 경우 실행 시간을 단축할 수 있다.
    - 11. CoT(Chain-of-Thought) 프롬프트 기법의 기본 원리를 설명하고, 모델에게 '생각할 시간'을 주기 위해 사용할 수 있는 가장 간단한 두 가지 Zero-shot CoT 구현 방법을 제시하십시오.
        - Chain-of-Thought(CoT)
        
        : LLM에 주어진 과제나 문제를 해결할 때 단계별로 생각하도록 명시하여 문제를 체계적이게 접근할 수 있도록 유도하는 프롬프팅 기법
        
        **Zero-shot CoT 구현 방법 1 -** ‘단계별로 설명해줘.’
        
        ```python
        Window VS Code 환경에서 Gemini CLI를 설치하는 방법에 대해 초보자에게 설명하듯이 생략없이 **차근차근 단계별로 설명해줘.**
        ```
        
        **Zero-shot CoT 구현 방법 2 -** ‘결정 과정에 대해 설명해줘.’
        
        ```python
        브로드컴 조정이 끝난 뒤 투자를 검토하고 있어. 사업 개요, 경쟁사 현황, 경쟁력, 재무상황, 투자 상황, 미래 전략, 애널리스트 목표가에 대해 분석해서 BUY/SELL 중 하나의 의견을 **결정하는 과정을 차근차근 논리적에게 제시**해줘.
        ```
        
    - 12. 애플리케이션 개발자가 방어해야 할 세 가지 주요 프롬프트 공격 유형을 나열하고, 각 공격이 애플리케이션의 보안에 미치는 주된 위험 또는 목표를 설명하십시오.
        - 주요 프롬프트 공격 유형
        
        ```python
        **1. 프롬프트 추출** - 애플리케이션의 시스템 프롬프트를 추출하여 이를 악용하려 하는 것 -> 애플리케이션 복제
        
        **2. 탈옥과 프롬프트 주입** - 모델이 나쁜 행동을 하도록 유도하는 것 -> 도구를 악용하도록 유도, 불법적 행위에 대한 정보 주입
        
        **3.** **정보 추출** - 모델의 학습 데이터나 컨텍스트에 사용된 정보를 노출하도록 만드는 것 -> 개인 정보 추출
        ```
        
        - 프롬프트 공격이 어플리케이션에 끼치는 위험
        
        ```python
        **1. 원격 코드 또는 도구 실행** - 어플리케이션이 강력한 tool을 사용하는 경우, 악의적인 의도를 가지고 어플리케이션으로 하여금 도구를 악용하도록 유도할 수 있다.
        
        **2.** **데이터 유출** - 악의적으로 시스템 또는 이용자 개인 정보를 추출할 수 있다.
        
        **3.** **사회적 해악** - 모델이 사회적으로 위험하거나 불법적인 활동에 대한 지식이나 튜토리얼을 얻게 할 수 있다.
        
        **4. 잘못된 정보** - 공격자가 자신의 편향이 담긴 정보를 모델이 출력하도록 유도할 수 있다.
        
        **5. 서비스 중단 및 전복** - 모델이 악의적인 답변이나 행동을 취하도록 유도하여 서비스 중단을 일으킬 수 있다.
        
        **6. 브랜드 위험** - 유해하고 편향 있는 답변을 GPT나 Gemini가 하면 OpenAI와 Google 같은 회사에 PR 위기(Public Relations Crisis)를 발생시킬 수 있다.
        ```
        
    - 13. 프롬프트 엔지니어링 자동화 도구 중 하나인 Promptbreeder가 프롬프트 최적화를 달성하기 위해 사용하는 작동 방식(전략)을 단계별로 설명하십시오.
        
        Promptbreeder는 진화 전략을 사용하여 프롬프트를 선택적으로 육성하는 방식
        
        1. 초기 프롬프트 설정:  사용자가 최적화하고자 하는 초기 프롬프트에서 시작
        2. 변이 생성: ai 모델을 사용하여 초기 프롬프트의 변형을 생성. 단순히 무작위로 바꾸는 것이 아닌 프롬프트를 어떻게 수정할지 지시하는 변이 생성 프롬프트에 따라 변경
        3. 평가 및 선택: 생성된 변형 프롬프트 중 가장 결과가 좋은 변형을 선택
        4. 반복: 선택된 프롬프트를 다시 새 기준점으로 삼아 위 과정을 반복
    - 14. 프롬프트를 코드와 분리하여 관리하는 것이 테스트 용이성(Testing) 및 협업(Collaboration) 측면에서 각각 어떤 이점을 제공하는지 설명하십시오.
        - 테스트 용이성: 코드와 프롬프트를 독립적으로 테스트. 코드는 그대로 둔 채 프롬프트를 교체해가며 성능을 테스트 가능
        - 협업: 개발자가 아니어도 코드에 신경쓰지 않고 프롬프트 작성이 가능함(기획자 등). 협업이 용이
    - 15. 개발팀이 프롬프트를 Git 저장소에 코드와 함께 버전 관리하는 대신 별도의 '프롬프트 카탈로그(prompt catalog)'를 사용하는 것이 유리한 이유를 설명하십시오.
        1. 버전 관리 용이: 여러 애플리케이션이 동일한 프롬프트를 공유할 경우 git에서 해당 프롬프트가 수정될 경우 모든 애플리케이션이 새 프롬프트를 사용해야 함. 프롬프트 카탈로그로 각 프롬프트의 버전을 관리하여 애플리케이션별로 다른 버전의 프롬프트를 사용할 수 있음
        2. 메타데이터 및 검색 기능: 카탈로그는 프롬프트에 메타데이터(모델 엔트포인트, 온도, top-p)를 같이 제공하고 어떤 애플리케이션이 특정 프롬프트에 의존하는지 추적이 가능
    - 16. 프롬프트 공격에 대한 방어 전략 중, 모델 수준 방어(Model-level defense)에서 OpenAI가 제시한 'Instruction Hierarchy(지침 계층 구조)'가 간접 프롬프트 주입 공격을 완화하는 원리를 설명하십시오.
        - 각 메시지에 대한 권한을 저장하고, 프롬프트 실행 시 메시지의 권한의 상충된다면 더 높은 등급의 지시를 따르는 방법
        
    
    ### 📝 예시 답안
    
    - 1. 프롬프트 엔지니어링이 모델 적응 기술로서 파인튜닝(finetuning)과 비교하여 갖는 근본적인 차이점은 무엇이며, 이 기술이 갖는 장점은 무엇입니까?
        
        프롬프트 엔지니어링은 모델이 원하는 결과를 생성하도록 지침(instruction)을 만드는 과정을 의미합니다. 프롬프트 엔지니어링은 모델의 **가중치(weights)를 변경하지 않고** 모델의 행동을 유도한다는 점에서 파인튜닝과 근본적으로 다릅니다. 파인튜닝은 사전 학습, 후속 학습 및 미세 조정 과정에서 모델 가중치를 업데이트하는 방식을 포함합니다. 프롬프트 엔지니어링의 주요 장점은 재원을 덜 소모하는(less resource-intensive) 기술이며, 기초 모델(foundation models)의 강력한 기본 능력 덕분에 많은 애플리케이션을 프롬프트 엔지니어링만으로 성공적으로 조정할 수 있다는 점입니다. 이는 가장 쉽고 일반적인 모델 적응 기술로 간주됩니다.
        
    - 2. 효과적인 프롬프트를 구성하는 세 가지 주요 구성 요소를 설명하고, 이 중 '작업 설명(Task description)'에 포함되어야 하는 구체적인 내용을 상세히 설명하십시오.
        
        프롬프트는 일반적으로 다음 세 가지 구성 요소 중 하나 이상으로 구성됩니다:
        
        1. **작업 설명 (Task description):** 모델이 수행하기를 원하는 작업, 모델이 맡아야 할 역할(role), 그리고 원하는 출력 형식(output format)을 포함합니다.
        
        2. **이 작업을 수행하는 방법에 대한 예시 (Example(s) of how to do this task):** 예를 들어, 텍스트의 유해성(toxicity)을 감지하도록 요청하는 경우, 유해한 텍스트와 그렇지 않은 텍스트의 몇 가지 예시를 제공할 수 있습니다.
        
        3. **구체적인 작업 (The task):** 모델이 수행하기를 원하는 실제 작업, 예를 들어 답변해야 할 질문이나 요약해야 할 책 등을 포함합니다.
        
    - 3. 모델의 '로버스트니스(robustness)'가 프롬프트 엔지니어링에 미치는 영향에 대해 설명하고, 강력한 모델을 사용하는 것이 이와 관련하여 어떤 이점을 제공하는지 두 가지 측면에서 논의하십시오.
        
        모델의 로버스트니스는 프롬프트가 약간 변경될 때(예: "5" 대신 "five"를 쓰거나, 새로운 줄을 추가하거나, 대소문자를 변경하는 등) 모델의 응답이 극적으로 달라지는 정도에 따라 결정됩니다. 모델이 덜 로버스트할수록, 원하는 결과를 얻기 위해 더 많은 조정 작업(fiddling)이 필요합니다. 강력한 모델은 일반적으로 더 높은 지능을 가지므로 "5"와 "five"가 같은 의미임을 이해할 가능성이 높고, 결과적으로 더 로버스트합니다. 따라서 강력한 모델을 사용하면 **두통을 줄이고(save you headaches)**, 프롬프트 조정에 **낭비되는 시간을 줄일(reduce time wasted on fiddling)** 수 있습니다.
        
    - 4. 인컨텍스트 러닝(In-Context Learning, ICL)이란 무엇이며, 이것이 모델의 행동 학습에 있어 기존의 학습 방식(예: 파인튜닝)과 어떻게 근본적으로 다른지 설명하십시오.
        
        인컨텍스트 러닝은 프롬프트를 통해 모델에게 수행할 작업을 가르치는 것을 말합니다. 기존의 모델 학습 방식(사전 학습, 후속 학습, 파인튜닝 등)은 원하는 행동을 배우기 위해 모델 가중치를 업데이트하는 것을 포함합니다. 그러나 ICL은 모델이 **가중치 업데이트 없이** 프롬프트 내의 예시나 컨텍스트로부터 원하는 행동을 학습할 수 있음을 보여주었습니다. 이로 인해 ICL은 모델이 지속적으로 새로운 정보를 통합하여 결정을 내릴 수 있게 하며, 모델이 구식(outdated)이 되는 것을 방지하는 **지속적 학습(continual learning)의 한 형태**가 됩니다.
        
    - 5. 제로샷 러닝(zero-shot learning)과 달리 퓨샷 러닝(few-shot learning)이 도메인 특정 사용 사례에서 여전히 큰 이점을 가질 수 있는 이유를 구체적인 예시를 들어 설명하십시오.
        
        퓨샷 러닝(프롬프트에 예시를 제공하는 것)은 강력한 모델(예: GPT-4)의 경우 제로샷 러닝 대비 개선 효과가 제한적일 수 있지만, 도메인 특정 사용 사례에서는 여전히 큰 차이를 만들 수 있습니다. 그 이유는 모델이 학습 데이터에서 해당 도메인에 특화된 예시를 충분히 보지 못했을 수 있기 때문입니다. 예를 들어, 만약 모델이 Ibis 데이터프레임 API의 예시를 학습 데이터에서 많이 보지 못했다면, 프롬프트에 Ibis 예시를 포함시키는 것이 모델의 관련 쿼리 처리 능력에 **큰 차이(a big difference)**를 만들 수 있습니다.
        
    - 6. 프롬프트 구조화에서 시스템 프롬프트(System Prompt)를 사용하는 것이 사용자 프롬프트(User Prompt)를 사용하는 것보다 모델 성능을 향상시키는 두 가지 잠재적 요인을 설명하십시오.
        
        시스템 프롬프트와 사용자 프롬프트는 결국 단일 최종 프롬프트로 결합되어 모델에 입력되지만, 시스템 프롬프트가 성능을 높이는 두 가지 잠재적 요인은 다음과 같습니다:
        
        1. **순서 우선 처리(Processing Order):** 시스템 프롬프트는 최종 프롬프트에서 **먼저 나오며**, 모델은 먼저 나오는 지침을 처리하는 데 더 능숙할 수 있습니다.
        
        2. **후학습 우선순위(Post-Training Priority):** 모델이 시스템 프롬프트에 더 많은 주의를 기울이도록 후학습(post-trained)되었을 수 있습니다. (OpenAI의 연구는 LLM이 특권 지침(privileged instructions)의 우선순위를 정하도록 훈련하는 것이 프롬프트 공격을 완화하는 데도 도움이 된다고 제안합니다).
        
    - 7. '건초 더미 속의 바늘(Needle in a Haystack, NIAH)' 테스트를 통해 밝혀진 컨텍스트 효율성(Context Efficiency)의 특징을 설명하고, 이 결과가 긴 프롬프트를 작성할 때 어떤 실질적인 시사점을 제공하는지 서술하십시오.
        
        NIAH 테스트는 프롬프트의 **시작(beginning)과 끝(end)** 부분에 삽입된 정보가 프롬프트의 **중간(middle)** 부분에 삽입된 정보보다 모델이 찾는 데 훨씬 더 능숙하다는 것을 보여주었습니다. 이는 프롬프트의 모든 부분이 동일하게 처리되지 않음을 시사합니다. 이 결과는 긴 프롬프트를 작성할 때 중요한 지침이나 핵심 정보를 모델이 쉽게 접근하고 이해할 수 있도록 프롬프트의 **가장 앞이나 뒤**에 배치하는 것이 유리함을 시사합니다.
        
    - 8. 프롬프트 엔지니어링 모범 사례 중 하나인 '페르소나(persona) 채택'의 중요성을 설명하고, 페르소나 채택이 모델의 응답에 미치는 긍정적인 변화를 예시와 함께 서술하십시오.
        
        모델에게 페르소나를 채택하도록 요청하는 것은 모델이 응답을 생성하는 데 사용해야 하는 **관점(perspective)**을 이해하는 데 도움이 되기 때문에 중요합니다. 예를 들어, "나는 병아리가 좋다. 병아리는 솜털이 많고 맛있는 알을 낳는다"는 에세이가 있을 때, 일반적인 모델은 5점 만점에 2점을 줄 수 있습니다. 그러나 모델에게 **'1학년 교사(first-grade teacher)'의 페르소나**를 채택하도록 요청하면, 모델은 그 관점을 사용하여 해당 에세이에 4점을 줄 수 있으며, 이는 모델이 쿼리에 응답하기 위해 올바른 관점을 사용하도록 돕습니다,.
        
    - 9. 모델에게 충분한 컨텍스트(Context)를 제공하는 것이 응답 품질 측면에서 중요한 이유 두 가지를 상세히 설명하십시오.
        
        충분한 컨텍스트를 제공하는 것이 중요한 이유는 다음과 같습니다:
        
        1. **응답 품질 향상:** 참고 자료가 시험에서 학생들의 성과를 높이는 것처럼, 충분한 컨텍스트는 모델이 **더 나은 응답(better responses)**을 생성하도록 돕습니다.
        
        2. **환각(Hallucinations) 완화:** 컨텍스트는 **환각을 완화**할 수 있습니다. 모델에게 필요한 정보가 제공되지 않으면, 모델은 신뢰할 수 없는 내부 지식에 의존하게 되어 환각을 일으킬 수 있기 때문에, 외부 컨텍스트 제공이 이를 방지하는 데 필수적입니다.
        
    - 10. 프롬프트 분해(Prompt Decomposition)의 개념을 정의하고, 이 기법이 성능 향상 외에 모니터링, 디버깅, 병렬화 측면에서 애플리케이션 개발에 제공하는 이점을 각각 설명하십시오.
        
        프롬프트 분해는 복잡한 작업을 여러 단계가 필요한 더 간단한 **하위 작업(subtasks)으로 나누는** 것을 의미하며, 전체 작업에 대한 하나의 거대한 프롬프트 대신 각 하위 작업이 자체 프롬프트를 가지게 되며, 이들은 순서대로 연결됩니다. 성능 향상 외의 이점은 다음과 같습니다:
        
        - **모니터링 (Monitoring):** 최종 출력뿐만 아니라 **모든 중간 출력**을 모니터링할 수 있습니다.
        - **디버깅 (Debugging):** 문제가 발생하는 단계를 격리하고, 다른 단계의 모델 행동을 변경하지 않고도 **독립적으로 수정**할 수 있습니다.
        - **병렬화 (Parallelization):** 독립적인 단계들을 **병렬로 실행**하여 시간을 절약할 수 있습니다. 예를 들어, 세 가지 다른 독서 수준(1학년, 8학년, 대학 신입생)에 대한 세 가지 스토리 버전을 동시에 생성할 수 있습니다.
    - 11. CoT(Chain-of-Thought) 프롬프트 기법의 기본 원리를 설명하고, 모델에게 '생각할 시간'을 주기 위해 사용할 수 있는 가장 간단한 두 가지 Zero-shot CoT 구현 방법을 제시하십시오.
        
        CoT(Chain-of-Thought) 프롬프트 기법의 기본 원리는 모델에게 **단계별로 생각(think step by step)**하도록 명시적으로 요청하여 문제 해결에 보다 체계적인 접근 방식을 유도하는 것입니다,. 이는 모델이 질문에 대해 "생각할 시간"을 갖도록 장려합니다. 가장 간단한 두 가지 Zero-shot CoT 구현 방법은 다음과 같습니다,:
        
        1. 프롬프트에 "**단계별로 생각하세요(think step by step)**"를 추가합니다.
        
        2. 프롬프트에 "**결정을 설명하세요(explain your decision)**"를 추가합니다.
        
    - 12. 애플리케이션 개발자가 방어해야 할 세 가지 주요 프롬프트 공격 유형을 나열하고, 각 공격이 애플리케이션의 보안에 미치는 주된 위험 또는 목표를 설명하십시오.
        
        개발자가 방어해야 할 세 가지 주요 프롬프트 공격 유형과 그 목표는 다음과 같습니다:
        
        1. **프롬프트 추출 (Prompt extraction):** 시스템 프롬프트를 포함하여 애플리케이션의 프롬프트를 추출하는 것을 목표로 하며, 이는 애플리케이션을 복제하거나 악용하는 데 사용될 수 있습니다,.
        
        2. **탈옥 및 프롬프트 주입 (Jailbreaking and prompt injection):** 모델이 부적절한 행동(bad things)을 하도록 유도하는 것을 목표로 합니다.
        
        3. **정보 추출 (Information extraction):** 모델의 학습 데이터(training data) 또는 컨텍스트에 사용된 사적인 정보(private information)를 노출시키거나 추출하는 것을 목표로 합니다,.
        
    - 13. 프롬프트 엔지니어링 자동화 도구 중 하나인 Promptbreeder가 프롬프트 최적화를 달성하기 위해 사용하는 작동 방식(전략)을 단계별로 설명하십시오.
        
        DeepMind의 Promptbreeder는 **진화 전략(evolutionary strategy)**을 활용하여 프롬프트를 선택적으로 "육성(breed)"합니다. 작동 방식은 다음과 같습니다:
        
        1. **초기 프롬프트(Initial Prompt) 설정:** 초기 프롬프트에서 시작합니다.
        
        2. **돌연변이 생성(Generate Mutations):** AI 모델을 사용하여 이 프롬프트에 대한 **돌연변이(mutations)**를 생성합니다. 이 과정은 일련의 '돌연변이 프롬프트(mutator prompts)'에 의해 유도됩니다.
        
        3. **선택 및 반복(Selection and Iteration):** 가장 유망한 돌연변이(the most promising mutation)를 선택하여, 사용자가 설정한 기준을 만족하는 프롬프트를 찾을 때까지 돌연변이를 계속 생성합니다.
        
    - 14. 프롬프트를 코드와 분리하여 관리하는 것이 테스트 용이성(Testing) 및 협업(Collaboration) 측면에서 각각 어떤 이점을 제공하는지 설명하십시오.
        
        프롬프트를 코드(예: `prompts.py` 파일)와 분리하여 관리하는 것은 여러 이점을 제공합니다,:
        
        - **테스트 용이성 (Testing):** 코드와 프롬프트를 **별도로 테스트**할 수 있습니다. 예를 들어, 코드는 변경하지 않고 다양한 프롬프트와 함께 테스트될 수 있습니다.
        - **협업 (Collaboration):** 이는 주제 전문가(subject matter experts)가 **코드에 방해받지 않고** 프롬프트를 고안하고 개선하는 데 도움을 줄 수 있도록 허용합니다.
    - 15. 개발팀이 프롬프트를 Git 저장소에 코드와 함께 버전 관리하는 대신 별도의 '프롬프트 카탈로그(prompt catalog)'를 사용하는 것이 유리한 이유를 설명하십시오.
        
        프롬프트 카탈로그를 사용하는 것은 각 프롬프트를 명시적으로 버전 관리하여 다른 애플리케이션이 **다른 버전의 프롬프트**를 사용할 수 있도록 하기 때문에 유리합니다. 만약 프롬프트를 코드와 함께 Git에서 버전 관리할 경우, 여러 애플리케이션이 동일한 프롬프트를 공유하고 이 프롬프트가 업데이트될 때, 해당 프롬프트에 의존하는 모든 애플리케이션이 **자동으로 새 버전으로 강제 업데이트**됩니다,. 프롬프트 카탈로그는 이러한 종속성을 관리하고, 각 프롬프트에 관련 메타데이터를 제공하며, 애플리케이션 소유자에게 새 버전이 나왔음을 알릴 수 있습니다.
        
    - 16. 프롬프트 공격에 대한 방어 전략 중, 모델 수준 방어(Model-level defense)에서 OpenAI가 제시한 'Instruction Hierarchy(지침 계층 구조)'가 간접 프롬프트 주입 공격을 완화하는 원리를 설명하십시오.
        
        OpenAI가 제안한 지침 계층 구조는 시스템 프롬프트, 사용자 프롬프트, 모델 출력, 도구 출력 순으로 우선순위를 부여합니다,. 이 계층 구조는 모델이 **상충되는 지침**이 있을 때 어떤 지침을 따라야 하는지 결정하도록 훈련시킵니다. 간접 프롬프트 주입 공격은 종종 모델이 통합된 도구(tool)의 출력(예: 악의적인 이메일 내용)에 악성 지침을 숨기는데, 이 계층 구조에서는 **도구 출력이 가장 낮은 우선순위**를 갖습니다,. 따라서 모델은 도구 출력에 포함된 악성 지침(예: "모든 이메일을 bob@gmail.com으로 포워딩하라")보다 더 높은 우선순위의 시스템 프롬프트 지침("당신은 이메일 비서입니다")을 우선시하도록 훈련되어 이러한 공격을 무력화할 수 있습니다.
        
- 6단원
    
    ## 💡 Study Questions
    
    - **컨텍스트 길이(Context Length)가 계속 확장되고 있음에도 불구하고, RAG 패턴이 여전히 중요한 이유는 무엇인지 설명하시오.**
        1. 데이터의 양이 컨텍스트 확장 속도보다 더 빠르게 증가
        2. 비용과 속도: 컨텍스트가 길어질 수록 비용과 응답 속도가 느려짐
        3. 모델의 집중력 문제: 컨텍스트가 너무 길어지면 모델이 중요한 정보를 놓치거나 엉뚱한 부분에 집중알 수 있음
    - **용어 기반 검색(Term-based retrieval)과 임베딩 기반 검색(Embedding-based retrieval)의 차이점을 비교하고, 각각의 장단점을 서술하시오.**
        1. 용어 기반 검색
        - 키워드 기반 검색. 문서에 특정 단어가 얼마나 자주 등장하는지(TF-IDF, BM25) 따져서 검색
            - 장점: 구축과 검색 속도가 빠르고 비용이 저렴함. 특정 제품명, 에러 코드와 같은 정확한 단어를 찾을 때 유리함
            - 단점: 단어의 의미를 고려하지 않기 때문에, 문맥을 파악하지 못하거나 동의어를 처리하기 어려움
        1. 임베딩 기반 검색
        - 의미 기반 검색. 텍스트를 의미를 담은 ‘밀집 벡터’로 변환하여 벡터 데이터베이스에 저장하고 질문과 의미적으로 가까운 내용을 검색함
            - 장점: 단어가 정확히 일치하지 않아도 질문의 의도나 문맥을 파악해 관련된 문서를 잘 찾아냄.(’트랜스포머’를 검색하면 변압기와 영화를 구분할 수 있음)
            - 단점: 벡터를 생성하고 검색하는 과정에서 비용이 높고 속도가 느려짐. 특수용어와 고유 명사 검색에 약함
    - **TF-IDF 알고리즘의 작동 원리를 설명하고, BM25가 이를 어떻게 개선했는지 기술하시오.**
        1. TF(Term Frequency): 특정 문서에 단어가 얼마나 자주 등장하는지 나타냄. 많이 등장할수록 해당 문서는 그 단어와 연관성이 높음.
        2. IDF(Inverse Document Frequency): 특정 단어가 전체 문서 집합에서 얼마나 희귀한지를 나타냄. ‘the’, 나 ‘and’처럼 모든 문서에 흔하게 등장하는 단어 대신 문서 군 전체에서 드물게 등장하는 단어에 더 높은 가중치를 부여함. 최종 점수는 이 두 값을 곱하여 계산
        
        BM25 (Best matching 25)는 TF-IDF를 개선한 알고리즘으로 가장 큰 차이는 ‘문서 길이 정규화’. 기존 TF-IDF는 문서 길이가 길어지면 단어가 등장할 확률이 자연스럽게 높아짐. BM25는 문서의 길이를 고려하여 점수를 조정해서 단순히 길이가 긴 문서가 무조건 상위 랭크되는 문제를 해결
        
    - **임베딩 기반 검색(Semantic Retrieval)의 전체 워크플로우를 인덱싱(Indexing)과 쿼리(Querying) 단계로 나누어 상세히 설명하시오.**
        
        **1. 인덱싱 :** 데이터를 빠르게 검색할 수 있도록 처리하는 과정
        
        - **데이터 분할:** 문서가 너무 길면 모델의 컨텍스트 제한을 초과할 수 있으므로, 각 문서를 관리 가능한 크기의 청크로 나눔.
        - **임베딩 생성:** **임베딩 모델**을 사용하여 분할된 각 데이터 청크를 고차원 벡터인 임베딩으로 변환
        - **벡터 데이터베이스 저장:** 생성된 임베딩 벡터들을 벡터 데이터베이스에 저장, 이때 벡터 검색이 빠르고 효율적으로 이루어질 수 있도록 벡터들을 인덱싱하여 보관.
        
        **2. 쿼리:** 사용자의 질문에 대해 가장 관련성이 높은 데이터를 찾아내는 과정
        
        - **쿼리 임베딩:** 사용자의 쿼리를 인덱싱 단계에서 사용했던 것과 **동일한 임베딩 모델**을 사용하여 벡터로 변환
        - **벡터 검색:** 리트리버는 벡터 데이터베이스에서 쿼리 임베딩과 가장 가까운 *k*개의 데이터 청크를 찾아냄.
    - **하이브리드 검색(Hybrid Search)의 개념과 이를 구현하기 위한 RRF(Reciprocal Rank Fusion) 알고리즘에 대해 설명하시오.**
        
        **1. 하이브리드 검색:** 용어 기반 검색과 임베딩 기반 검색을 결합한 형태를 의미
        
        - **필요성:** 용어 기반 검색은 속도가 빠르고 특정 제품명이나 에러 코드와 같은 고유 명사 검색에 강점이 있지만, 단어의 의미적 맥락을 파악하지 못함. 반면, 임베딩 기반 검색(시맨틱 검색)은 질문의 의도를 잘 이해하지만 키워드가 가려질 수 있는 단점이 있음. 하이브리드 검색은 이 두 방식의 장점을 모두 취하여 검색의 정확도를 높임.
        - **구현 방식:**
        
        ◦ **순차적 방식:** 먼저 저렴하고 빠른 용어 기반 검색으로 후보군을 뽑은 후, 정교한 임베딩 기반 검색(리랭킹)으로 최종 순위를 매기는 방식
        
        ◦ **병렬 방식(앙상블):** 두 검색기를 동시에 실행하여 각각의 결과 목록을 얻은 뒤, 이를 하나로 통합하는 방식입니다. 이때 순위 통합을 위해 RRF 알고리즘이 사용됨
        
        **2. RRF 알고리즘:**  여러 검색기가 생성한 **서로 다른 순위 목록을 하나의 최종 순위로 통합**하기 위한 알고리즘
        
        - **핵심 원리:** 각 문서가 각 검색 결과에서 차지한 순위의 역수를 합산하여 최종 점수를 산출
        - **상세 공식:** 하이브리드 검색과 RRF를 활용하면 키워드 매칭의 정확성과 의미적 유사성을 동시에 확보할 수 있어, 더욱 강력한 검색 시스템을 구축할 수 있음.
    - **문서 청킹(Chunking) 전략이 검색 성능에 미치는 영향을 설명하고, 청크 크기(Chunk Size) 결정 시 고려해야 할 트레이드오프(Trade-off)에 대해 논의하시오.**
        
        1.청킹 전략이 검색 성능에 미치는 영향
        
        - 문서를 무작위로 분할하면 맥락이 단절될 수 있으므로, 청크 간 중첩(Overlap)을 통해 문맥을 보존해야 한다.
        - 검색 목적에 맞는 청킹 방식(Q&A 단위, 코드 구조 기반 분할 등)은 검색 정밀도를 향상시킨다.
        - 작은 청크는 컨텍스트 창 내에 다양한 정보를 포함할 수 있어 검색 결과의 다양성과 답변 품질을 높인다.
        
        2. 청크 크기 결정 시 고려해야 할 트레이드오프
        
        - 정보 다양성 vs 맥락 유지: 작은 청크는 정보 다양성이 높으나 맥락 유실 위험이 있고, 큰 청크는 맥락 유지에는 유리하나 활용 가능한 정보 범위가 제한된다.
        - 검색 정확도 vs 계산 비용: 청크 크기를 줄일수록 벡터 수가 증가하여 임베딩·저장 비용과 검색 지연이 증가한다.
        - 모델 제약: 청크 크기는 모델의 최대 토큰 제한을 고려해야 하며, 특정 모델에 최적화된 청킹은 모델 변경 시 재인덱싱이 필요하다.
        
        결론
        모든 상황에 적용 가능한 최적의 청크 크기는 존재하지 않으며, 데이터 특성과 사용자 질의를 고려해 실험적으로 결정해야 한다.
        
    - **쿼리 재작성(Query Rewriting)이 필요한 상황을 예시와 함께 설명하고, 이를 해결하는 프로세스를 기술하시오.**
        - **쿼리 재작성이 필요한 상황**
            1. **대화 맥락 의존 질문**
                
                사용자가 이전 대화를 전제로 짧게 질문할 경우, 단독 쿼리로는 의미가 불명확해 정확한 검색이 어렵다.
                
                예: “John Doe는 언제 구매했지?” 이후 “Emily Doe는 어때요?”
                
            2. **대명사 및 개체 불명확성**
                
                질문에 대명사나 생략된 대상이 포함되어 참조 대상이 명확하지 않은 경우 재작성이 필요하다.
                
                예: “그의 아내는?” → ‘그’가 누구인지 먼저 식별해야 함.
                
        - **쿼리 재작성 해결 프로세스**
            1. 사용자의 현재 질문과 이전 대화 기록을 함께 수집한다.
            2. 생성 모델에 대화 맥락을 반영하여 질문을 재작성하도록 프롬프트를 제공한다.
            3. 맥락 없이도 의미가 통하는 독립적인 쿼리를 생성한다.
            4. 재작성된 쿼리를 기반으로 리트리버를 통해 문서 검색을 수행한다.
        - **효과**
            
            쿼리 재작성은 검색 정확도를 높이고, 잘못된 추론이나 환각 발생 가능성을 줄인다.
            
    - **문맥적 검색(Contextual Retrieval)을 위해 청크를 보강하는 방법들을 설명하고, 특히 Anthropic이 제안한 방식에 대해 서술하시오.**
        
        1️⃣ 문맥적 검색을 위한 청크 보강 방법
        
        1. 메타데이터 추가
        
        각 청크에 문서 제목, 섹션(장) 이름, 작성 목적 등의 정보를 함께 저장
        
        해당 청크가 **문서의 어디에서 나온 내용인지** 쉽게 파악 가능
        
        2. 요약 정보 추가
        
        문서 전체 또는 상위 단락의 요약을 청크에 포함
        
        청크 하나만 보더라도 **전체 흐름을 이해**할 수 있음
        
        3. 인접 청크 정보 활용
        
        앞·뒤 청크의 핵심 내용을 일부 포함
        
        문장이 중간에서 잘려도 **맥락 단절을 완화**
        
        ---
        
        ### 2️⃣ Anthropic이 제안한 문맥적 검색 방식
        
        Anthropic은 각 청크 앞에
        
        “이 청크가 문서 전체에서 어떤 역할을 하는지 설명하는 문장”을 생성한 후,
        
        그 설명과 청크를 함께 임베딩하는 방식을 제안했다.
        
        예시:“이 텍스트는 고객 구매 이력을 설명하는 문서 중 결제 내역을 다룬 부분이다.”
        
        이렇게 하면 청크가 **혼자서도 충분한 의미를 가지게 되어**,
        
        검색 시 더 정확하고 관련성 높은 결과를 얻을 수 있다.
        
        ---
        
        ### 3️⃣ 정리
        
        문맥적 검색을 위해서는 단순히 문서를 나누는 것보다, 각 청크에 **배경 설명과 문서 내 위치 정보를 보강**하는 것이 중요하다. Anthropic 방식은 이를 생성 모델로 자동화한 대표적인 문맥 강화 전략이다.
        
    - **테이블 형식의 데이터(Tabular Data)를 처리하기 위한 RAG 워크플로우를 설명하고, Text-to-SQL 패턴이 어떻게 작동하는지 기술하시오.**
        
        1) 테이블 데이터에서 RAG가 필요한 이유
        
        테이블 형식 데이터는 행(row)과 열(column)로 이루어져 있어 일반 텍스트처럼 임베딩해서 검색하기 어렵다.따라서 **자연어 질문을 SQL로 변환해 직접 데이터베이스를 조회**하는 방식이 더 효과적이다. 이때 사용되는 대표적인 접근이 **Text-to-SQL 기반 RAG**이다.
        
        2) 테이블 데이터를 처리하는 RAG 워크플로우
        
        🔹 1단계: 사용자 질문 입력
        
        사용자는 자연어로 질문한다. 예: “지난달 서울 지역 매출 합계는 얼마야?”
        
        🔹 2단계: 스키마 정보 제공
        
        LLM에게 테이블 구조(컬럼명, 타입, 관계)를 함께 제공한다.→ 어떤 테이블에 어떤 데이터가 있는지 이해시키기 위함
        
        🔹 3단계: Text-to-SQL 변환
        
        LLM이 자연어 질문을 **SQL 쿼리로 변환**한다.
        
        예:
        
        ```sql
        SELECTSUM(sales)
        FROM orders
        WHERE region='Seoul'
        AND order_dateBETWEEN'2024-03-01'AND'2024-03-31';
        ```
        
        🔹 4단계: 데이터베이스 조회
        
        생성된 SQL을 실제 데이터베이스에 실행해 결과를 가져온다.
        
        🔹 5단계: 결과 후처리 및 응답 생성
        
        조회 결과를 다시 자연어로 변환해 사용자에게 설명한다.
        
        ---
        
        3) Text-to-SQL 패턴의 작동 방식
        
        - Text-to-SQL은 **검색(Retrieval)** 대신 **구조적 질의(Query Execution)**를 사용한다.
        - 임베딩으로 문서를 찾는 것이 아니라 👉 질문 → SQL → DB 실행 → 결과 반환 흐름을 따른다.
        - 이 과정에서 LLM은
            - 질문 의도 파악, 필요한 컬럼 선택, 조건(WHERE), 집계(SUM, COUNT 등) 생성을 담당한다.
        
        ---
        
        4) 장점과 주의점
        
        ✅ 장점
        
        - 정확한 수치 계산 가능
        - 최신 데이터 반영 가능
        - 대규모 테이블에도 효율적
        
        ⚠️ 주의점
        
        - 잘못된 SQL 생성 위험 → 검증 필요
        - 스키마 설명이 부실하면 오류 증가
        - 권한 관리 및 SQL Injection 방지 필요
        
        ---
        
        5) 정리
        
        테이블 데이터 RAG에서는 문서를 검색하는 대신, **Text-to-SQL을 통해 데이터베이스를 직접 조회**하는 방식이 핵심이다. 이 패턴은 수치 기반 질문이나 분석 질의에 특히 강력하며, 스키마 제공과 SQL 검증이 성공의 핵심 요소다.
        
    - **AI 에이전트(Agent)의 정의를 '환경(Environment)'과 '행동(Action)'의 관점에서 설명하고, 도구(Tools)가 에이전트의 능력에 미치는 영향을 서술하시오.**
        
        AI Agent: **자신의 환경을 인지**하고 그 환경에 **대응하여 행동**할 수 있는 모든 것
        
        환경은 에이전트가 작동하는 영역으로, 에이전트의 사용 사례에 의해 정의된다. 예를 들어, 자율주행 자동차 에이전트에게 도로 시스템이 곧 환경이 된다.
        
        행동은 에이전트가 환경 내에서 수행할 수 있는 작업의 집합을 의미한다.
        
        결과적으로 에이전트는 자신이 처한 환경을 인식하고, 그 안에서 목적을 달성하기 위해 적절한 행동을 취하는 주체라고 정의할 수 있다.
        
        도구가 에이전트의 능력에 미치는 영향
        
        : 도구는 에이전트가 수행할 수 있는 행동의 집합을 확장시킨다. 도구는 에이전트가 환경을 인지하는 능력을 강화하기도 한다(웹 검색 도구). 또한 계산기, 코드 인터프리터, 이미지 생성 도구 등 에이전트의 성능상 약점을 보완하고 기능적 확장을 가능하게 하기도 한다. 그리고 외부 도구(API)를 통해 에이전트가 현실의 다양한 작업을 자동화하는 능력을 갖게 할 수 있다.
        
    - **에이전트 시스템에서 계획(Planning)과 실행(Execution)을 분리해야 하는 이유와 그 이점을 설명하시오.**
        
        에이전트를 설계할 때 계획을 수행하면서 예기치 못한 오류와 실수가 발생할 수 있다. 이러한 경우 실행 과정에서 과도한 비용과 많은 시간이 소요될 위험이 있다. 따라서 계획과 실행을 분리하여 실행 전 계획을 검토하는 과정이 필수적이다.
        
        계획과 실행을 분리하면 계획을 실행하기 전 사전 검증이 가능하다. 또한 계획을 병렬적으로 생성하여 평가자가 가장 유망한 계획을 선택하게 함으로써 작업의 성공률을 높일 수 있다. 그리고 계획과 실행이 분리된 구조에서 각 단계마다 reflection 과정을 삽입하여 목표 달성 여부를 확인하고 실수를 바로잡을 수 있다.
        
    - **에이전트의 계획 수립 시 사용할 수 있는 다양한 제어 흐름(Control Flows)의 유형들을 나열하고 각각을 설명하시오.**
        1. 순차형 - 작업 간 의존성에 따라 차례로 실행
        2. 병렬형 - 여러 작업을 동시에 수행하여 효율을 높임
        3. 조건문 - 이전 단계 결과에 따라 수행할 작업을 선택
        4. 반복문 - 특정 조건이 충족될 때까지 동일한 작업을 반복
    - **ReAct 프레임워크와 Reflexion 프레임워크를 중심으로 에이전트의 성찰(Reflection) 및 오류 수정(Error Correction) 메커니즘을 설명하시오.**
        - ReAct: 각 단계에서 에이전트는 자신의 생각을 설명하고(계획),행동을 취한다음 관찰 결과를 분석(성찰)하는단계를 반복하며 이는 에이전트가 작업이 완료됐다고 판단할때까지 계속된다.
        - Reflexion:  성찰은 두 모듈로 결과를 평가하는 평가자와 무엇이 잘못되었는지 스스로 과정을 되짚어보는 성찰 모듈로 이루어짐. 각 단계에서 평가와 성찰 후 에이전트는 새로운 궤적을 제안함.
    - **에이전트에게 적합한 도구(Tool)를 선택하고 최적화하기 위한 전략들에 대해 논의하시오.**
        - 도구가 많을수록 에이전트의 능력은 향샹되지만 효율적으로 사용하기는 어려워진다. 모델의 컨택스트 한계도 초과하는 위험이 존재.
            - 여러 도구 조합으로 에이전트 성능 비교
            - 특정 도구를 제거했을대 성능 하락을 비교
            - 자주 실수하는 도구를 찾기
            - 도구 호출 분포를 시각화하여 많이 사용되는 도구와 사용되지 않는 도구를 파악
    - **에이전트 시스템에서 발생할 수 있는 주요 실패 모드(Failure Modes)를 계획(Planning), 도구(Tool), 효율성(Efficiency) 측면으로 나누어 설명하시오.**
        - 계획:
            - 도구 사용 실패: 유효하지 않은 도구, 유효하지 않는 파라미터, 잘못된 파라미터 값
            - 목표 달성 실패
            - 성찰 오류
        - 도구 실패
            - 각단계를 코드로 옮기는 과정에서
            - 적절한 도구의 부재
        - 효율성을 측정하는 방법
            - 작업을 완료하는데 평균적인 단계를 측정
            - 비용 측정
            - 각 행동이 걸리는 시간과 비용
    - **AI 모델을 위한 세 가지 메모리 메커니즘(내부 지식, 단기 메모리, 장기 메모리)을 정의하고, 각각의 역할과 정보 관리 전략을 설명하시오.**
        - 내부 지식: 모든 모델이 접근 가능
        - 단기 메모리: 컨텍스트, 속도는 빠르나 용량이 한정
        - 장기 메모리: 외부 데이터 소스
    
    ---
    
    - 📚 예시 답안
        
        ### 1. 컨텍스트 길이와 RAG의 중요성
        
        - **데이터 무한 확장성:** 모델의 컨텍스트 윈도우가 길어져도 기업의 데이터 증가 속도를 따라잡기 어렵습니다.
        - **성능 최적화:** 컨텍스트가 길어질수록 모델이 정보의 중간 부분을 놓치는 'Lost in the Middle' 현상이 발생하거나 잘못된 정보에 집중할 가능성이 커집니다.
        - **비용 및 지연 시간:** 입력 토큰 수가 늘어날수록 API 비용이 증가하고 응답 속도(Latency)가 느려집니다.
        - **정확도:** RAG는 쿼리와 가장 관련 있는 정보만 선별하여 전달하므로 모델의 효율성과 답변 품질을 동시에 높일 수 있습니다.
        
        ### 2. 용어 기반 검색 vs 임베딩 기반 검색
        
        - **용어 기반 검색 (Sparse Vector)**
        - **특징:** 키워드 매칭(Lexical) 방식.
        - **장점:** 인덱싱/쿼리 속도가 빠름, 특정 고유 명사나 에러 코드 검색에 강력함.
        - **단점:** 의미적 유사성을 파악하지 못함 (동의어, 문맥 파악 불가).
        - **임베딩 기반 검색 (Dense Vector)**
        - **특징:** 벡터화를 통한 의미적(Semantic) 검색.
        - **장점:** 질문의 의도를 파악하고 유의어를 검색할 수 있어 유연함.
        - **단점:** 비용 발생, 키워드 일치도가 중요한 검색에서 성능이 저하될 수 있음.
        
        ### 3. TF-IDF와 BM25
        
        - **TF-IDF:**
        - **TF(단어 빈도):** 문서 내 단어 출현 횟수가 높을수록 중요도 상승.
        - **IDF(역문서 빈도):** 흔한 단어(the, a)의 가중치를 낮추고 희귀 단어의 가중치를 높임.
        - **BM25 (Best Matching 25):**
        - **개선점:** TF-IDF의 단점인 '문서 길이' 문제를 해결.
        - **정규화:** 문서의 평균 길이를 고려하여, 단순히 내용이 길어서 단어가 많이 포함된 문서가 높은 점수를 받는 것을 방지합니다.
        
        ### 4. 임베딩 기반 검색 워크플로우
        
        - **인덱싱(Indexing) 단계:**
        1. **Chunking:** 문서를 적절한 크기로 분할.
        2. **Embedding:** 임베딩 모델을 통해 벡터로 변환.
        3. **Storage:** 벡터 데이터베이스(VectorDB)에 저장.
        - **쿼리(Querying) 단계:**
        1. **Vectorization:** 사용자 질문을 벡터로 변환.
        2. **Retrieval:** 유사도(Similarity) 기반 top-k 청크 검색.
        3. **Generation:** 검색된 컨텍스트를 LLM에 전달하여 최종 응답 생성.
        
        ### 5. 하이브리드 검색과 RRF
        
        - **하이브리드 검색:** 키워드 검색과 벡터 검색을 결합하여 각 방식의 단점을 보완하는 기법.
        - **RRF (Reciprocal Rank Fusion):**
        - 서로 다른 검색 결과 리스트를 하나로 통합하는 알고리즘.
        - 각 문서의 순위(Rank)에 역수를 취해 점수를 합산하여 최종 순위를 결정합니다.
        
        ### 6. 청킹 전략과 트레이드오프
        
        - **영향:** 청크의 크기는 검색의 **정확도**와 **문맥 보존** 사이의 균형을 결정합니다.
        - **트레이드오프:**
        - **작은 청크:** 더 세밀한 정보 검색이 가능하나 문맥이 끊길 위험이 있음.
        - **큰 청크:** 문맥 파악은 유리하나 관련 없는 노이즈가 섞이고 컨텍스트 윈도우를 빨리 채움.
        - **해결책:** 청크 간 일정 부분을 겹치게 하는 **Overlap** 전략을 사용하여 정보 단절을 방지합니다.
        
        ### 7. 쿼리 재작성 (Query Rewriting)
        
        - **필요성:** 대화의 맥락(Context)이 없으면 이해하기 어려운 모호한 질문을 해결하기 위함.
        - **예시:** "어제 본 보고서 다시 보여줘" → "2025년 12월 18일 작성된 매출 보고서 보여줘"로 변환.
        - **프로세스:** 이전 대화 이력과 현재 질문을 LLM에 전달하여, 검색에 최적화된 독립적인 질문으로 다시 작성하게 합니다.
        
        ### 8. 문맥적 검색과 Anthropic의 방식
        
        - **문제점:** 잘게 쪼개진 청크는 원본 문서의 핵심 주제를 놓칠 수 있음.
        - **Anthropic 제안 방식 (Contextual Retrieval):**
        - 각 청크를 인덱싱할 때, 해당 청크가 원본 문서에서 어떤 맥락을 가지는지 설명하는 짧은 텍스트(50~100 토큰)를 생성하여 청크 앞에 붙입니다.
        - 이를 통해 검색 성능을 획기적으로 향상시킵니다.
        
        ### 9. 테이블 데이터 RAG와 Text-to-SQL
        
        - **워크플로우:**
        1. **Text-to-SQL:** 자연어 질문을 SQL 쿼리로 변환 (스키마 정보 포함).
        2. **Execution:** DB에서 쿼리를 실행해 로우 데이터(Raw Data) 추출.
        3. **Synthesis:** 추출된 데이터와 질문을 결합해 최종 답변 생성.
        - 이 방식은 정형 데이터에 대해 벡터 검색보다 훨씬 정확한 수치 계산과 필터링을 가능하게 합니다.
        
        ### 10. 에이전트의 정의와 도구
        
        - **정의:** 환경을 **인식(Perceive)**하고 목표 달성을 위해 **행동(Action)**을 선택하는 자율적인 시스템.
        - **환경:** 에이전트가 활동하는 영역 (OS, 웹브라우저, 특정 소프트웨어 등).
        - **도구(Tools):** 에이전트가 행동을 수행하는 수단 (API 호출, 계산기, 검색기 등). 도구의 범위가 곧 에이전트의 능력치를 결정합니다.
        
        ### 11. 계획과 실행의 분리
        
        - **이유:** 모델이 생각과 동시에 행동하면 오류가 발생할 확률이 높고 수정이 어렵습니다.
        - **이점:**
        - **효율성:** 불필요한 API 호출 방지 및 비용 절감.
        - **안정성:** 실행 전 계획을 검토(Review)하거나 수정할 기회를 가짐.
        
        ### 12. 에이전트 제어 흐름 유형
        
        - **순차적(Sequential):** 작업 A 완료 후 B 실행.
        - **병렬(Parallel):** 독립적인 작업들을 동시에 수행하여 속도 향상.
        - **조건문(If/Else):** 특정 조건 만족 여부에 따라 경로 변경.
        - **반복문(Loop):** 목표를 달성할 때까지 특정 단계 반복.
        
        ### 13. ReAct와 Reflexion
        
        - **ReAct:** Thought(추론)와 Action(행동)을 번갈아 수행하며 실시간 관찰(Observation)을 통해 다음 단계 결정.
        - **Reflexion:** 실패한 결과에 대해 '왜 실패했는지'를 스스로 분석(Self-Reflection)하고, 이를 메모리에 저장하여 다음 시도에 반영하는 사후 수정 메커니즘.
        
        ### 14. 도구 선택 및 최적화 전략
        
        - **Ablation Study:** 특정 도구를 뺐을 때 성능이 얼마나 떨어지는지 확인하여 필수 도구 선별.
        - **도구 전이(Tool Transition):** 자주 함께 사용되는 도구들을 묶어 하나의 고성능 도구로 단순화.
        - **문서화 최적화:** LLM이 도구를 잘 이해할 수 있도록 도구의 설명(Description)을 정교하게 다듬기.
        
        ### 15. 에이전트 실패 모드
        
        - **계획 실패:** 목표와 무관한 계획 수립, 할루시네이션으로 인한 잘못된 파라미터 전달.
        - **도구 실패:** 도구가 에러를 반환하거나, 에이전트가 예상치 못한 형식의 데이터를 응답할 때.
        - **효율성 문제:** 정답은 맞혔으나 너무 많은 단계를 거쳐 비용과 시간이 과다 소모됨.
        
        ### 16. AI 모델의 세 가지 메모리
        
        - **내부 지식(Internal):** 모델 학습 시 내재화된 파라미터 정보 (정적임).
        - **단기 메모리(Short-term):** 현재 대화의 컨텍스트(Context Window) 내 정보.
        - **장기 메모리(Long-term):** 벡터 DB나 외부 저장소에 기록되어 필요할 때마다 꺼내 쓰는 정보 (RAG).
- 7단원
    - 문제
        - 1. 파인튜닝이 모델의 가중치(Weights)를 직접 조정함으로써 얻는 이점을 프롬프트 기반 방식과 비교하여 **서술하십시오.**
            
            <aside>
            💡
            
            1. 모델 행동을 구조적으로 변화시킴
            프롬프트는 지시만 바꾸지만, 파인튜닝은 가중치를 수정해 모델의 능력 자체를 재구성함, 사용자 요구 스타일·형식을 더 정확히 따르게 됨
            2. 일관된 출력 형식 준수 능력 향상
            JSON, YAML, DSL 같은 구조화된 출력 형식을 더 안정적으로 생성하도록 학습됨
            프롬프트로는 불안정할 수 있는 부분을 구조적으로 해결함
            3. 도메인 특화 성능 강화
            특정 도메인의 예시 데이터를 가중치에 반영하여 일반 모델 대비 전문적·정확한 출력을 내도록 함 (예: 특정 SQL 방언, 특정 산업 문서 스타일 등)
            4. 모델의 ‘행동적 문제’를 교정 가능
            사실은 맞지만 맥락에 안 맞는 답, 형식 미준수 등 프롬프트로는 고치기 어려운 문제를 안정적으로 해결함
            5. 예시를 내부화하여 짧은 프롬프트로도 고품질 결과 생성
            프롬프트에 예시를 반복해 넣지 않아도 됨 → 비용·지연 감소, 더 많은 예시 학습 가능함
            </aside>
            
        - 2. 사전 학습된 베이스 모델의 지식을 활용하는 전이 학습이 '샘플 효율성(Sample efficiency)'에 미치는 긍정적 영향을 **설명하십시오.**
            
            <aside>
            💡
            
            1. 이미 사전 학습된 지식을 활용하여 적은 데이터로도 빠르게 학습 가능
            베이스 모델은 방대한 데이터로 사전 학습되어 있기 때문에, 새로운 작업에서 처음부터 학습할 필요가 없음
            → 필요한 학습량(샘플 수)이 크게 감소함
            2. 새로운 작업에 필요한 능력이 이미 모델 내부에 부분적으로 존재함
            전이 학습은 기존에 학습한 일반적 언어 패턴·세계 지식·추론 능력을 재활용함
            → 파인튜닝 시에는 세부 조정만 하면 되므로 소량의 데이터로도 높은 성능을 달성함
            3. 데이터 수집·주석 비용 감소
            특정 분야(예: 법률 QA, text-to-SQL)는 데이터가 적고 주석 비용이 큰데, 전이 학습 덕분에 수백 개 수준의 데이터만으로도 충분함
            → 비용과 시간 모두 절감
            4. 모델이 새로운 작업을 더 빠르게 일반화함
            사전 학습 과정에서 이미 다양한 패턴을 경험했기 때문에, 적은 예시로도 새로운 작업의 규칙을 빠르게 파악함
            </aside>
            
        - 3. 모델의 실패 원인이 '정보 부재'인지 '행동 문제'인지에 따라 RAG와 파인튜닝 중 무엇을 선택해야 하는지 그 **기준을 제시하십시오.**
            
            <aside>
            💡
            
            1. 정보 부재(Information Missing)가 원인일 때 → RAG 선택
            모델이 필요한 사실이나 문서를 모르고 있어서 틀린 답을 하는 경우
            예: 기업 내부 매뉴얼, 최신 데이터, 전문 지식 등 모델 내부에 없는 정보를 요구할 때
            → 외부 지식 소스를 연결하는 RAG가 효과적임
            2. 행동 문제(Behavior Issue)가 원인일 때 → 파인튜닝 선택
            모델이 사실을 알고 있어도 형식을 지키지 않음, 맥락에서 벗어나 말함, 일관성이 떨어짐, 안전성 이슈 있음
            정보는 있지만 “행동 방식이 잘못된” 경우
            → 파인튜닝을 통해 가중치를 조정해 행동을 구조적으로 교정해야 함
            - 정보가 부족해서 틀린 답 → RAG
            - 행동 방식 자체가 잘못돼서 틀린 답 → 파인튜닝
            </aside>
            
        - 4. 신경망 학습의 역전파(Backpropagation) 메커니즘이 GPU 메모리 점유에 미치는 영향을 **분석하십시오.** 모델 가중치 외에 그래디언트(Gradients)와 옵티마이저 상태(Optimizer states)가 추가적인 메모리를 요구함으로써 발생하는 하드웨어 제약 사항을 **설명하십시오.**
            
            <aside>
            💡
            
            신경망 학습 과정에서는 순전파와 역전파 과정이 둘 다 이루어진다. 특히, 역전파 과정에서는 모델 가중치, 활성화 함수를 통과한 값(activations), 그래디언트, 옵티마이저 상태에 대한 정보를 저장해야 하기 때문에 추가적인 메모리를 요구하게 된다:
            
            예시) 7B-parameter model
            
            1. 16-bit format에서 모델을 로딩할 때
            
            : 2 bytes * 7B = 14GB 메모리
            
            1. Adam optimizer로 full finetuning
            
            : 7B * 3(파라미터마다 그래디언트 1개 + 옵티마이저 상태값 2개(모멘텀 및 분산 등)) * 2 bytes = 42GB 메모리
            
            1. Total memory needed = 14GB + 42GB = 56GB
            
            (activations는 포함하지 않은 메모리)
            
            </aside>
            
        - 5. BF16 포맷이 FP16과 비교하여 대규모 모델 훈련의 안정성에 기여하는 바를 **고찰하십시오.**
            
            <aside>
            💡
            
            BF16 - 8 byte range / 7 byte precision
            
            FP16 - 5 byte range / 10 byte precision
            
            BF16는 FP32와 동일한 range byte를 가지므로 동일한 수치 범위를 표현할 수 있다.
            
            반면에 FP16는 범위 비트가 적어 표현할 수 있는 최대값에 한계가 있다. 수치 범위를 벗어나면 무한대로 반올림되거나 임의의 값으로 변환될 수 있다고 한다.
            
            이에 따라 대규모 모델 훈련 중 발생하는 큰 값들이 FP16의 범위를 초과하면 모델 품질이 저하되거나 훈련이 실패할 수 있다. BF16은 FP16보다 훨씬 큰 값을 표현할 수 있어, 이러한 오버플로우 현상을 방지하고 훈련 프로세스를 안정적으로 유지할 수 있다.
            
            </aside>
            
        - 6. 양자화 인지 학습(QAT)이 저비트 모델의 추론 품질 유지에 미치는 영향을 사후 양자화(PTQ)와 비교하여 **설명하십시오.**
            
            <aside>
            💡
            
            사후 양자화(Post-Training Quantization, PTQ): 모델이 이미 완전히 훈련된 후에 양자화를 수행하는 방식
            
            한계 - 훈련이 끝난 후 정밀도를 낮추기 때문에 모델의 품질이 저하(degrade)될 수 있는 위험이 있다. 특히 8비트 이하의 매우 낮은 비트로 변환할 때 이러한 품질 유지 문제가 도전 과제가 된다.
            
            양자화 인지 학습(Quantization-Aware Training, QAT): QAT의 주된 목표는 추론 시 저비트(저정밀도) 환경에서도 높은 품질을 유지하는 모델을 만드는 것이다. 이를 위해 모델은 훈련 과정 중에 저비트(ex. 8 byte)의 동작을 시뮬레이션한다.
            
            효과 - 훈련 단계에서 양자화로 인한 오차를 미리 경험하고 이에 적응하기 때문에 최종적으로 생성된 모델은 저비트 환경에서도 고품질의 출력을 내는 법을 학습하게 된다. 이는 PTQ에서 발생할 수 있는 품질 저하 문제를 직접적으로 해결하기 위한 방법이다.
            
            </aside>
            
        - 7. 풀 파인튜닝(Full finetuning)이 대규모 모델에서 가지는 메모리 한계를 지적하고, PEFT가 어떻게 이 문제를 해결하는지 **서술하십시오.** 적은 수의 학습 파라미터로 풀 파인튜닝에 근접한 성능을 내기 위한 핵심 원리를 **기술하십시오**
            
            <aside>
            💡
            
            한계: 풀 파인튜닝은 모델의 모든 파라미터를 업데이트 하므로 막대한 메모리가 필요함
            
            PEET: PEET는 학습 가능한 파라미터의 수를 획기적으로 줄여 메모리 사용량을 최소화
            모델의 전체 가중치를 업데이트하는 대신 특정 위치에 소수의 추가 파라미터를 삽입하고 이들만 학습시켜서 메모리 요구량을 줄임
            
            핵심원리: 거대 언어 모델은 수많은 파라미터를 가지고 있지만 실제로는 매우 낮은 내제적 차원을 가짐
            사전 학습 과정이 하위 작업을 위한 압축 프레임워크 역할을 하기 때문에, 소수의 파라미터를 조정하는 것만으로 모델의 행동을 유의미하게 변화시킬 수 있음
            
            </aside>
            
        - 8. LoRA(Low-Rank Adaptation)가 원래의 가중치 행렬(*W*)을 유지하면서도 효율적으로 학습할 수 있는 수학적 원리를 **설명하십시오.**
            
            <aside>
            💡
            
            </aside>
            
        - 9. LoRA 어댑터를 베이스 모델에 병합(Merge)하여 서빙할 때와 분리하여 서빙할 때의 차이점을 **비교하여 서술하십시오.**
            
            <aside>
            💡
            
            병합방식: 학습한 조각들을 원본 모델에 아예 합쳐버리는 방식. 서비스 할 때 추가 계산이 필요 없어 속도가 빠르지만 고객별로 다른 모델을 제공해야 해서 저장 공간을 많이 차지한다.
            
            분리방식: 공유하는 원본 모델 하나는 그대로 두고 작은 학습 조각(어댑터)만 따로 보관하다가 필요할 때 끼워 쓰는 형태. 여러 작업을 하나의 서버에서 처리할 때 어댑터만 바꾸면 돼서 저장 공간을 줄이고 작업 전환이 빠르다.
            
            </aside>
            
        - 10. 4비트 NF4 양자화와 페이지드 옵티마이저(Paged optimizers)가 단일 GPU에서의 거대 모델 학습을 가능하게 만든 과정을 **설명하십시오.** 다만, 이러한 메모리 절감이 실제 학습 시간에 미칠 수 있는 부정적 영향을 함께 **기술하십시오**
            
            <aside>
            💡
            
            <NF4, paged optimizer가 단일 GPU에서 거대 모델 학습이 가능한 과정>
            
            1. NF4(normalFloat-4): QLoRA가 사용하는 4비트 형식
            - LLM은 원래 BF16을 사용, 하지만 QLoRA는 4비트로 저장햇다가(1/4로 줄어듬) 순전파와 역전파를 계산할 때만 다시 BF16으로 역양자화해서 씀
            - 모델의 데이터(가중치)는 보통 정규분포를 그리는데 NF4는 이 분포에 딱 맞춰 데이터를 압축하는 방식, 그래서 예전에는 GPU 4대가 필요했던 모델이라면 이젠 단일 GPU 안에 데이터를 넣을 수 있게 된 것임.
            1. Paged optimizer: GPU 메모리가 꽉 차기 전에, 안쓰는 메모리를 CPU로 옮겨두고 필요하면 다시 가져오는 방식, 메모리가 부족해서 학습이 멈추는 일이 없기 떄문에 단일 GPU에서도 긴 문장을 학습할 수 있게 됨
            
            <메모리 절감이 실제 학습 시간에 미칠 수 있는 부정적 영향>
            
            : 메모리를 아낀 대신 시간을 손해 보게 됨 
            
            1. NF4: 메모리 사용량을 줄여줄 수 있지만, 양자화하고 다시 되돌리는 과정에서 시간이 더 걸려서 학습시간이 늘어날 수 있음.
            2. Paged optimizer: CPU 와 GPU 사이의 길은 GPU 내부 통로보다 훨씬 좁고 느려서 데이터 이동 때문에 전체 학습 속도가 늘어남.
            
            </aside>
            
        - 11. 여러 파인튜닝된 모델을 하나로 합치는 '모델 머징'이 다중 작업(Multi-task) 수행에 미치는 영향을 **서술하십시오.** 별도의 모델 앙상블 방식과 비교하여 추론 비용 측면에서 가지는 장점을 **설명하십시오**
            
            <aside>
            💡
            
            - 모델 머징: 서로 다른 작업에 대해 각각 파인튜닝을 병렬로 진행한 다음, 완료 되면 서로 다른 모델들의 가중치만 골라서 합치는 방식
            - 앙상블: 각 구성 모델을 그대로 놔둔, 모델 출력만 결합하는 방식
            
            <multi-task 수행에 미치는 영향>
            
            : 파인 튜닝을 한 모델의 지식만 골라서 합치는 방식이기 때문에 하나의 모델이 A 작업도 잘하고 B 작업도 잘하는 다중 작업 수행에 유리하게 됨. 
            
            <앙상블 방식과 비교해 추론 비용 측면에서의 장점>
            
            - 앙상블은 성능을 끌어올릴 순 있지만, 요청 하나당 여러번 추론을 돌려야해서 비용이 더 든다. (모델을 3번 돌려야 하니까 GPU 메모리도 시간도 그만큼 더 든다)
            - 하지만, 모델 머징의 경우에는 가중치 자체가 합쳐진 거라, 최종 결과물은 결국 모델 1개의 용량임. 그래서 추가적인 하드웨어 비용, 지연시간 없이 여러 모델의 성능을 동시에 누릴 수 있음.
            </aside>
            
        - 12. 순차적 파인튜닝(Sequential finetuning)에서 발생하는 치명적 망각 현상을 정의하고, 모델 머징이 이를 어떻게 완화할 수 있는지 **방안을 제시하십시오.**
            
            <aside>
            💡
            
            치명적 망각이란, 모델이 새로운 작업으로 순차적으로 파인튜닝될 때 이전에 학습한 내용이 **급격히 사라지는 현상**
            
            1. **응답의 정확성 및 전반적인 품질 향상:** 모델은 제공된 관련 정보를 활용하여 더 **정확하고 상세하며 유용한 응답**을 생성할 수 있습니다. 컨텍스트는 모델이 각 쿼리에 맞춰 적절한 답변을 구성하도록 돕는 핵심 요소입니다.
            
            2. **환각(Hallucination) 현상 방지:** 모델에게 필요한 정보가 주어지지 않으면 신뢰할 수 없는 **내부 지식에 의존**하게 되어 거짓 정보를 지어낼 위험이 큽니다. 충분한 컨텍스트를 제공하면 이러한 **환각을 완화하고 응답의 사실적 일관성과 신뢰성**을 높일 수 있습니다.
            
            **비유하자면,** 컨텍스트를 제공하는 것은 학생에게 시험을 볼 때 기억력에만 의존하게 하는 대신, 옆에 **관련 참고 서적**을 두고 정확한 답을 찾게 도와주는 것과 같습니다
            
            </aside>
            
        - 13. 모델 가중치를 단순 평균(Weight Averaging)하는 것보다 SLERP 방식을 사용하는 것이 유리한 이유를 기하학적 관점에서 **설명하십시오.**
            
            <aside>
            💡
            
            </aside>
            
        - 14. 학습률의 크기가 손실 곡선(Loss curve)의 변동성에 미치는 영향을 분석하고, 적절한 학습률 범위를 찾는 과정을 **설명하십시오.**
            
            <aside>
            💡
            
            **1. 학습률 크기가 손실 곡선의 변동성에 미치는 영향**
            
            - **학습률이 너무 큰 경우:** 모델 파라미터가 최적의 지점을 지나쳐 버리기 때문에 손실 곡선이 심하게 요동(fluctuation)치며 불안정한 모습을 보입니다.
            - **학습률이 너무 작은 경우:** 손실 곡선은 매우 안정적이지만 **감소 속도가 지나치게 느려** 목표 지점에 도달하는 데 너무 오랜 시간이 걸리게 됩니다.
            
            **2. 적절한 학습률 범위를 찾는 과정**
            
            - **초기 범위 설정:** 보편적인 최적값은 없으므로 보통 **1e-7에서 1e-3 사이**의 범위에서 실험을 시작합니다.
            - **사전 학습 지표 활용:** 사전 학습(Pre-training)이 끝난 시점의 학습률에 **0.1에서 1 사이의 상수를 곱한 값**을 시작점으로 설정하는 것이 일반적인 관행입니다.
            - **곡선 모니터링 및 조정:** **손실 곡선이 안정적으로 유지되는 한 가장 높은 학습률**을 선택하는 것이 학습 효율 면에서 가장 좋습니다.
            - **스케줄링 도입:** 학습 과정 전체에서 동일한 값을 쓰는 대신, 진행 상황에 따라 학습률을 점진적으로 조정하는 학습률 스케줄(Learning rate schedules)을 적용하여 성능을 최적화합니다
            </aside>
            
        - 15. 배치 크기 설정이 학습 안정성에 미치는 영향과 GPU 메모리 한계를 극복하기 위한 '그래디언트 누적(Gradient accumulation)' 기술의 역할을 **설명하십시오.**
            
            <aside>
            💡
            
            </aside>
            
            - 답안
                1. 파인튜닝은 모델의 **가중치(Weights)를 직접 조정**하여 특정 작업에 적응시키는 과정인 반면, 프롬프트 방식은 가중치 수정 없이 지시사항과 문맥만을 제공합니다. 파인튜닝은 특히 **모델의 지시 이행 능력(Instruction-following)**과 특정 출력 형식(JSON, YAML 등) 준수 능력을 개선하는 데 효과적입니다. 다만, 프롬프트 방식에 비해 데이터 확보, 하드웨어 자원, 머신러닝 전문 인력 등 **더 높은 초기 투자 비용**이 발생한다는 트레이드오프가 존재합니다
                2. 전이 학습은 한 작업에서 얻은 지식을 새로운 관련 작업 학습을 가속화하는 데 활용하는 기술입니다. 이는 **샘플 효율성(Sample efficiency)**을 크게 높여주는데, 예를 들어 법률 질의응답 모델을 처음부터 학습시키려면 수백만 개의 예시가 필요하지만, 잘 훈련된 베이스 모델을 파인튜닝하면 **단 몇 백 개의 예시만으로도** 효과적인 학습이 가능합니다
                3. 실패 원인이 **'정보 부재(Information-based)'**라면 외부 지식에 접근할 수 있는 **RAG**가 적합하며, **'행동 문제(Behavior-based)'**라면 출력 스타일과 형식을 교정하는 **파인튜닝**이 적합합니다. "파인튜닝은 형식(Form)을 위한 것이고, RAG는 사실(Facts)을 위한 것이다"라는 원칙에 따라, 최신성 유지와 사실적 정확성이 중요하다면 RAG를, 복잡한 구문 준수와 스타일 최적화가 중요하다면 파인튜닝을 선택해야 합니다
                4. 학습 시에는 순전파뿐만 아니라 **역전파(Backpropagation)** 과정을 수행해야 하므로 추론보다 훨씬 많은 메모리가 필요합니다. 메모리 점유의 주요 원인은 모델 가중치 외에도 **그래디언트(Gradients)**와 **옵티마이저 상태(Optimizer states)**입니다. 특히 Adam 옵티마이저는 학습 가능한 파라미터당 2개의 추가 상태 값을 저장하므로 메모리 요구량을 크게 증가시킵니다
                5. BF16과 FP16은 모두 16비트를 사용하지만 비트 배분이 다릅니다. FP16은 정밀도(10비트)에 집중하여 수치 범위가 좁은 반면, **BF16은 범위(8비트)**에 더 많은 비트를 할당하여 FP32와 동일한 수치 범위를 가집니다. 따라서 BF16은 대규모 모델 학습 시 발생하는 **큰 수치(Out-of-bound)를 더 안정적으로 처리**할 수 있지만, FP16에 비해 정밀도는 다소 낮다는 특징이 있습니다
                6. **PTQ**는 학습이 완료된 후 모델을 저비트로 변환하는 방식으로 구현이 간단하여 개발자들에게 흔히 사용됩니다. 반면, **QAT**는 학습 과정에서 저비트 환경을 시뮬레이션하여 **추론 시 품질 저하를 최소화**합니다. QAT는 최종 모델의 정확도는 높지만, 학습 계산은 여전히 고정밀도로 수행되어 학습 시간이 단축되지 않거나 오히려 늘어날 수 있다는 트레이드오프가 있습니다
                7. 최근의 거대 모델은 모든 파라미터를 업데이트하는 '풀 파인튜닝' 시 단일 GPU 메모리를 초과하는 막대한 자원을 요구합니다. **PEFT**는 전체 가중치 중 극히 일부(수 퍼센트 미만)만 업데이트하거나 추가 모듈을 학습시킴으로써 **메모리 발자국을 획기적으로 줄여줍니다**. 이는 성능 면에서 풀 파인튜닝에 근접하면서도 훨씬 적은 자원으로 학습을 가능케 합니다
                8. LoRA는 원래의 고차원 가중치 행렬 *W*를 고정한 채, 이를 두 개의 **저차원 행렬** *A***와** *B***의 곱**으로 분해하여 이 작은 행렬들만 학습시킵니다. **랭크(*r*)**가 작을수록 학습할 파라미터 수와 메모리 사용량은 줄어들지만, 모델의 표현력이 제한될 수 있으며, 반대로 랭크가 너무 높으면 오버피팅의 위험이 생길 수 있습니다
                9.  LoRA 어댑터를 베이스 모델에 **병합(Merge)**하면 추론 지연 시간이 없으나, 여러 어댑터를 서빙할 때 각각 전체 모델을 저장해야 하므로 저장 공간 낭비가 큽니다. 반면, 어댑터를 **분리**하여 유지하면 하나의 베이스 모델만 저장하고 100개의 작은 어댑터만 관리하면 되므로 **다중 고객(Multi-tenant) 서빙 효율성**이 비약적으로 향상되지만, 추론 시 약간의 지연 시간이 발생할 수 있습니다
                10. QLoRA는 모델 가중치를 **4비트 NF4 포맷**으로 양자화하고, 메모리 부족 시 CPU로 데이터를 전송하는 **페이지드 옵티마이저(Paged optimizers)**를 사용하여 65B 모델을 단일 48GB GPU에서 학습할 수 있게 했습니다. 그러나 양자화 및 역양자화 단계가 추가되어 **학습 시간이 늘어날 수 있다는 제약**이 따릅니다
                11. 모델 머징은 여러 파인튜닝된 모델을 하나로 합쳐 **다양한 능력을 갖춘 단일 모델**을 만드는 기술입니다. 이는 모델 출력값만을 조합하는 앙상블 방식과 달리, 단 한 번의 추론 호출만 필요하므로 **추론 비용을 획기적으로 절감**하면서도 여러 작업의 성능을 동시에 확보할 수 있습니다
                12. 순차적으로 여러 작업을 학습시키면 이전 지식을 잃어버리는 '치명적 망각'이 발생합니다. 모델 머징을 이용하면 각 작업을 **병렬로 독립적으로 학습시킨 후 합치기 때문에** 이러한 망각 현상을 피할 수 있습니다. 이는 개별 작업의 전문성을 유지하면서도 모델의 범용적 성능을 보존하는 데 유리합니다
                13. 가중치를 단순히 산술 평균하는 방식과 달리, **SLERP**는 가중치 벡터를 구체 상의 점으로 간주하고 **최단 경로(Shortest path)를 따라 보간**합니다. 이는 단순 평균이 가중치의 기하학적 특성을 훼손할 수 있는 문제를 보완하여, 모델 고유의 특성을 더 잘 보존하면서 자연스러운 결합을 가능하게 합니다
                14. 학습률은 매 학습 단계에서 가중치를 얼마나 변경할지 결정하는 '보폭'입니다. 학습률이 너무 크면 **손실 곡선이 심하게 요동치며 발산**할 수 있고, 너무 작으면 학습 속도가 지나치게 느려집니다. 따라서 초기에는 큰 보폭으로 빠르게 수렴시키고 끝으로 갈수록 보폭을 줄이는 **스케줄링**을 통해 최적해에 정밀하게 도달해야 합니다
                15. 배치 크기가 클수록 여러 예시의 신호를 종합하여 **안정적인 업데이트**가 가능하지만, 더 많은 GPU 메모리가 소요됩니다. 메모리 제약으로 큰 배치를 쓰지 못할 때, 여러 배치의 그래디언트를 모았다가 한 번에 업데이트하는 **그래디언트 누적(Gradient accumulation)** 기술을 통해 하드웨어 한계를 극복하고 안정적인 학습을 수행할 수 있습니다
                
- 8단원
    
    ### **💡 문제 출제**
    
    - **1. 데이터 중심(Data-centric) AI와 모델 중심(Model-centric) AI의 접근 방식을 비교 설명하십시오.**
        
        <aside>
        💡
        
        - **모델 중심(Model-centric) AI:** 데이터셋은 고정된 것으로 간주하고, **모델의 아키텍처, 크기, 또는 훈련 기법을 개선**하여 성능을 높이는 데 집중합니다. "주어진 데이터에서 최상의 성능을 내는 모델은 무엇인가?"를 고민합니다.
        - **데이터 중심(Data-centric) AI:** 모델 아키텍처는 고정한 채, **데이터의 품질과 구성을 개선**하여 시스템의 성능을 최적화하는 방식입니다. "모델의 성능을 극대화하기 위해 어떤 데이터가 필요한가?"를 고민합니다.
        - **차별화 요소:** 모델이 점차 범용화됨에 따라 **데이터의 품질과 다양성**이 모델 성능을 가르는 핵심 차별화 요소로 부상하고 있습니다.
        - **상호 관계:** 두 방식은 서로 배타적인 것이 아니며, 기술적 진보를 위해 **모델과 데이터 모두에 대한 지속적인 개선**이 병행되어야 합니다.
        
        **요약하자면**, 모델 중심 AI가 **'레시피와 조리기구(모델)'** 개발에 집중한다면, 데이터 중심 AI는 '식재료의 신선도와 품질(데이터)'을 높여 요리의 맛을 끌어올리는 것과 같음
        
        </aside>
        
    - **2.파인튜닝을 위한 고품질 데이터가 갖추어야 할 6가지 주요 특성을 나열하고 각각 설명하십시오.**
        
        <aside>
        💡
        
        1. **관련성 (Relevant):** 학습 데이터는 모델이 수행하고자 하는 작업과 직접적으로 관련이 있어야 합니다. 예를 들어, 현대 법률 질문에 답하는 모델을 학습시키기 위해 19세기의 법률 데이터를 사용하는 것은 부적절할 수 있습니다.
        
        2. **작업 요구사항과의 정렬 (Aligned with task requirements):** 데이터의 주석(Annotation)은 작업의 요구사항과 일치해야 합니다. 예를 들어, 작업이 사실적 일관성, 창의성, 또는 간결함을 요구한다면 주석 역시 그 특성을 정확히 반영하고 있어야 합니다. 단순히 '정확함'을 넘어 사용자가 원하는 구체적인 스타일과 정렬되는 것이 중요합니다.
        
        3. **일관성 (Consistent):** 여러 예시나 서로 다른 작업자들 사이에서 주석의 기준이 동일해야 합니다. 기준이 일관되지 않으면(예: 같은 품질의 에세이에 다른 점수를 부여함) 모델이 학습하는 데 혼란을 줄 수 있습니다. 명확한 가이드라인을 갖추는 것이 이를 보장하는 핵심입니다.
        
        4. **정확한 형식 (Correctly formatted):** 모든 데이터 예시는 모델이 기대하는 형식을 따라야 합니다. 불필요한 HTML 태그, 일관되지 않은 대소문자 표기, 잘못된 숫자 형식 등은 모델의 학습을 방해할 수 있으므로 제거하거나 수정해야 합니다.
        
        5. **충분한 고유성 (Sufficiently unique):** 데이터셋 내에 중복된 예시가 없어야 합니다. 중복 데이터는 데이터 분포를 왜곡하여 모델에 편향을 심어줄 수 있고, 테스트 세트 오염을 유발하며, 계산 자원을 낭비하게 만듭니다.
        
        6. **준수성 (Compliant):** 데이터는 개인정보 보호법(PII) 등 관련 법규와 내부 윤리 정책을 준수해야 합니다. 예를 들어, 개인 식별 정보가 포함된 데이터를 모델 학습에 사용해서는 안 됩니다.
        
        이러한 특성들을 갖춘 데이터는 양이 적더라도 노이즈가 섞인 대량의 데이터보다 모델 성능 개선에 훨씬 더 효과적일 수 있음
        
        </aside>
        
    - **3.데이터 커버리지(Data Coverage) 확보를 위해 고려해야 할 다양성의 차원 3가지를 설명하십시오.**
        
        <aside>
        💡
        
        - **작업(Task) 다양성**
            
            모델이 수행해야 할 다양한 작업 유형을 포함해야 함
            
            질의응답, 요약, 번역, 분류, 추론 등 서로 다른 태스크를 포함함으로써 모델이 다양한 문제 유형에 일반화될 수 있음
            
        - **주제(Topic / Domain) 다양성**
            
            금융, 기술, 패션, 교육 등 다양한 주제 영역의 데이터를 포함해야 함
            
            이를 통해 특정 도메인에 편향되지 않고 실제 사용자 질문 분포를 폭넓게 커버할 수 있음
            
        - **입력 및 출력 형식(Instruction / Output Format) 다양성**
            
            짧은 질문과 긴 지시문, 자연어 응답, yes/no 답변, JSON과 같은 구조화된 출력 등 다양한 표현과 형식을 포함해야 함
            
            이를 통해 모델이 다양한 사용자 표현 방식과 응답 요구에 안정적으로 대응할 수 있음
            
        </aside>
        
    - **4.데이터 수량 증가에 따른 '수확 체감(Diminishing returns)' 현상의 의미와 시사점을 설명하십시오.**
        
        <aside>
        💡
        
        - **의미**
            
            데이터 수량이 증가할수록 모델 성능은 향상되지만 일정 시점 이후에는 동일한 양의 데이터를 추가해도 성능 개선 폭이 점점 감소하는 현상을 의미함
            
            초기에는 적은 데이터 증가로도 큰 성능 향상을 얻을 수 있으나 데이터가 많아질수록 추가 데이터의 효과는 제한적이 됨
            
        - **시사점**
            
            1) 무작정 데이터 양을 늘리는 것보다 데이터 품질과 다양성이 더 중요해질 수 있음
            
            2) 성능이 정체되는 구간에서는 데이터 수량 확대보다 데이터 구성 개선(다양성, 커버리지)이 효과적임
            
        
               3) 추가 데이터 확보에는 비용이 들기 때문에 성능 향상이 거의 없는 구간에서는 비용 대비 효율을 고려한 데이터 전략이 필요함
        
        → 따라서 데이터 수량 증가는 중요하지만 일정 수준 이후에는 품질·다양성 중심의 데이터 전략으로 전환해야 함
        
        </aside>
        
    - **5.AI 엔지니어링에서 '데이터 플라이휠(Data Flywheel)'이 작동하는 단계를 설명하십시오.**
        
        <aside>
        💡
        
        데이터 플라이휠이란? 
        
        서비스 사용으로 생성된 데이터를 모델 개선에 활용하고 개선된 모델이 다시 더 많은 사용자와 고품질 데이터를 만들어내는 선순환 구조
        
        - **1단계: 서비스 사용을 통한 데이터 및 피드백 수집**
            
            실제 AI 서비스를 사용하는 과정에서 사용자 입력, 행동 로그, 피드백과 같은 데이터가 자연스럽게 생성됨
            
            이 데이터는 실제 사용 환경을 반영한다는 점에서 매우 높은 가치를 가짐
            
        - **2단계: 수집된 데이터를 활용한 모델 개선**
            
            수집된 데이터를 정제하고 이를 활용해 모델을 파인튜닝하거나 평가·개선함
            
            이 과정에서 모델은 사용자 요구와 실제 사용 패턴에 더 잘 맞도록 발전함
            
        - **3단계: 개선된 모델을 통한 서비스 품질 향상 및 데이터 증가**
            
            성능이 향상된 모델은 더 나은 사용자 경험을 제공하고 사용자 수 증가 및 더 많은 고품질 데이터 유입으로 이어짐
            
        </aside>
        
    - **6.데이터 증강(Data Augmentation)과 데이터 합성(Data Synthesis)의 차이점을 정의와 예시를 들어 비교하십시오.**
        
        <aside>
        💡
        
        1. 데이터 증강
        
        : 기존의 실제 데이터를 변형하여 새로운 데이터를 만드는 것
        
        EX) 고양이 사진을 좌우로 뒤집어 새로운 이미지 생성
        
        1. 데이터 합성
        
        : 실제 데이터의 속성을 모방하여 가상의 데이터를 생성하는 것
        
        EX) 원본 데이터 → Diffusion 모델 학습 → 랜덤 노이즈 입력 → 원본 데이터와 통계적 특성이 유사한 합성 데이터 생성
        
        </aside>
        
    - **7.데이터 생성 시 '시뮬레이션(Simulation)' 기법의 중요성을 안전성과 효율성 측면에서 설명하십시오.**
        
        <aside>
        💡
        
        1. 안정성
        
        : 시뮬레이션 기법은 현실 세계에서 데이터를 수집할 때 발생할 수 있는 사고나 물리적 손상의 위험을 방지하여 안정성을 확보할 수 있다.
        
        1. 효율성
        
        : 자율주행이나 로봇 공학처럼 비용이 많이 드는 실험을 가상 환경에서 반복적으로 수행할 수 있게 하여 데이터 수집의 효율성을 극대화할 수 있다.
        
        </aside>
        
    - **8. AI를 활용한 데이터 합성 기법 중 **'역지시(Reverse Instruction)'**가 작동하는 방식을 설명하십시오.**
        
        <aside>
        💡
        
        역지시(Reverse Instruction) 기법은 소설이나 위키피디아 아티클과 같이 이미 존재하는 고품질의 장문 콘텐츠를 가져와서, AI로 하여금 해당 내용을 결과값으로 도출할 수 있는 Instruction을 역으로 생성하는 방법이다.
        
        이 방법은 이미 검증된 고품질의 인간 작성 콘텐츠를 답변으로 사용하기 때문에, AI가 답변을 직접 생성할 때 발생할 수 있는 환각 오류를 피하면서 고품질의 학습 데이터를 확보할 수 있는 장점이 있다.
        
        ```markdown
        '정답: 고품질의 텍스트' → Instruction 생성 → (입력 프롬프트, 정답) instructive learning 데이터 쌍 생성 → 모델 학습
        ```
        
        </aside>
        
    - **9.Llama 3의 코딩 데이터 합성 파이프라인에서 '자율적 오류 수정' 과정이 어떻게 이루어지는지 설명하십시오.**
        
        <aside>
        💡
        
        - 임정
            - ??어디 문단에 있는걸까.. 책 p455
        - **모범답변**: 모델이 생성한 코드 솔루션이 유닛 테스트나 린터(Linter) 검증을 통과하지 못할 경우, **실패 메시지와 오류 내용을 다시 모델에게 프롬프트로 전달**합니다. 모델은 이 피드백을 바탕으로 코드를 스스로 수정하며, 이 과정을 **최종 검증을 통과할 때까지 반복**하여 고품질의 검증된 데이터만 데이터셋에 포함시킵니다.
        </aside>
        
    - **10.~~합성~~ 데이터 품질 검증을 위한 '기능적 정확성'과 'AI 심사위원(judge as LLM)' 방식의 차이를 비교 설명하십시오.**
        
        <aside>
        💡
        
        - 임정
            - 기능적 정확성: 코딩처럼 기능적으로 평가할 수 있는 문제에 적용
            - AI 검증기: 위 방식이 불가능하다면, 범용 AI 평가자나 특화된 채점기를 사용함. 1~5점으로 점수를 매기거나 좋음/나쁨 으로 평가하는 것. 혹은 실제/합성 데이터를 섞어서 어느것이 합성데이터인지 블라인드 테스트를 해볼 수 도 있음
        - **모범 답변:** **기능적 정확성**은 코드 실행 결과나 수학 정답처럼 객관적 지표로 성공 여부를 즉시 확인할 수 있는 작업에 사용됩니다. 반면, **AI 심사위원**은 정답이 고정되지 않은 개방형 응답의 논리성이나 유용성을 평가하기 위해 강력한 모델(예: GPT-4)을 활용하여 점수를 매기거나 분류하는 방식입니다.
        </aside>
        
    - **11.'모델 붕괴(Model Collapse)' 현상의 정의와 이를 방지하기 위한 핵심 방안을 제시하십시오.**
        
        <aside>
        💡
        
        - 임정
            - AI가 생성한 콘텐츠(자동수익화 블로그, 쇼츠자동화)를 기반으로 훈련된 생성형 AI 모델의 성능이 저하되는 현상. 2023년 Shumailov et all 에서 처음 명명. VAE, GMM, LLM 모델등에서 일어날 수 있음
            - 원인:  데이터 불균형을 가지고 있는 데이터셋으로 합성데이터를 만들면 희귀한 클래스가 점차 없어지는 것 과 동일
            - 해결방안: 실제 데이터와 섞기(명확한 답은 없음)
        - **모범 답변:** 모델 붕괴란 모델이 생성한 데이터로만 반복 학습할 경우, 확률이 낮은 **희귀한 패턴은 잊어버리고 보편적인 패턴만 과잉 학습하여 모델의 다양성과 성능이 점차 퇴화**하는 현상입니다. 이를 방지하기 위해서는 학습 데이터에 **AI가 만든 데이터뿐만 아니라 실제 인간이 생성한 데이터를 일정 비율로 섞어서** 학습시켜야 합니다.
        </aside>
        
    - **12.'모델 증류(Model Distillation)'의 개념과 이를 통해 얻을 수 있는 이점을 두 가지 측면에서 설명하십시오.**
        
        <aside>
        💡
        
         모델 증류는 작은 모델(학생)이 큰 모델(교사)의 행동을 모방하도록 훈련시키는 방법. 작은 모델은 처음부터 학습하거나 사전 학습된 모델을 미세 조정 하여 교사 모델이 생성한 데이터나 행동을 학습한다.
        
        이점
          1. 배포 효율성 및 비용 절감: 작은 모델은 메모리를 적게 차지하고 추론 속도가 빠르다
          2. 성능 유지 밎 최적화: 학생 모델이 교사 모델보다 훨씬 가볍지만 교사 모델의 언어 이해 능력을 상당 부분 유지할 수 있다. 그리고 단순 모방을 넘어 교사 모델보다 더 강력한 학생 모델을 만들 수도 있다.
        
        </aside>
        
    - **13.데이터 처리 과정에서 '수동 검사(Manual Inspection)'의 중요성을 가치적 측면에서 서술하십시오.**
        
        <aside>
        💡
        
        개발자가 데이터를 직접 확인하면서 자동화 도구의 한계를 보완하거나 데이터의 이해도를 높여서 나중에 발생할 수 있는 복잡한 문제를 예방할 수 있음.
        
        </aside>
        
    - **14.데이터 중복 제거(Deduplication)가 모델 성능 향상과 자원 효율성 측면에 미치는 영향을 설명하십시오.**
        
        <aside>
        💡
        
        1. 편향 방지 및 성능 저하 예방: 중복된 데이터는 데이터 분포를 왜곡시켜 편향을 강화함. 또한 중복된 데이터로 학습된 모델은 더 작은 중복되지 않은 데이터로 학습된 모델과 비슷한 성능을 보임.
        2. 자원 효율성: 중복된 데이터로 모델을 훈련시키는 것은 실질적 성능 향상은 없고 시간과 컴퓨팅 자원의 낭비임. 중복된 데이터 제거로 전체 데이터 양을 줄여서 처리 시간 단축 가능.
        </aside>
        
    - **15.데이터 정제 과정에서 '노이즈(Noise)'의 예시 3가지와 그것이 모델에 미치는 부정적 영향을 설명하십시오.**
        
        <aside>
        💡
        
        </aside>
        
    - **16. 파인튜닝 데이터 포맷팅(Formatting) 시 실제 추론 환경과의 일관성이 중요한 이유를 서술하십시오.**
        
        <aside>
        💡
        
        </aside>
        
    
    ### 📝 예시 답안
    
    **1. 데이터 중심(Data-centric) AI와 모델 중심(Model-centric) AI의 접근 방식을 비교 설명하세요.**
    
    - **답변:** 모델 중심 AI는 모델의 아키텍처, 크기, 또는 훈련 알고리즘을 개선하여 성능을 높이는 데 집중하는 방식입니다. 반면, **데이터 중심 AI는 모델을 고정한 채 데이터 자체의 품질을 개선(데이터 정제, 고품질 데이터셋 구축, 샘플 추가 등)하여 성능을 최적화**하는 데 주력합니다. 최근에는 모델이 범용화되면서 데이터가 성능의 핵심 차별화 요소로 부상하고 있습니다.
    
    **2. 파인튜닝을 위한 고품질 데이터가 갖추어야 할 6가지 주요 특성을 나열하고 각각 설명하세요.**
    
    - **답변:** 고품질 데이터는 다음 6가지를 만족해야 합니다. ① **관련성(Relevant)**: 학습 데이터가 타겟 작업과 직접적으로 연관되어야 합니다. ② **정렬(Aligned)**: 주석이 작업 요구사항(예: 사실 관계, 스타일)과 일치해야 합니다. ③ **일관성(Consistent)**: 여러 주석가나 샘플 간에 판단 기준이 동일해야 합니다. ④ **정확한 형식(Correctly formatted)**: 모델이 기대하는 토큰 및 채팅 템플릿 형식을 준수해야 합니다. ⑤ **고유성(Unique)**: 중복이 없어 특정 패턴에 편향되지 않아야 합니다. ⑥ **준수성(Compliant)**: 개인정보 보호법 등 법적/윤리적 정책을 지켜야 합니다.
    
    **3. 데이터 커버리지(Data Coverage) 확보를 위해 고려해야 할 다양성의 차원 3가지를 설명하세요.**
    
    - **답변:** 첫째, **작업 유형의 다양성**으로 요약, 질의응답, 번역 등 모델이 수행할 다양한 작업이 포함되어야 합니다. 둘째, **주제 다양성**으로 패션, 금융, 기술 등 사용자가 질문할 수 있는 광범위한 도메인을 다뤄야 합니다. 셋째, **형식의 다양성**으로 짧은 답변부터 긴 답변, JSON 출력 등 예상되는 모든 응답 스타일을 포함해야 모델의 견고함이 유지됩니다.
    
    **4. 데이터 수량 증가에 따른 '수확 체감(Diminishing returns)' 현상의 의미와 시사점을 설명하세요.**
    
    - **답변:** 수확 체감이란 데이터셋이 커질수록 동일한 양의 데이터를 추가했을 때 얻어지는 성능 향상 폭이 점차 줄어드는 현상을 의미합니다. 예를 들어, 초기 1,000개의 샘플은 큰 성능 향상을 가져오지만, 이미 100만 개가 있는 상태에서의 추가 1,000개는 미미한 영향만 줄 수 있습니다. 따라서 **데이터 확보 비용 대비 성능 이득을 분석하여 최적의 투입 시점을 결정**하는 것이 중요합니다.
    
    **5. AI 엔지니어링에서 '데이터 플라이휠(Data Flywheel)'이 작동하는 단계를 단계별로 설명하세요.**
    
    - **답변:** 1단계로 실제 서비스에서 **사용자가 생성한 데이터와 피드백을 수집**합니다. 2단계로 이 데이터를 정제하여 **모델을 다시 훈련(파인튜닝)**합니다. 3단계로 개선된 모델이 더 나은 서비스를 제공함으로써 **더 많은 사용자와 고품질 데이터를 유입**시킵니다. 이 순환 구조는 시간이 흐를수록 경쟁자가 따라잡기 힘든 강력한 경쟁 우위(데이터 해자)를 만들어냅니다.
    
    **6. 데이터 증강(Data Augmentation)과 데이터 합성(Data Synthesis)의 차이점을 정의와 예시를 들어 비교하세요.**
    
    - **답변:** **데이터 증강**은 기존의 실제 데이터를 변형하여 새 샘플을 만드는 기법으로, 문장에서 단어를 동의어로 교체하거나 이미지를 회전시키는 것이 예시입니다. 반면, **데이터 합성**은 실제 데이터 없이 규칙이나 AI 모델을 이용해 인위적으로 데이터를 생성하는 과정으로, 템플릿을 이용한 가짜 영수증 생성이나 LLM을 이용한 새 시나리오 작성이 포함됩니다.
    
    **7. 데이터 생성 시 '시뮬레이션(Simulation)' 기법의 중요성을 안전성과 효율성 측면에서 설명하세요.**
    
    - **답변:** 안전성 측면에서 자율주행이나 로보틱스처럼 **현실에서 수집하기 위험하거나 비용이 막대한 데이터(사고 상황 등)를 가상 환경에서 안전하게 대량 생성**할 수 있게 해줍니다. 효율성 측면에서는 인간이 생각하지 못한 최적의 행동 시퀀스를 AI가 스스로 탐색하고 학습 데이터로 활용하게 함으로써 학습 속도를 극대화할 수 있습니다.
    
    **8. AI를 활용한 데이터 합성 기법 중 '역지시(Reverse Instruction)'가 작동하는 방식을 설명하세요.**
    
    - **답변:** 역지시는 먼저 **고품질의 결과물(책, 기사, 위키피디아 등)을 확보**한 뒤, AI 모델에게 **"이 결과물을 출력하게 만들려면 어떤 질문(지시어)을 해야 하는가?"라고 물어 지시어를 생성**하게 하는 방식입니다. 이는 AI가 답변까지 생성할 때 발생할 수 있는 환각 현상을 방지하면서 고품질의 (지시어, 응답) 쌍을 확보할 수 있다는 장점이 있습니다.
    
    **9. Llama 3의 코딩 데이터 합성 파이프라인에서 '자율적 오류 수정' 과정이 어떻게 이루어지는지 설명하세요.**
    
    - **답변:** 모델이 생성한 코드 솔루션이 유닛 테스트나 린터(Linter) 검증을 통과하지 못할 경우, **실패 메시지와 오류 내용을 다시 모델에게 프롬프트로 전달**합니다. 모델은 이 피드백을 바탕으로 코드를 스스로 수정하며, 이 과정을 **최종 검증을 통과할 때까지 반복**하여 고품질의 검증된 데이터만 데이터셋에 포함시킵니다.
    
    **10. 합성 데이터 품질 검증을 위한 '기능적 정확성'과 'AI 심사위원' 방식의 차이를 비교 설명하세요.**
    
    - **답변:** **기능적 정확성**은 코드 실행 결과나 수학 정답처럼 객관적 지표로 성공 여부를 즉시 확인할 수 있는 작업에 사용됩니다. 반면, **AI 심사위원**은 정답이 고정되지 않은 개방형 응답의 논리성이나 유용성을 평가하기 위해 강력한 모델(예: GPT-4)을 활용하여 점수를 매기거나 분류하는 방식입니다.
    
    **11. '모델 붕괴(Model Collapse)' 현상의 정의와 이를 방지하기 위한 핵심 방안을 제시하세요.**
    
    - **답변:** 모델 붕괴란 모델이 생성한 데이터로만 반복 학습할 경우, 확률이 낮은 **희귀한 패턴은 잊어버리고 보편적인 패턴만 과잉 학습하여 모델의 다양성과 성능이 점차 퇴화**하는 현상입니다. 이를 방지하기 위해서는 학습 데이터에 **AI가 만든 데이터뿐만 아니라 실제 인간이 생성한 데이터를 일정 비율로 섞어서** 학습시켜야 합니다.
    
    **12. '모델 증류(Model Distillation)'의 개념과 이를 통해 얻을 수 있는 이점을 두 가지 측면에서 설명하세요.**
    
    - **답변:** 모델 증류는 거대 모델(Teacher)의 출력을 작은 모델(Student)이 학습하게 하여 지식을 전달하는 기법입니다. 이점으로는 첫째, **비용 및 지연 시간 감소**로 작고 빠른 모델을 통해 거대 모델에 근접한 성능을 내면서 운영 비용을 절감할 수 있습니다. 둘째, 성능 유지 측면에서 특정 작업에 특화된 고성능 소형 모델을 구축할 수 있습니다.
    
    **13. 데이터 처리 과정에서 '수동 검사(Manual Inspection)'의 중요성을 가치적 측면에서 서술하세요.**
    
    - **답변:** 수동 검사는 자동화 도구가 놓칠 수 있는 **미묘한 오류 패턴이나 데이터의 질감(Texture)을 파악**할 수 있게 해줍니다. 저자 칩 후옌은 이를 **"가치 대 명성 비율이 가장 높은 활동"**이라고 표현하며, 데이터 분포를 직접 확인하는 15분이 수 시간의 시행착오를 줄여주고 모델의 강점과 약점에 대한 깊은 직관을 제공한다고 강조합니다.
    
    **14. 데이터 중복 제거(Deduplication)가 모델 성능 향상과 자원 효율성 측면에 미치는 영향을 설명하세요.**
    
    - **답변:** 성능 측면에서는 중복 데이터로 인한 **특정 패턴 편향을 방지하고 테스트 셋 오염을 막아** 모델의 일반화 능력을 높여줍니다. 자원 효율성 측면에서는 불필요한 데이터를 학습하는 데 소모되는 **연산 자원(GPU 시간 등)과 저장 공간을 절약**하여 전체적인 훈련 비용을 낮춥니다.
    
    **15. 데이터 정제 과정에서 '노이즈(Noise)'의 예시 3가지와 그것이 모델에 미치는 부정적 영향을 설명하세요.**
    
    - **답변:** 노이즈의 예로는 스크레이핑 시 섞여 들어온 **HTML 태그, 중복된 문단, 개인정보(PII)** 등이 있습니다. 이러한 노이즈는 모델이 불필요한 토큰에 집중하게 만들어 **정확도를 떨어뜨리고**, 입력 토큰 길이를 늘려 **비용을 상승**시키며, 안전 정책을 위반하는 모델을 만들 위험이 있습니다.
    
    **16. 파인튜닝 데이터 포맷팅(Formatting) 시 실제 추론 환경과의 일관성이 중요한 이유를 서술하세요.**
    
    - **답변:** 모델은 학습 시 경험한 데이터의 구조(공백, 특수 기호, 화살표 등)를 매우 정밀하게 학습하기 때문입니다. 학습 데이터의 포맷이 실제 추론 시 사용하는 프롬프트 템플릿과 단 하나라도 다를 경우(예: 추가 공백 등), **모델이 학습한 대로 작동하지 않고 성능이 급격히 저하되는 버그**가 발생할 수 있습니다.
    
- 9단원
    
    ### **💡 문제 출제**
    
    - **1. 모델 추론 최적화가 필요한 근본적인 이유가 무엇인가?**
        
        <aside>
        💡
        
        - **지연 시간(latency)이 실제 서비스 가치에 직접적인 영향을 미치기 때문**
            
            모델의 예측 성능이 아무리 뛰어나더라도 추론 속도가 느릴 경우, 실제 사용자 환경에서는 응답 지연으로 인해 결과의 정확성과 무관하게 서비스 가치가 감소함
            
        - **추론 비용이 서비스의 비용 대비 효율(ROI)을 결정하기 때문**
            
            모델은 한 번 학습하지만 배포된 AI 시스템에서는 추론이 사용자 요청마다 반복되므로 전체 시스템 비용에서 가장 큰 비중을 차지하는 단계는 추론 단계임. 추론 비용이 높을 경우 대규모 서비스 운영이 어려워짐
            
        - **추론은 학습보다 훨씬 더 빈번하게 발생하는 단계이기 때문**
            
            모델 학습은 상대적으로 드물게 수행되는 반면, 추론은 서비스 운영 기간 동안 지속적으로 발생하므로 추론 단계의 비효율은 곧 시스템 전체의 비효율로 이어짐
            
        </aside>
        
    - **2. 추론 과정에서 발생하는 두 가지 주요 연산 병목 현상을 설명하세요**
        
        <aside>
        💡
        
        - **연산 제약(Compute-bound) 병목**
            
            모델 추론 과정에서 대규모 행렬 곱셈(Matrix Multiplication)과 같은 연산이 많아 GPU 또는 CPU의 연산 처리 능력이 성능의 한계가 되는 경우임. 이 경우 연산량이 많아 계산 속도가 추론 지연의 주요 원인이 됨
            
        - **메모리 대역폭 제약(Memory bandwidth-bound) 병목**
            
            모델 파라미터나 중간 결과를 메모리에서 연산 장치로 가져오는 과정에서 메모리와 프로세서 간 데이터 전송 속도(대역폭)가 제한되어 성능이 저하되는 경우임. 대규모 모델에서는 메모리 접근 속도가 추론 성능의 주요 병목이 됨
            
        
        책에서는 추론 병목을 계산이 느린 경우(Compute-bound)와 메모리에서 데이터 가져오는 게 느린 경우(Memory bandwidth-bound)로 구분하고 있음
        
        </aside>
        
    - **3. 트랜스포머 기반 언어 모델의 추론 단계인 ‘Prefill’과 ‘Decode’는 각각 어떤 병목 현상에 해당하나요?**
        
        <aside>
        💡
        
        - **Prefill 단계 → 연산 제약(Compute-bound) 병목**
            
            Prefill 단계에서는 입력 시퀀스 전체에 대해 한 번에 attention 및 행렬 연산이 수행됨. 이 과정에서 대규모 행렬 곱셈이 집중적으로 발생하므로 GPU/CPU의 연산 처리 능력이 추론 성능의 주요 병목이 됨
            
        - **Decode 단계 → 메모리 대역폭 제약(Memory bandwidth-bound) 병목**
            
            Decode 단계에서는 토큰을 하나씩 생성하며 이전 토큰들의 key-value 캐시를 반복적으로 메모리에서 읽어옴. 이로 인해 연산량 자체보다는 메모리 접근과 대역폭이 성능의 주요 병목이 됨
            
        </aside>
        
    - **4. 사용자 경험 측면에서 중요한 두 가지 지연 시간 지표인 TTFT와 TPOT의 차이점을 설명하세요.**
        
        <aside>
        💡
        
        1. TTFT(Time to First Token)
        
        : 사용자가 질문을 보낸 후 첫 번째 토큰이 생성될 때까지의 시간. 프리필(prefill) 단계에 해당하며 사용자가 체감하는 초기 반응 속도를 결정한다.
        
        1. TPOT(Time Per Output Token)
        
        : 첫 번째 토큰 생성 이후 각 출력 토큰이 생성되는 평균 시간. 디코딩(decode) 단계에 해당하며 사용자가 글을 읽는 속도(텍스트 생성 속도)에 영향을 준다.
        
        1. 차이점
        
        : TTFT는 시스템이 응답을 시작하는 기다림의 시간을, TPOT는 응답 시작 후 정보가 전달되는 흐름의 속도를 의미한다.
        
        개인적으로는 TTFT는 길어도 되지만 TPOT가 길면 굉징히 답답함..
        
        </aside>
        
    - **5. 단순한 처리량(Throughput)과 굿풋(goodput)의 차이는 무엇인가요?**
        
        <aside>
        💡
        
        처리량(Throughput): 시스템이 단위 시간당 처리할 수 있는 전체 작업의 양
        
        굿풋(Goodput): 단순히 많이 처리하는 것이 아니라, 사용자가 정의한 서비스 품질 기준(Service Level Objective, SLO)를 충족한 유효한 처리량
        
        차이점: 유효성과 SLO의 충족 여부
        
        </aside>
        
    - **6. GPU 활용도를 측정할 때 nvidia-smi에서 보여주는 수치보다 MFU가 더 정확한 효율 지표인 이유는 무엇인가요?**
        
        <aside>
        💡
        
        nividia-smi의 활용도(Utilization)는 특정 시간 동안 하나 이상의 커널이 GPU에서 실행 중인지 여부만 나타내므로, 단순한 메모리 읽기/쓰기 작업만으로도 100%가 될 수 있어 실제 계산 효율을 왜곡한다. 즉, nividia-smi는 GPU의 가동 여부만 측정할 뿐, 연산의 밀도는 측정하지 못한다.
        
        예시- 100초를 기준으로 예를 들면, gpu가 가벼운 메모리 복사 작업에 연산량의 1%를 100초 동안 실행했다면 nividia-smi에는 gpu 활용도가 100%로 나온다(낮은 MUF).
        
        반면에, MUF(Model FLOPs Utilization)는 하드웨어의 이론적 최대 연산 성능(Peak FLOPs) 대비 실제 모델 계산에 사용된 연산량의 비율을 측정하므로, 하드웨어가 실제 계산에 얼마나 효율적으로 사용되고 있는지 더 정확하게 보여준다.
        
        </aside>
        
    - **7. CPU와 비교하여 GPU가 머신러닝 워크로드, 특히 행렬 연산에 최적화된 하드웨어 구조적 특징은 무엇인가요?**
        
        <aside>
        💡
        
        1. CPU: 복잡한 명령어를 처리하는 능력은 강력하지만 소수의 코어만 가짐
        2. GPU: 복잡한 일을 처리하는 능력은 약하지만 작은 수천개의 코어로 이루어짐, 복잡한 기능은 다 빼고 산술만 할 수 있게 작게 만들어짐
        
        >> 그렇다면 왜 행렬 연산(ML)에 GPU가 유리할까?
        
         
        
        $\begin{pmatrix} a & b \\ c & d \end{pmatrix} \times \begin{pmatrix} e & f \\ g & h \end{pmatrix}$
        
        CPU는 이걸 순서대로 계산하지만 GPU는 수천 개의 코어들이 동시에 계산하기 때문에 전체적인 산술 연산 데이터 처리량에서 GPU가 CPU를 압도하게 되는 것임.
        
        </aside>
        
    - **8. 모델 압축 기법 중 'Pruning(가지치기)'의 두 가지 방식에 대해 설명하세요.**
        
        <aside>
        💡
        
        - 프루닝의 핵심 아이디어: 큰 모델 안에 전체 모델의 동작을 담을 수 있는 파라미터의 부분집합이 존재하지 않을까?
        - 프루닝의 장점: 모델 저장 공간도 줄고 연산도 빨라짐
        - 프루닝의 두 가지 방식
            1. 구조적 프루닝: 신경망 노드 전체를 제거하는 것, 아키텍처를 바꾸고 파라미터 개수를 줄임(제거 단위: 레이어 덩어리)
            2. 비구조적 프루닝: 원래 모양을 유지하되 예측에 도움되지 않는 파라미터를 찾아서 0으로 설정(제거 단위: 개별 가중치)
        
        ** 하지만 집필 시점에는 실제로 프루닝을 쓰는 경우가 많지 않았음 
        
        : 원본 모델 아키텍쳐에 대한 이해가 필요해서 하기가 어렵고, 다른 방법보다 성능 향상도 훨씬 적은 경우가 많기 때문임, 또 희소 모델을 만드는데 모든 하드웨어 아키텍쳐가 그 희소성의 이점을 잘 활용하도록 설계되어 있지는 않기 때문임.
        
        </aside>
        
    - **9. 'Speculative Decoding(투사적 디코딩)'의 기본 작동 원리는 무엇인가요?**
        
        <aside>
        💡
        
        자기 회귀 언어 모델은 토큰을 하나씩 차례대로 생성하는데 이 과정은 느릴 뿐만 아니라 비용도 많이 듬.
        
        그래서 투사적 디코딩(더 빠르지만 성능이 낮은 모델을 사용해 토큰 시퀀스를 생성한 다음, 이를 목표 모델이 검증하는 방식)을 사용함.
        
        - 기본 작동 원리
            1. 초안 모델(가벼운 모델)이 K개의 토큰 시퀀스를 생성
            2. 목표 모델(거대 모델)이 이 K개의 생성된 토큰을 병렬로 검증(이미 써져 있는 글자가 맞는지 확인할때 GPU를 가지고 동시에 한번에 계산할 수 있음)
            3. 목표 모델이 초안 시퀀스를 왼쪽부터 순서대로 검증, 처음으로 예측이 엇갈리는 지점 바로 앞까지의 토큰들만 수락함. 
            4. 문장이 완성될 때까지 위의 과정을 반복한다. 
        </aside>
        
    - **10. 'KV 캐시(KV Cache)'란 무엇이며, 왜 추론 시에만 사용되나요?**
        
        <aside>
        💡
        
        1. **KV 캐시**는 트랜스포머(Transformer) 기반의 대규모 언어 모델(LLM)이 텍스트를 생성할 때, **이전에 계산했던 데이터를 재사용하기 위해 메모리에 저장해두는 기술**.
        
        → 다음 단어를 생성할 때, 임시 저장해두는 ‘중간 계산 저장소’
        
        2. 왜 추론(Inference) 시에만 쓰나요?
        
        - **학습은 '동시적'이기 때문:** 학습할 때는 정답 문장이 이미 다 주어져 있습니다. GPU가 문장 전체를 **'한꺼번에(병렬)'** 처리하므로, 앞 단어의 계산 결과를 기다렸다가 저장할 필요가 없습니다.
        - **추론은 '순차적'이기 때문:** 추론은 단어를 하나씩 순서대로 만들어야 합니다. "A → B → C"를 만들 때, C를 만들려면 A와 B의 정보가 다시 필요한데, 매번 처음부터 다시 계산하면 너무 느려집니다. 그래서 미리 계산한 A, B의 KV 값을 '기억(캐싱)'해두는 것입니다.
        
        </aside>
        
    - **11. Multi-Query Attention(MQA)과 Grouped-Query Attention(GQA)은 어떻게 KV 캐시의 메모리 점유율을 줄이나요?**
        
        <aside>
        💡
        
        기존 방식(MHA)이 모든 Query마다 전용 Key와 Value를 가졌다면, MQA와 GQA는 이 **Key와 Value를 서로 나눠 쓰게(공유)** 하여 저장 용량을 줄임.
        
        - **MQA (전체 공유):** 모든 Query가 **단 1개**의 KV만 공유합니다. 메모리는 가장 적게 쓰지만(최대 90% 이상 절감), 성능이 조금 떨어질 수 있습니다.
        - **GQA (그룹 공유):** Query를 몇 개씩 묶어 **그룹별로 1개**의 KV를 공유합니다. 메모리 절약과 모델 성능 사이의 균형을 맞춘 '황금 밸런스' 방식입니다.
        
        **왜 메모리가 줄어드나요?**
        
        - **물리적 개수 감소:** 저장해야 할 Key, Value 벡터의 개수 자체가 헤드 수만큼 줄어듭니다. (예: 32개 저장할 것을 1개나 8개만 저장)
        - **중복 제거:** 똑같은 정보를 여러 번 저장하지 않고 하나만 저장한 뒤 돌려쓰기 때문에, 남는 GPU 메모리에 더 긴 문장(Context)을 담거나 **더 많은 사용자**의 요청을 동시에 처리할 수 있습니다
        </aside>
        
    - **12. 배치(Batching) 방식 중 'Continuous Batching(연속 배치)'이 'Static Batching'보다 효율적인 이유는 무엇인가요?**
        
        <aside>
        💡
        
        연속 배치 방식이 정적 배치 방식보다 효율적인 이유는 언어모델의 응답 길이가 서로 다를 때 발생하는 유휴 자원 문제를 해결하기 때문이다.
        
        —-
        정적 배치의 비효율성
        
        - 불필요한 대기: 정적 배치는 고정된 수의 요청을 묶어서 한 번에 처리한다. 따라서 어떤 요청을 10개의 토큰만 생성하면 끝나지만 어떤 요청은 1000개의 토큰을 생성해야 할 수도 있다. 이럴 경우 10개짜리 요청은 1000개짜리 요청이 완료될 때까지 결과를 반환하지 못하고 대기해야 한다.
        
        - 자원 낭비: 짧은 요청을 처리한 연산자원은 같은 배치의 긴 요청이 끝날 때까지 작업을 하지 않고 놀게 된다.
        
        —-
        연속 배치의 효율성
        
        - 즉각적인 반환: 배치 내의 특정 요청 처리가 완료되면 다른 긴 요청이 끝나기를 기다리지 않고 해당 사용자에게 즉각 응답을 반환한다.
        
        - 지속적 자원 활용: 요청이 완료되어 비게 된 자원에 새로운 요청을 즉시 투입한다.
        
        </aside>
        
    - **13. 추론 서버에서 'Prefill'과 'Decode' 단계를 서로 다른 인스턴스로 분리(Decoupling)하여 얻는 이점은 무엇인가요?**
        
        <aside>
        💡
        
        자원 경합을 제거하여 전체적 처리량과 지연 시간 성능을 최적화 할 수 있다.
        
        —-
        1. 병목현상 분리를 통한 간섭 제거: 프리필과 디코드는 서로 다른 컴퓨팅 자원을 요구하기 때문에 한 인스턴스에서 같이 실행하면 비효율적인 경쟁이 발생한다.
        
        - 프리필: 입력 토큰 전체를 한 번에 병령로 처리한다. 연산량이 매우 많아 연산 제한 특성을 가진다.
        
        - 디코드: 토큰을 하나씩 순차적으로 생성한다. 연산량은 낮지만 메모리에서 데이터를 얼마나 빨리 가져오는지가 중요한 메모리 대역폭 제한 특성을 가진다.
        
        이 두 작업을 분리하지 않는다면 새로운 요청이 들어와 프리필 작업을 수행하는 순간 대량의 연산 작업을 독점한다. 이로 인해 이미 진행중이던 다른 요청들의 디코드 작업이 연산 자원을 할당받지 못해 일시적으로 느려지는 현상이 발생한다. (토큰 생성 속도 저하)
        —-
        2. 처리량 증가 및 지연시간 준수
        
        - 처리량 증가:각 단계가 자신에게 최적화된 자원을 사용하므로 더 많은 요청을 처리할 수 있음.
        
        - 지연 시간 요구사항 충족: 프리필 작업이 디코드 작업을 방해하지 않으므로 응답이 생성되는 속도를 일정하게 유지하여 지연시간 목표를 준수하기 수월함.
        —-
        3. 유연한 자원 배분
        
        애플리케이션의 특성에 맞춰 프리필 인스턴스와 디코드 인스턴스의 비율을 조절할 수 있음.
        
        - 긴 문맥 처리가 중요한 경우 입력이 길어 프리필 부하가 크기 때문에 프리필 인스턴스 비율을 높여 초기 응답 시간(TTFT)을 줄일 수 있음.
        
        - 빠른 생성이 중요한 경우: 출력이 길어 디코드 부하가 크다면 디코드 인스턴스의 비율을 높여 토큰 생성 속도(TPOT)을 최적화할 수 있음.
        
        </aside>
        
    - **14. ‘Prompt Caching'이 특히 효과적인 사용 사례(Use Case) 두 가지를 예로 드세요.**
        
        <aside>
        💡
        
        </aside>
        
    - **15. 모델 병렬화 전략 중 'Tensor Parallelism'과 'Pipeline Parallelism'의 주요 차이점은 무엇인가요?**
        
        <aside>
        💡
        
        </aside>
        
    
    ### 📝 예시 답안
    
    1. 모델을 더 빠르고(Faster), 더 저렴하게(Cheaper) 만들기 위해서입니다. 모델이 너무 느리면 사용자에게 무용지물이 될 수 있고, 너무 비싸면 투자 대비 수익(ROI)을 맞출 수 없기 때문입니다.
    
    2. 연산 자체에 시간이 걸리는 **Compute-bound**와, 메모리와 프로세서 간의 데이터 전송 속도에 제약을 받는 **Memory bandwidth-bound**가 있습니다.
    
    3. 입력 토큰을 병렬로 처리하는 **Prefill 단계는 Compute-bound**이며, 토큰을 하나씩 생성하는 **Decode 단계는 Memory bandwidth-bound**입니다.
    
    4. **TTFT(Time to First Token)**는 쿼리 송신 후 첫 번째 토큰이 나올 때까지 걸리는 시간이며, **TPOT(Time per Output Token)**는 첫 토큰 이후 각 출력 토큰이 생성되는 간격의 시간입니다.
    
    5. Throughput은 단순히 초당 생성되는 토큰 수를 의미하지만, **Goodput**은 그중에서도 서비스 수준 목표(SLO, 예: 지연 시간 제한)를 만족하는 요청의 수만을 측정합니다.
    
    6. `nvidia-smi`는 단순히 GPU가 작업을 수행 중인 시간의 비율만 보여주지만, **MFU**는 칩의 이론적 최대 연산 능력(FLOP/s) 대비 실제로 수행된 연산의 비율을 보여주기 때문에 실제 연산 효율성을 더 잘 반영합니다.
    
    7. CPU는 소수의 강력한 코어로 순차적 처리에 능한 반면, **GPU는 수천 개의 작은 코어로 구성되어 병렬 처리에 최적화**되어 있습니다. 머신러닝의 핵심인 행렬 연산은 고도의 병렬화가 가능하기 때문에 GPU가 유리합니다.
    
    8. 신경망의 노드 전체를 제거하여 구조를 바꾸는 방식과, 덜 중요한 파라미터를 0으로 설정하여 모델을 희소(Sparse)하게 만드는 방식이 있습니다.
    
    9. 작고 빠른 '초안 모델(Draft model)'이 여러 토큰을 먼저 생성하고, 원래의 '타겟 모델'이 이를 병렬로 한꺼번에 검증하여 수용 여부를 결정하는 방식입니다.
    
    10. 이전 단계에서 계산된 Key와 Value 벡터를 저장해 재사용하는 메모리 공간입니다. 훈련 시에는 모든 토큰을 한 번에 알 수 있어 필요 없지만, **추론 시에는 토큰을 순차적으로 생성하므로 중복 계산을 피하기 위해 필수적**입니다.
    
    11. 모든 쿼리 헤드가 하나의 Key-Value 쌍을 공유(MQA)하거나, 헤드 그룹별로 공유(GQA)함으로써 저장해야 할 KV 쌍의 개수를 크게 줄여 메모리 사용량을 절감합니다.
    
    12. Static Batching은 모든 요청이 완료될 때까지 기다려야 하지만, **Continuous Batching은 개별 요청이 끝나는 즉시 결과를 반환하고 그 자리에 새 요청을 채워 넣을 수 있어** 하드웨어 활용도와 응답 속도가 모두 향상됩니다.
    
    13. 두 단계의 연산 특성(Compute-bound vs Memory-bound)이 다르기 때문에, 자원 경쟁을 방지하고 각 단계에 최적화된 리소스를 할당하여 전체적인 처리량과 지연 시간을 개선할 수 있습니다.
    
    14. 매번 포함되는 긴 **시스템 프롬프트**가 있는 경우, 또는 동일한 문서에 대해 여러 번 질문하는 **RAG 기반 챗봇**이나 **긴 대화 기록**이 있는 경우에 효과적입니다.
    
    15.  **Tensor Parallelism**은 단일 연산(예: 행렬 곱셈)을 여러 장치로 쪼개어 병렬로 실행하여 지연 시간을 줄이며, **Pipeline Parallelism**은 모델의 레이어들을 여러 장치에 나누어 배치하여 데이터가 흐르듯이 처리하게 함으로써 처리량을 높입니다.
    
- 10단원
    
    ### 💡 문제 출제
    
    - Q1. AI 애플리케이션 아키텍처가 단순한 모델 API 호출에서 시작하여 점차 복잡해지는 5단계 과정을 순서대로 요약하여 설명하십시오.
        
        <aside>
        💡
        
        **1. 단순 모델 API 호출**
        
        사용자의 입력을 그대로 모델에 전달하고, 모델의 응답을 그대로 반환하는 가장 기본적인 구조
        
        별도의 맥락 보강, 안전 장치, 최적화 없이 빠르게 프로토타입을 만들 수 있음
        
        **2. 컨텍스트 강화(Context Construction)**
        
        외부 문서, 데이터베이스, 검색, 도구 등을 활용해 모델이 참고할 추가 정보를 제공한다. 이를 통해 모델이 더 정확하고 맥락에 맞는 응답을 생성할 수 있음
        
        **3. 가드레일(Guardrails) 추가**
        
        입력과 출력에 대한 검증을 통해 보안, 개인정보 보호, 품질 문제를 방지
        
        민감 정보 유출, 잘못된 응답, 정책 위반 등의 위험을 줄이기 위한 단계
        
        **4. 모델 라우터 및 게이트웨이 도입**
        
        여러 모델과 도구를 효율적으로 관리하기 위해 라우팅과 통합 인터페이스를 추가함
        
        요청 유형에 따라 적절한 모델을 선택하고, 보안·비용·접근 제어를 중앙에서 관리함
        
        **5. 캐싱 및 에이전트 패턴 적용**
        
        캐시를 통해 지연 시간과 비용을 줄이고, 반복·분기·루프 구조를 갖는 에이전트 패턴을 통해 복잡한 작업을 수행할 수 있도록 확장함
        
        → 이러한 단계적 확장은 품질, 안전성, 비용, 확장성을 균형 있게 만족시키기 위한 현실적인 발전 과정
        
        </aside>
        
    - Q2. AI 아키텍처에서 '컨텍스트 구성(Context Construction)'의 역할은 무엇이며, 이것이 왜 모델의 출력 품질에 중요한지 설명하십시오.
        
        <aside>
        💡
        
        - **컨텍스트 구성의 역할**
        컨텍스트 구성(Context Construction)은 모델이 응답을 생성할 때 참고해야 할 정보를 **외부 시스템에서 수집·선별·조합하여 입력 프롬프트에 포함시키는 아키텍처 단계**임
        여기에는 검색 결과, 데이터베이스 조회 결과, 사용자 상태, 이전 대화 이력 등이 포함됨
        - **출력 품질에 중요한 이유**
        대형 언어 모델은 입력으로 주어진 컨텍스트에 강하게 의존하여 응답을 생성하므로 컨텍스트가 부족하거나 부정확할 경우 환각(hallucination)이나 부정확한 응답이 발생함
        반대로, 적절하게 구성된 컨텍스트를 제공하면 모델의 추론 정확도와 응답의 신뢰성이 크게 향상됨
        
        → 따라서 컨텍스트 구성은 모델을 변경하지 않고도 출력 품질을 개선할 수 있는 핵심 아키텍처 요소임
        
        </aside>
        
    - Q3. 입력 가드레일(Input Guardrails)에서 PII(개인식별정보) 유출을 방지하기 위해 사용하는 '마스킹(Masking) 및 언마스킹(Unmasking)' 기법의 작동 원리를 단계별로 설명하십시오.
        
        <aside>
        💡
        
        1. **PII 탐지**
        사용자 입력에서 전화번호, 주소와 같은 개인정보를 탐지
        2. **마스킹(Masking)**
        탐지된 개인정보를 [PHONE NUMBER]와 같은 플레이스홀더로 마스킹하여 원래 개인정보가 외부 API로 전달되지 않도록 함
        3. **가역적 PII 맵 저장**
        마스킹에 사용된 플레이스홀더와 원래 개인정보를 연결하는 가역적 PII 맵을 내부적으로 저장함
        4. **언마스킹(Unmasking)**
        모델이 생성한 응답에 플레이스홀더가 포함된 경우, 저장된 PII 맵을 이용해 해당 부분을 원래 개인정보로 복원한 후 사용자에게 제공함
        
        → 이를 통해 외부로는 개인정보를 숨기면서 사용자에게는 자연스러운 응답을 제공할 수 있음
        
        </aside>
        
    - Q4. 출력 가드레일(Output Guardrails)의 두 가지 주요 기능과, 이를 통해 감지하고자 하는 대표적인 실패 유형(품질 및 보안 측면)을 설명하십시오.
        
        <aside>
        💡
        
        - 출력 가드레일 두 가지 주요 기능
            1. 모델의 출력 실패 감지
            2. 각 실패 모드에 대한 처리 정책을 지정
        - 실패 유형
            - 품질
                1. 유효하지 않은 JSON과 같은 포맷 오류
                2. 사실과 다른 환각
                3. 낮은 품질의 답변
            - 보안
                1. 혐오 발언
                2. 개인정보를 포함한 답변
                3. 원격 도구나 코드 실행을 사용하는 답변
        </aside>
        
    - Q5. 모델 라우터(Router)를 도입했을 때 얻을 수 있는 주요 이점 두 가지를 구체적인 예시와 함께 설명하십시오.
        
        <aside>
        💡
        
        모델 라우터
        
        : 모든 사용자 쿼리를 하나의 모델로 처리하는 대신, 쿼리의 의도를 분석하여 가장 적합한 모델이나 솔루션으로 연결해 주는 시스템 구성 요소
        
        주요 이점
        
        1. 쿼리의 주제에 특화된 모델을 사용하여 범용 모델보다 더 나은 성능을 낼 수 있다.
            
            e.g. 코딩 문제 해결 관련 쿼리 → Opus 4.5 / Qwen2.5-Coder-32B
            
        2. 모든 쿼리에 고비용 모델을 사용하는 대신 간단한 쿼리는 더 저렴한 모델로 라우팅하여 비용을 효율적으로 관리할 수 있다.
            
            e.g. 단순 정보 요청(비밀번호 재설정과 관련된 쿼리) → BERT(의도 분류기) → 관련 FAQ 페이지로 라우팅
            
        </aside>
        
    - Q6. 모델 게이트웨이(Model Gateway)의 정의와 이것이 제공하는 핵심 기능 3가지를 설명하십시오.
        
        <aside>
        💡
        
        모델 게이트웨이
        
        : 조직이 다양한 모델(자체 호스팅 및 외부 API)과 안전하고 통일된 방식으로 상호작용할 수 있도록 돕는 중간 계층(layer)
        
        핵심기능
        
        1. 다양한 모델에 대한 통합 인터페이스 제공
        2. 중앙화된 접근 제어 및 비용 관리
        3. API 장애 시 대안 모델로 연결하는 장애 조치(Fallback) 기능 수행
        </aside>
        
    - Q7. '정확한 캐싱(Exact Caching)'과 '의미적 캐싱(Semantic Caching)'의 차이점을 설명하고, 의미적 캐싱이 가질 수 있는 위험 요소(Risk)에 대해 논하십시오.
        
        <aside>
        💡
        
        - **정확한 캐싱 (Exact Caching) :** 사용자의 쿼리가 이전에 처리되어 캐시에 저장된 항목과 **정확히 일치할 때만** 캐싱된 결과를 사용합니다.
        - **의미적 캐싱 (Semantic Caching):** 입력된 쿼리가 기존 캐시 항목과 문구는 다르더라도 **의미적으로 유사할 경우** 캐싱된 결과를 재사용합니다
        - **의미적 캐싱의 위험 요소 (Risk)**
            1. **정확성 저하 및 오답 반환:** 사용자의 질문이 미세하게 다름에도 불구하고 시스템이 "같은 의미"라고 잘못 판단할 수 있습니다.
            2. **데이터 유출(Data Leak) 위험:** 특정 사용자의 정보가 포함된 응답이 캐시될 경우, 다른 사용자가 유사한 질문을 했을 때 해당 **개인정보가 노출될 위험**이 있습니다. 
            3. **임계값 설정의 어려움:** 유사도를 판단하는 **임계값을 설정하는 과정이 까다롭고** 많은 시행착오를 필요로 합니다.
            4. **컴퓨팅 오버헤드:** 의미적 캐싱은 단순 조회가 아닌 **벡터 검색 과정**을 거쳐야 하므로, 캐시 크기가 커질수록 검색 시간이 길어지고 컴퓨팅 자원을 많이 소모하게 됩니다.
        
        **요약하자면**, 정확한 캐싱은 **일치성**을 중시하여 안전하지만 범위가 좁고, 의미적 캐싱은 **효율성**을 극대화하지만 **정확성과 보안 측면에서 추가적인 검토**가 필수적입니다.
        
        </aside>
        
    - Q8. AI 시스템에 '쓰기 작업(Write Actions)'을 부여할 때 발생할 수 있는 이점과 위험성을 비교하여 설명하십시오.
        
        <aside>
        💡
        
        **1. 쓰기 작업의 이점: 자동화 범위의 극대화**
        
        - **엔드투엔드(End-to-End) 워크플로 완성:** 쓰기 작업은 시스템이 단순한 정보 조회를 넘어 **실질적인 과업을 완수**할 수 있게 합니다.
        - **시스템 역량의 비약적 향상:** 모델이 쓰기 작업을 수행할 수 있게 되면 이메일 작성, 주문 처리, 은행 송금과 같은 작업을 수행할 수 있어 **시스템이 훨씬 더 유능해집니다**.
        
        **2. 쓰기 작업의 위험성: 심각한 보안 및 안전 사고**
        
        - **높은 이해관계와 사고 위험:** 시스템이 현실 세계나 데이터 원천에 직접 변화를 줄 수 있기 때문에, **신뢰할 수 없는 AI가 잘못된 작업(예: 잘못된 은행 송금)을 수행할 경우 그 결과가 치명적**일 수 있습니다.
        - **보안 취약점 악용:** 악의적인 공격자가 시스템을 조종하여 **권한이 없는 코드를 실행하거나 데이터베이스의 항목을 삭제**하도록 유도하는 등 심각한 보안 리스크를 초래할 수 있습니다.
        - **비물리적·광범위한 피해:** 쓰기 작업을 가진 AI는 주식 시장 조작, 저작권 침해, 개인정보 보호 위반, 편향 강화 및 허위 정보 유포 등 **사회적으로 광범위한 피해를 입힐 잠재력**을 가집니다.
        </aside>
        
    - Q9. 기존 소프트웨어 엔지니어링에서의 '모니터링(Monitoring)'과 '관측 가능성(Observability)'의 개념적 차이를 AI 시스템의 관점에서 설명하십시오.
        
        <aside>
        💡
        
        1. 모니터링
        - 시스템의 외부 출력을 지속적으로 관찰해서 내부에서 문제가 발생하는 시점을 알아내는 활동, 하지만 그것만으로 문제의 원인을 파악할 수 있다는 보장은 없음
        1. 관찰 가능성
        - 시스템에 문제가 발생했을 때 그 원인을 파악하는데 도움이 되도록 시스템의 런타임에 대한 충분한 정보를 수집하고 분석할 수 있게 시스템을 계측하는 것을 의미함.
        </aside>
        
    - Q10. AI 애플리케이션 운영 중 발생할 수 있는 3가지 주요 드리프트(Drift) 유형을 나열하고 각각에 대해 간략히 설명하십시오.
        
        <aside>
        💡
        
        - 드리프트 : 학습에 사용했던 데이터와 실제 데이터가 서로 달라지면서 ai의 성능이 떨어지는 현상
            1. 시스템 프롬프트 변경
                - 템플릿 업데이트나 오타 수정 등으로 지시문이 바뀜,
                - ai에게 내리는 지시가 달라져서 결과가 변함
            2. 사용자 행동 변화
                - 사용자가 더 나은 결과를 얻기 위해 질문 방식을 바꿈
                - ai 로 들어오는 질문 내용의 성격이 변함
            3. 기반 모델 변경
                - 모델 자체가 업데이트되거나 버전이 바뀜
                - ai의 뇌 자체가 바껴서 성능이나 말투가 변함
        </aside>
        
    - Q11. AI 파이프라인 오케스트레이터(Orchestrator)를 도입할 때 고려해야 할 3가지 주요 평가 기준은 무엇입니까?
        
        <aside>
        💡
        
        </aside>
        
    - Q12. 사용자 피드백 중 '명시적 피드백(Explicit Feedback)'과 '암시적 피드백(Implicit Feedback)'의 차이를 정의하고, 대화형 인터페이스에서의 예시를 들어 설명하십시오.
        
        <aside>
        💡
        
        </aside>
        
    - Q13. 자연어 피드백(Natural Language Feedback)에서 사용자의 만족/불만족을 파악할 수 있는 신호(Signal) 3가지를 설명하십시오.
        
        <aside>
        💡
        
        </aside>
        
    - Q14. 사용자 피드백 수집 시 발생할 수 있는 '관대함 편향(Leniency Bias)'이란 무엇이며, 이를 완화하기 위한 방법은 무엇입니까?
        
        <aside>
        💡
        
        </aside>
        
    - Q15. 사용자 피드백을 모델 학습에 반영할 때 발생할 수 있는 '퇴행적 피드백 루프(Degenerate Feedback Loop)' 현상에 대해 설명하십시오.
        
        <aside>
        💡
        
        </aside>
        
    
    ---
    
    ### 📚 예시 답안
    
    - A1.
        
        AI 애플리케이션 아키텍처는 다음과 같은 5단계로 발전합니다.
        
        1. **단순 모델 API:** 쿼리를 모델에 보내고 응답을 받는 가장 기본적인 형태입니다.
        2. **컨텍스트 구성:** 검색(Retrieval)이나 도구(Tool)를 통해 모델에 필요한 외부 정보를 제공하여 컨텍스트를 강화합니다.
        3. **가드레일 추가:** 입력과 출력에 대한 안전 장치를 마련하여 개인정보 유출이나 유해한 응답을 방지합니다.
        4. **라우터 및 게이트웨이 추가:** 쿼리 의도에 따라 적절한 모델로 연결하는 라우터와, 통합 인터페이스 및 보안을 담당하는 게이트웨이를 도입합니다.
        5. **캐시 및 에이전트 패턴:** 대기 시간과 비용을 줄이기 위해 캐시를 추가하고, 루프나 쓰기 작업(Write Action)이 가능한 에이전트 패턴으로 확장합니다.
    - A2.
        
        컨텍스트 구성은 모델이 질문에 답하는 데 필요한 관련 정보를 검색(Retrieval)하거나 도구(Tool)를 통해 수집하여 제공하는 과정입니다. 이는 파운데이션 모델에게 필요한 정보를 제공하여 출력을 생성하게 한다는 점에서 전통적인 머신러닝의 '피처 엔지니어링(Feature Engineering)'에 비유됩니다. 적절한 컨텍스트가 없으면 모델은 정확한 답변을 할 수 없으므로, 출력 품질에 결정적인 역할을 합니다.
        
    - A3.
        
        PII 마스킹 및 언마스킹 과정은 다음과 같습니다.
        
        1. 사용자 쿼리에서 전화번호나 주소 같은 민감한 정보를 탐지합니다.
        2. 탐지된 정보를 `[PHONE NUMBER]`와 같은 플레이스홀더로 마스킹(치환)하여 외부 API로 전송되는 것을 막습니다.
        3. 이때, 원래 정보와 플레이스홀더를 매핑하는 '가역적 PII 맵(Reversible PII map)'을 저장합니다.
        4. 모델이 응답을 생성하면, 응답 내의 플레이스홀더를 PII 맵을 이용해 다시 원래 정보로 복원(언마스킹)하여 사용자에게 제공합니다.
    - A4.
        
        출력 가드레일의 두 가지 주요 기능은 출력 실패를 감지하는 것과 실패 모드에 따른 처리 정책을 지정하는 것입니다 .
        
        - **품질 실패:** 잘못된 JSON 포맷과 같이 형식이 어긋나거나, 사실과 다른 환각(Hallucination)을 포함하는 경우입니다 .
        - **보안 실패:** 인종차별적 발언이나 성적 콘텐츠 같은 유해한 응답, 또는 개인정보가 포함된 응답을 생성하는 경우입니다.
    - A5.
        
        모델 라우터(Router)를 사용하면 다음과 같은 이점이 있습니다.
        
        1. **전문화된 성능:** 모든 쿼리를 일반 모델로 처리하는 대신, 기술 문제 해결이나 결제 관련 등 특정 주제에 특화된 모델로 라우팅하여 더 나은 성능을 얻을 수 있습니다.
        2. **비용 절감:** 모든 쿼리에 값비싼 모델을 사용하는 대신, 간단한 쿼리는 더 저렴한 모델로 보내 비용을 아낄 수 있습니다.
    - A6.
        
        모델 게이트웨이는 조직이 다양한 모델(서드파티 API 및 자체 호스팅 모델)과 상호작용할 수 있도록 하는 통합된 중간 계층입니다.
        
        핵심 기능 3가지는 다음과 같습니다.
        
        1. **통합 인터페이스 제공:** API가 변경되어도 게이트웨이만 수정하면 되므로 코드 유지보수가 용이합니다.
        2. **접근 제어 및 비용 관리:** 중앙화된 접근 권한 관리와 사용량 제한을 통해 보안을 강화하고 비용을 통제할 수 있습니다.
        3. **장애 조치(Fallback):** 주 모델 API에 장애가 발생했을 때 대안 모델로 라우팅하거나 재시도하는 로직을 구현할 수 있습니다.
    - A7.
        - *정확한 캐싱(Exact Caching)**은 요청된 쿼리가 캐시에 저장된 항목과 정확히 일치할 때만 저장된 응답을 반환합니다. 반면, **의미적 캐싱(Semantic Caching)**은 쿼리가 정확히 일치하지 않아도 의미적으로 유사하다면(예: 임베딩 유사도 기반) 캐시된 응답을 재사용합니다.
        - 의미적 캐싱의 위험 요소로는 잘못된 유사도 판단으로 인해 엉뚱한 응답을 반환할 수 있다는 점과, 사용자별 정보(예: 내 주문 내역)가 다른 사용자에게 유출될 수 있는 데이터 누수 위험이 있습니다.
    - A8.
        
        쓰기 작업(Write Actions)을 추가하면 시스템이 이메일을 보내거나 주문을 넣는 등 환경을 직접 변경할 수 있어 시스템의 능력이 크게 확장됩니다. 하지만 이는 동시에 시스템이 오작동하거나 공격받았을 때 실제 세계에 직접적인 피해를 줄 수 있는 위험(Risk)도 크게 증가시킵니다. 따라서 쓰기 권한 부여는 매우 신중하게 이루어져야 합니다.
        
    - A9.
        
        전통적인 모니터링은 시스템의 외부 출력만을 추적하여 내부의 문제를 파악하려 하며, 출력이 내부 상태를 보장하지 않습니다. 반면 **관측 가능성(Observability)**은 시스템의 외부 출력을 통해 내부 상태를 추론할 수 있다는 더 강력한 가정을 전제로 합니다. 즉, 관측 가능성은 문제가 발생했을 때 새로운 코드를 배포하지 않고도 로그와 지표만으로 왜 문제가 발생했는지 파악할 수 있도록 시스템을 계측(Instrumenting)하는 과정을 포함합니다.
        
    - **A10.**
        1. **시스템 프롬프트 변경:** 프롬프트 템플릿 업데이트나 오타 수정 등으로 인해 알지 못하는 사이에 시스템 프롬프트가 변경되는 경우입니다.
        2. **사용자 행동 변화:** 사용자들이 더 나은 결과를 얻기 위해 쿼리 방식을 변경(예: 더 간결하게 질문)함에 따라 입력 데이터의 분포가 변하는 것입니다.
        3. **기반 모델 변경:** API 제공자가 예고 없이 모델을 업데이트하여, 동일한 API를 사용함에도 성능이나 동작이 달라지는 경우입니다.
    - A11.
        
        오케스트레이터를 평가할 때 다음 3가지를 고려해야 합니다.
        
        1. **통합 및 확장성:** 현재 사용 중이거나 미래에 사용할 구성 요소(모델, 데이터베이스 등)를 지원하는지, 지원하지 않는 경우 얼마나 쉽게 확장할 수 있는지 확인해야 합니다.
        2. **복잡한 파이프라인 지원:** 분기(branching), 병렬 처리, 에러 핸들링 등 복잡한 로직을 효율적으로 관리할 수 있는 기능을 제공하는지 평가해야 합니다.
        3. **사용 편의성, 성능 및 확장성:** 직관적인 API와 문서를 제공하는지, 그리고 숨겨진 API 호출로 지연 시간을 유발하지 않고 트래픽 증가에 따라 확장 가능한지 고려해야 합니다.
    - A12.
        - *명시적 피드백(Explicit Feedback)**은 사용자가 '좋아요/싫어요', '별점' 등 시스템의 요청에 대해 직접적으로 제공하는 피드백입니다.
        - *암시적 피드백(Implicit Feedback)**은 사용자의 행동을 통해 간접적으로 추론하는 피드백입니다. 대화형 인터페이스에서는 사용자가 응답 생성을 중간에 멈추거나(부정적), 대화를 길게 이어가는 것(긍정적 또는 부정적일 수 있음) 등이 예시가 될 수 있습니다.
    - **A13.**
        1. **조기 종료(Early Termination):** 사용자가 응답 생성을 중간에 중단하거나 앱을 종료하는 것은 대화가 잘 진행되지 않고 있다는 신호일 수 있습니다.
        2. **오류 수정(Error Correction):** 사용자가 "아니, 내 말은..."이나 "다시 확인해 봐"라고 말하며 수정을 요청하는 것은 모델의 응답이 틀렸거나 불충분하다는 신호입니다.
        3. **감정 표현(Sentiment):** 사용자의 메시지에서 좌절, 실망 등의 부정적 감정이 드러나거나, 반대로 긍정적인 감정이 드러나는 것을 통해 만족도를 파악할 수 있습니다.
    - A14.
        - *관대함 편향(Leniency Bias)**은 사용자가 갈등을 피하거나 귀찮음을 덜기 위해 실제보다 더 긍정적인 평가(예: 5점 만점에 5점)를 내리는 경향입니다. 이를 완화하기 위해서는 낮은 등급에 대한 부정적인 느낌을 줄이고 구체적인 선택지를 제공하는 것이 좋습니다. 예를 들어, 단순한 숫자 등급 대신 "불평할 것은 없지만 훌륭하지도 않음"과 같이 구체적인 문장으로 된 선택지를 제시할 수 있습니다.
    - A15.
        - *퇴행적 피드백 루프(Degenerate Feedback Loop)**는 모델의 예측 결과가 사용자 피드백에 영향을 주고, 이 피드백이 다시 모델 학습에 반영되어 초기 편향이 증폭되는 현상입니다 . 예를 들어, 추천 시스템이 상위에 노출한 콘텐츠가 더 많은 클릭을 받아 계속해서 추천되는 현상이 있습니다. 대화형 AI에서는 모델이 사용자의 의견에 무조건 동조하는 **아첨꾼(Sycophancy)**이 되어, 정확성보다 사용자가 듣고 싶어 하는 말을 하도록 학습되는 부작용을 낳을 수 있습니다.

## 회고

템플릿

- 템플릿(복사해서 사용)
    - Keep: 스터디간 좋았고 계속해서 유지하고 싶은 나의 습관이나 학습전략
    - Problem: 스터디간 어려웟던 점이나 아쉬웠던점
    - Try: Problem을 극복하기 위해서 다음 스터디에서 해볼만한 개선안
- 임정
    - Keep
        - [학습 관련] 데이터 관련 챕터는 정말 좋았다. ML에서의 AI로 관점을 더 확장시킬 수 있는 좋은 단원이였음
        - 팀장 없이 스스로 돌아가는 시스템을 만든것, 나의 부재를 채울 수 있었다. (NotebookLM)
    - Problem: 이론적인 부분만 한다는게 늘 아쉬움, 1시간내 할 수 있는것이 정해져 있다. 아예 시간을 더 배분해서 해야할까?
    - Try
        - n8n이나 간단한 langchain/graph로 개념증명(PoC)을 하는 시간을 가지면 어떨까? 개념증명의 정의가 어렵고, 각 챕터별 발제자의 난이도가 올라갈 수 있을 것 같다.
        - 노션이 접근성이 좋긴하지만 이제 Github 같은 오픈 프로젝트로 넘기는게 추후 자료증빙이나 공유에도 편할 것 같다.
- 효진
    
    Keep: 매주 정해진 분량을 읽고 노션에 정리한 것
    - 이해한 내용으로만 끝나는게 아니라 발표하면서 한번 더 정리하고 풀어서 설명을 하면서 두번 복습하게 되고 좀더 깊이 이해하는데 많은 도움이 되었음
    - 단순 이해가 아니라 “왜 이런게 필요하지?”를 개인적으로 질문하면서 읽은 점이 책을 이해하는데 많은 도움이 되었음
    - 스터디원들끼리 각자 이해한 방식으로 설명해보는 과정에서 개념이 더 명확해졌음
    
    Problem: 
    - 시스템 관점 설명이 많다 보니 처음엔 추상적으로 느껴진 부분이 많았음
    - 용어가 한 번에 이해되기보다는 검색해보거나 이해해야 했음(이건 부족한 저의 문제이니 남탓은 못함ㅜ 직접 챗지피티랑 제민이한테 물어보면서 많이 배웠음)
    - 실제 서비스 경험이 없으면 “왜 필요한지” 감이 잘 안 오는 챕터들도 있었음
    
    Try: 
    - 각 장마다 “이게 실제 서비스에서 언제 필요해지는지”를 참고 예시 모델을 보면 더욱 도움이 될것 같음
    
    - 뭐 하나 만들어 보고싶음
    
- 도현
    1. Keep: 스터디간 좋았고 계속해서 유지하고 싶은 나의 습관이나 학습전략
        - 최종 프로젝트 당시 3장, 4장(LLM 평가 부분) 내용을 프로젝트에 바로 적용하면서 도움이 되었다. 프로젝트를 수행할 때 항상 관련 reference 중 특히 잘 정리된 이론서나 핸즈온 실무서를 먼저 조사하는 습관을 가지고 스터디를 진행했다. 내가 보는 책이 곧 내 수준을 결정하게 되는 것 같다. 앞으로도 우선순위에 맞게 필요한 책들을 독파해 가면 지속적인 성장을 성취할 수 있을 것이라고 생각한다.
            
            ![image.png](AI%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81%20%EC%8A%A4%ED%84%B0%EB%94%94/image%202.png)
            
            ![image.png](AI%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81%20%EC%8A%A4%ED%84%B0%EB%94%94/image%203.png)
            
            ![image.png](AI%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81%20%EC%8A%A4%ED%84%B0%EB%94%94/image%204.png)
            
            ![image.png](AI%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81%20%EC%8A%A4%ED%84%B0%EB%94%94/image%205.png)
            
    2. Problem: 스터디간 어려웟던 점이나 아쉬웠던점
        - 업무 관련해서 새로운 우선순위가 생겨서 5장부터는 책을 정독하지는 못했다.
    3. Try: Problem을 극복하기 위해서 다음 스터디에서 해볼만한 개선안
        - 그러나 추후 업무에 LLM, RAG, Agentic AI를 적용해야 하는 시간표가 있는데, 그때 가서 제대로 정독할 수 있을 거라고 생각한다.
        - LLM 관련 프로젝트를 진행하면서 내가 구현한 RAG/Agentic AI 핵심 로직은 API 개발까지 내가 구현해야 할 필요성과 책임감을 느꼈다. 최근 에이콘출판에서 AI/데이터사이언스 관점에서 쓰여진 API 책이 나왔다. 내용을 보니 도움이 많이 될 것 같다. 나중에 읽어볼 예정.
            
            [AI와 데이터 사이언스 API](http://www.acornpub.co.kr/book/9791161758374)
            
- 이승형
    - Keep: 매주 한단원씩 책을 읽는게 좋았음. 앞으로 의무적으로라도 책을 조금씩 읽고 싶다.
    - Problem: 번역서라 그런지 아니면 급하게 읽어서 그런지 내용이 이해가 잘 안되는 부분이 있었다
    - Try: 나중에 시간을 좀 투자해서 원서로 읽어보고 싶다
- 최유희
    - Keep: 스터디간 좋았고 계속해서 유지하고 싶은 나의 습관이나 학습전략
        - **구체적인 기간과 분량**을 정해서 읽으니까 명확한 목표 의식이 생기고, 확실히 혼자 읽을 때보다 완독률이 높아졌다고 할 수 있을 것 같습니다
        - 다른 분들이 정리한 내용을 보면서 내가 놓쳤던 부분도 한번 더 짚고 넘어갈 수 있어서 좋았습니다.
    - Problem: 스터디간 어려웠던 점이나 아쉬웠던 점
        - 한번 읽는 것만으로는 전체 내용을 완전히 내 것으로는 소화하지 못했다 라는 깊이에 대한 아쉬움이 남습니다.
        - 실제 사례나 제 프로젝트에 어떻게 적용할지 고민해보지 못했던 게 아쉽습니다.
    - Try: Problem을 극복하기 위해서 다음 스터디에서 해볼만한 개선안
        - 문제를 풀때 확실히 머리속에 남는 게 많은 것 같아서 내 문제를 풀고나서 다른 문제들도 풀어보면서 체득하면 좋을 것 같습니다.
        - 실제로 해당 개념이 적용된 프로젝트나 다른 읽을 거리를 읽어보고 팀원들과 공유해보는 것도 좋을 것 같습니다.
        
- 홍현경
    
    keep: **강제성을 통한 학습 연속성 확보 -** 이어드림이 끝난 후 ai관련 공부에 대해 헤이해질 때마다 매주 일요일 스터디를 통해 AI 공부의 흐름을 유지할 수 있었던거 같음. 스터디가 끝난 후에도 특정 시간을 정해 이 분야에 대해 계속 학습을 이어가고 싶음.
    
    problem: 전반적인 책의 내용을 다 이해하는 것 보다는 내가 푼 문제만 이해를 하는거 같다.
    
    try:  그래도 개인 참여 방식이라 내가 푼 문제라도 지식을 들고 갈 수 있어 문제를 정해서 각자 풀고 돌아가면서 발표는 하는건 좋은 것 같다. 하지만 다른 사람의 답은 잘 안듣거나 그냥 흘려듣게 되는거 같은데 어떤걸 시도하는게 좋을까 제미나이에 물어봄→ 스터디 마지막 5~10분 동안 각자 발표한 내용에서 짧은 퀴즈를 하나씩 내고 다 같이 맞히는 시간을 가집니다. 맞히기 위해서라도 다른 사람의 설명을 집중해서 듣게 된다고 추천해줌.