# 10단원

    
    ### 💡 문제 출제
    
    - Q1. AI 애플리케이션 아키텍처가 단순한 모델 API 호출에서 시작하여 점차 복잡해지는 5단계 과정을 순서대로 요약하여 설명하십시오.
        
        <aside>
        💡
        
        **1. 단순 모델 API 호출**
        
        사용자의 입력을 그대로 모델에 전달하고, 모델의 응답을 그대로 반환하는 가장 기본적인 구조
        
        별도의 맥락 보강, 안전 장치, 최적화 없이 빠르게 프로토타입을 만들 수 있음
        
        **2. 컨텍스트 강화(Context Construction)**
        
        외부 문서, 데이터베이스, 검색, 도구 등을 활용해 모델이 참고할 추가 정보를 제공한다. 이를 통해 모델이 더 정확하고 맥락에 맞는 응답을 생성할 수 있음
        
        **3. 가드레일(Guardrails) 추가**
        
        입력과 출력에 대한 검증을 통해 보안, 개인정보 보호, 품질 문제를 방지
        
        민감 정보 유출, 잘못된 응답, 정책 위반 등의 위험을 줄이기 위한 단계
        
        **4. 모델 라우터 및 게이트웨이 도입**
        
        여러 모델과 도구를 효율적으로 관리하기 위해 라우팅과 통합 인터페이스를 추가함
        
        요청 유형에 따라 적절한 모델을 선택하고, 보안·비용·접근 제어를 중앙에서 관리함
        
        **5. 캐싱 및 에이전트 패턴 적용**
        
        캐시를 통해 지연 시간과 비용을 줄이고, 반복·분기·루프 구조를 갖는 에이전트 패턴을 통해 복잡한 작업을 수행할 수 있도록 확장함
        
        → 이러한 단계적 확장은 품질, 안전성, 비용, 확장성을 균형 있게 만족시키기 위한 현실적인 발전 과정
        
        </aside>
        
    - Q2. AI 아키텍처에서 '컨텍스트 구성(Context Construction)'의 역할은 무엇이며, 이것이 왜 모델의 출력 품질에 중요한지 설명하십시오.
        
        <aside>
        💡
        
        - **컨텍스트 구성의 역할**
        컨텍스트 구성(Context Construction)은 모델이 응답을 생성할 때 참고해야 할 정보를 **외부 시스템에서 수집·선별·조합하여 입력 프롬프트에 포함시키는 아키텍처 단계**임
        여기에는 검색 결과, 데이터베이스 조회 결과, 사용자 상태, 이전 대화 이력 등이 포함됨
        - **출력 품질에 중요한 이유**
        대형 언어 모델은 입력으로 주어진 컨텍스트에 강하게 의존하여 응답을 생성하므로 컨텍스트가 부족하거나 부정확할 경우 환각(hallucination)이나 부정확한 응답이 발생함
        반대로, 적절하게 구성된 컨텍스트를 제공하면 모델의 추론 정확도와 응답의 신뢰성이 크게 향상됨
        
        → 따라서 컨텍스트 구성은 모델을 변경하지 않고도 출력 품질을 개선할 수 있는 핵심 아키텍처 요소임
        
        </aside>
        
    - Q3. 입력 가드레일(Input Guardrails)에서 PII(개인식별정보) 유출을 방지하기 위해 사용하는 '마스킹(Masking) 및 언마스킹(Unmasking)' 기법의 작동 원리를 단계별로 설명하십시오.
        
        <aside>
        💡
        
        1. **PII 탐지**
        사용자 입력에서 전화번호, 주소와 같은 개인정보를 탐지
        2. **마스킹(Masking)**
        탐지된 개인정보를 [PHONE NUMBER]와 같은 플레이스홀더로 마스킹하여 원래 개인정보가 외부 API로 전달되지 않도록 함
        3. **가역적 PII 맵 저장**
        마스킹에 사용된 플레이스홀더와 원래 개인정보를 연결하는 가역적 PII 맵을 내부적으로 저장함
        4. **언마스킹(Unmasking)**
        모델이 생성한 응답에 플레이스홀더가 포함된 경우, 저장된 PII 맵을 이용해 해당 부분을 원래 개인정보로 복원한 후 사용자에게 제공함
        
        → 이를 통해 외부로는 개인정보를 숨기면서 사용자에게는 자연스러운 응답을 제공할 수 있음
        
        </aside>
        
    - Q4. 출력 가드레일(Output Guardrails)의 두 가지 주요 기능과, 이를 통해 감지하고자 하는 대표적인 실패 유형(품질 및 보안 측면)을 설명하십시오.
        
        <aside>
        💡
        
        - 출력 가드레일 두 가지 주요 기능
            1. 모델의 출력 실패 감지
            2. 각 실패 모드에 대한 처리 정책을 지정
        - 실패 유형
            - 품질
                1. 유효하지 않은 JSON과 같은 포맷 오류
                2. 사실과 다른 환각
                3. 낮은 품질의 답변
            - 보안
                1. 혐오 발언
                2. 개인정보를 포함한 답변
                3. 원격 도구나 코드 실행을 사용하는 답변
        </aside>
        
    - Q5. 모델 라우터(Router)를 도입했을 때 얻을 수 있는 주요 이점 두 가지를 구체적인 예시와 함께 설명하십시오.
        
        <aside>
        💡
        
        모델 라우터
        
        : 모든 사용자 쿼리를 하나의 모델로 처리하는 대신, 쿼리의 의도를 분석하여 가장 적합한 모델이나 솔루션으로 연결해 주는 시스템 구성 요소
        
        주요 이점
        
        1. 쿼리의 주제에 특화된 모델을 사용하여 범용 모델보다 더 나은 성능을 낼 수 있다.
            
            e.g. 코딩 문제 해결 관련 쿼리 → Opus 4.5 / Qwen2.5-Coder-32B
            
        2. 모든 쿼리에 고비용 모델을 사용하는 대신 간단한 쿼리는 더 저렴한 모델로 라우팅하여 비용을 효율적으로 관리할 수 있다.
            
            e.g. 단순 정보 요청(비밀번호 재설정과 관련된 쿼리) → BERT(의도 분류기) → 관련 FAQ 페이지로 라우팅
            
        </aside>
        
    - Q6. 모델 게이트웨이(Model Gateway)의 정의와 이것이 제공하는 핵심 기능 3가지를 설명하십시오.
        
        <aside>
        💡
        
        모델 게이트웨이
        
        : 조직이 다양한 모델(자체 호스팅 및 외부 API)과 안전하고 통일된 방식으로 상호작용할 수 있도록 돕는 중간 계층(layer)
        
        핵심기능
        
        1. 다양한 모델에 대한 통합 인터페이스 제공
        2. 중앙화된 접근 제어 및 비용 관리
        3. API 장애 시 대안 모델로 연결하는 장애 조치(Fallback) 기능 수행
        </aside>
        
    - Q7. '정확한 캐싱(Exact Caching)'과 '의미적 캐싱(Semantic Caching)'의 차이점을 설명하고, 의미적 캐싱이 가질 수 있는 위험 요소(Risk)에 대해 논하십시오.
        
        <aside>
        💡
        
        - **정확한 캐싱 (Exact Caching) :** 사용자의 쿼리가 이전에 처리되어 캐시에 저장된 항목과 **정확히 일치할 때만** 캐싱된 결과를 사용합니다.
        - **의미적 캐싱 (Semantic Caching):** 입력된 쿼리가 기존 캐시 항목과 문구는 다르더라도 **의미적으로 유사할 경우** 캐싱된 결과를 재사용합니다
        - **의미적 캐싱의 위험 요소 (Risk)**
            1. **정확성 저하 및 오답 반환:** 사용자의 질문이 미세하게 다름에도 불구하고 시스템이 "같은 의미"라고 잘못 판단할 수 있습니다.
            2. **데이터 유출(Data Leak) 위험:** 특정 사용자의 정보가 포함된 응답이 캐시될 경우, 다른 사용자가 유사한 질문을 했을 때 해당 **개인정보가 노출될 위험**이 있습니다. 
            3. **임계값 설정의 어려움:** 유사도를 판단하는 **임계값을 설정하는 과정이 까다롭고** 많은 시행착오를 필요로 합니다.
            4. **컴퓨팅 오버헤드:** 의미적 캐싱은 단순 조회가 아닌 **벡터 검색 과정**을 거쳐야 하므로, 캐시 크기가 커질수록 검색 시간이 길어지고 컴퓨팅 자원을 많이 소모하게 됩니다.
        
        **요약하자면**, 정확한 캐싱은 **일치성**을 중시하여 안전하지만 범위가 좁고, 의미적 캐싱은 **효율성**을 극대화하지만 **정확성과 보안 측면에서 추가적인 검토**가 필수적입니다.
        
        </aside>
        
    - Q8. AI 시스템에 '쓰기 작업(Write Actions)'을 부여할 때 발생할 수 있는 이점과 위험성을 비교하여 설명하십시오.
        
        <aside>
        💡
        
        **1. 쓰기 작업의 이점: 자동화 범위의 극대화**
        
        - **엔드투엔드(End-to-End) 워크플로 완성:** 쓰기 작업은 시스템이 단순한 정보 조회를 넘어 **실질적인 과업을 완수**할 수 있게 합니다.
        - **시스템 역량의 비약적 향상:** 모델이 쓰기 작업을 수행할 수 있게 되면 이메일 작성, 주문 처리, 은행 송금과 같은 작업을 수행할 수 있어 **시스템이 훨씬 더 유능해집니다**.
        
        **2. 쓰기 작업의 위험성: 심각한 보안 및 안전 사고**
        
        - **높은 이해관계와 사고 위험:** 시스템이 현실 세계나 데이터 원천에 직접 변화를 줄 수 있기 때문에, **신뢰할 수 없는 AI가 잘못된 작업(예: 잘못된 은행 송금)을 수행할 경우 그 결과가 치명적**일 수 있습니다.
        - **보안 취약점 악용:** 악의적인 공격자가 시스템을 조종하여 **권한이 없는 코드를 실행하거나 데이터베이스의 항목을 삭제**하도록 유도하는 등 심각한 보안 리스크를 초래할 수 있습니다.
        - **비물리적·광범위한 피해:** 쓰기 작업을 가진 AI는 주식 시장 조작, 저작권 침해, 개인정보 보호 위반, 편향 강화 및 허위 정보 유포 등 **사회적으로 광범위한 피해를 입힐 잠재력**을 가집니다.
        </aside>
        
    - Q9. 기존 소프트웨어 엔지니어링에서의 '모니터링(Monitoring)'과 '관측 가능성(Observability)'의 개념적 차이를 AI 시스템의 관점에서 설명하십시오.
        
        <aside>
        💡
        
        1. 모니터링
        - 시스템의 외부 출력을 지속적으로 관찰해서 내부에서 문제가 발생하는 시점을 알아내는 활동, 하지만 그것만으로 문제의 원인을 파악할 수 있다는 보장은 없음
        1. 관찰 가능성
        - 시스템에 문제가 발생했을 때 그 원인을 파악하는데 도움이 되도록 시스템의 런타임에 대한 충분한 정보를 수집하고 분석할 수 있게 시스템을 계측하는 것을 의미함.
        </aside>
        
    - Q10. AI 애플리케이션 운영 중 발생할 수 있는 3가지 주요 드리프트(Drift) 유형을 나열하고 각각에 대해 간략히 설명하십시오.
        
        <aside>
        💡
        
        - 드리프트 : 학습에 사용했던 데이터와 실제 데이터가 서로 달라지면서 ai의 성능이 떨어지는 현상
            1. 시스템 프롬프트 변경
                - 템플릿 업데이트나 오타 수정 등으로 지시문이 바뀜,
                - ai에게 내리는 지시가 달라져서 결과가 변함
            2. 사용자 행동 변화
                - 사용자가 더 나은 결과를 얻기 위해 질문 방식을 바꿈
                - ai 로 들어오는 질문 내용의 성격이 변함
            3. 기반 모델 변경
                - 모델 자체가 업데이트되거나 버전이 바뀜
                - ai의 뇌 자체가 바껴서 성능이나 말투가 변함
        </aside>
        
    - Q11. AI 파이프라인 오케스트레이터(Orchestrator)를 도입할 때 고려해야 할 3가지 주요 평가 기준은 무엇입니까?
        
        <aside>
        💡
        
        </aside>
        
    - Q12. 사용자 피드백 중 '명시적 피드백(Explicit Feedback)'과 '암시적 피드백(Implicit Feedback)'의 차이를 정의하고, 대화형 인터페이스에서의 예시를 들어 설명하십시오.
        
        <aside>
        💡
        
        </aside>
        
    - Q13. 자연어 피드백(Natural Language Feedback)에서 사용자의 만족/불만족을 파악할 수 있는 신호(Signal) 3가지를 설명하십시오.
        
        <aside>
        💡
        
        </aside>
        
    - Q14. 사용자 피드백 수집 시 발생할 수 있는 '관대함 편향(Leniency Bias)'이란 무엇이며, 이를 완화하기 위한 방법은 무엇입니까?
        
        <aside>
        💡
        
        </aside>
        
    - Q15. 사용자 피드백을 모델 학습에 반영할 때 발생할 수 있는 '퇴행적 피드백 루프(Degenerate Feedback Loop)' 현상에 대해 설명하십시오.
        
        <aside>
        💡
        
        </aside>
        
    
    ---
    
    ### 📚 예시 답안
    
    - A1.
        
        AI 애플리케이션 아키텍처는 다음과 같은 5단계로 발전합니다.
        
        1. **단순 모델 API:** 쿼리를 모델에 보내고 응답을 받는 가장 기본적인 형태입니다.
        2. **컨텍스트 구성:** 검색(Retrieval)이나 도구(Tool)를 통해 모델에 필요한 외부 정보를 제공하여 컨텍스트를 강화합니다.
        3. **가드레일 추가:** 입력과 출력에 대한 안전 장치를 마련하여 개인정보 유출이나 유해한 응답을 방지합니다.
        4. **라우터 및 게이트웨이 추가:** 쿼리 의도에 따라 적절한 모델로 연결하는 라우터와, 통합 인터페이스 및 보안을 담당하는 게이트웨이를 도입합니다.
        5. **캐시 및 에이전트 패턴:** 대기 시간과 비용을 줄이기 위해 캐시를 추가하고, 루프나 쓰기 작업(Write Action)이 가능한 에이전트 패턴으로 확장합니다.
    - A2.
        
        컨텍스트 구성은 모델이 질문에 답하는 데 필요한 관련 정보를 검색(Retrieval)하거나 도구(Tool)를 통해 수집하여 제공하는 과정입니다. 이는 파운데이션 모델에게 필요한 정보를 제공하여 출력을 생성하게 한다는 점에서 전통적인 머신러닝의 '피처 엔지니어링(Feature Engineering)'에 비유됩니다. 적절한 컨텍스트가 없으면 모델은 정확한 답변을 할 수 없으므로, 출력 품질에 결정적인 역할을 합니다.
        
    - A3.
        
        PII 마스킹 및 언마스킹 과정은 다음과 같습니다.
        
        1. 사용자 쿼리에서 전화번호나 주소 같은 민감한 정보를 탐지합니다.
        2. 탐지된 정보를 `[PHONE NUMBER]`와 같은 플레이스홀더로 마스킹(치환)하여 외부 API로 전송되는 것을 막습니다.
        3. 이때, 원래 정보와 플레이스홀더를 매핑하는 '가역적 PII 맵(Reversible PII map)'을 저장합니다.
        4. 모델이 응답을 생성하면, 응답 내의 플레이스홀더를 PII 맵을 이용해 다시 원래 정보로 복원(언마스킹)하여 사용자에게 제공합니다.
    - A4.
        
        출력 가드레일의 두 가지 주요 기능은 출력 실패를 감지하는 것과 실패 모드에 따른 처리 정책을 지정하는 것입니다 .
        
        - **품질 실패:** 잘못된 JSON 포맷과 같이 형식이 어긋나거나, 사실과 다른 환각(Hallucination)을 포함하는 경우입니다 .
        - **보안 실패:** 인종차별적 발언이나 성적 콘텐츠 같은 유해한 응답, 또는 개인정보가 포함된 응답을 생성하는 경우입니다.
    - A5.
        
        모델 라우터(Router)를 사용하면 다음과 같은 이점이 있습니다.
        
        1. **전문화된 성능:** 모든 쿼리를 일반 모델로 처리하는 대신, 기술 문제 해결이나 결제 관련 등 특정 주제에 특화된 모델로 라우팅하여 더 나은 성능을 얻을 수 있습니다.
        2. **비용 절감:** 모든 쿼리에 값비싼 모델을 사용하는 대신, 간단한 쿼리는 더 저렴한 모델로 보내 비용을 아낄 수 있습니다.
    - A6.
        
        모델 게이트웨이는 조직이 다양한 모델(서드파티 API 및 자체 호스팅 모델)과 상호작용할 수 있도록 하는 통합된 중간 계층입니다.
        
        핵심 기능 3가지는 다음과 같습니다.
        
        1. **통합 인터페이스 제공:** API가 변경되어도 게이트웨이만 수정하면 되므로 코드 유지보수가 용이합니다.
        2. **접근 제어 및 비용 관리:** 중앙화된 접근 권한 관리와 사용량 제한을 통해 보안을 강화하고 비용을 통제할 수 있습니다.
        3. **장애 조치(Fallback):** 주 모델 API에 장애가 발생했을 때 대안 모델로 라우팅하거나 재시도하는 로직을 구현할 수 있습니다.
    - A7.
        - *정확한 캐싱(Exact Caching)**은 요청된 쿼리가 캐시에 저장된 항목과 정확히 일치할 때만 저장된 응답을 반환합니다. 반면, **의미적 캐싱(Semantic Caching)**은 쿼리가 정확히 일치하지 않아도 의미적으로 유사하다면(예: 임베딩 유사도 기반) 캐시된 응답을 재사용합니다.
        - 의미적 캐싱의 위험 요소로는 잘못된 유사도 판단으로 인해 엉뚱한 응답을 반환할 수 있다는 점과, 사용자별 정보(예: 내 주문 내역)가 다른 사용자에게 유출될 수 있는 데이터 누수 위험이 있습니다.
    - A8.
        
        쓰기 작업(Write Actions)을 추가하면 시스템이 이메일을 보내거나 주문을 넣는 등 환경을 직접 변경할 수 있어 시스템의 능력이 크게 확장됩니다. 하지만 이는 동시에 시스템이 오작동하거나 공격받았을 때 실제 세계에 직접적인 피해를 줄 수 있는 위험(Risk)도 크게 증가시킵니다. 따라서 쓰기 권한 부여는 매우 신중하게 이루어져야 합니다.
        
    - A9.
        
        전통적인 모니터링은 시스템의 외부 출력만을 추적하여 내부의 문제를 파악하려 하며, 출력이 내부 상태를 보장하지 않습니다. 반면 **관측 가능성(Observability)**은 시스템의 외부 출력을 통해 내부 상태를 추론할 수 있다는 더 강력한 가정을 전제로 합니다. 즉, 관측 가능성은 문제가 발생했을 때 새로운 코드를 배포하지 않고도 로그와 지표만으로 왜 문제가 발생했는지 파악할 수 있도록 시스템을 계측(Instrumenting)하는 과정을 포함합니다.
        
    - **A10.**
        1. **시스템 프롬프트 변경:** 프롬프트 템플릿 업데이트나 오타 수정 등으로 인해 알지 못하는 사이에 시스템 프롬프트가 변경되는 경우입니다.
        2. **사용자 행동 변화:** 사용자들이 더 나은 결과를 얻기 위해 쿼리 방식을 변경(예: 더 간결하게 질문)함에 따라 입력 데이터의 분포가 변하는 것입니다.
        3. **기반 모델 변경:** API 제공자가 예고 없이 모델을 업데이트하여, 동일한 API를 사용함에도 성능이나 동작이 달라지는 경우입니다.
    - A11.
        
        오케스트레이터를 평가할 때 다음 3가지를 고려해야 합니다.
        
        1. **통합 및 확장성:** 현재 사용 중이거나 미래에 사용할 구성 요소(모델, 데이터베이스 등)를 지원하는지, 지원하지 않는 경우 얼마나 쉽게 확장할 수 있는지 확인해야 합니다.
        2. **복잡한 파이프라인 지원:** 분기(branching), 병렬 처리, 에러 핸들링 등 복잡한 로직을 효율적으로 관리할 수 있는 기능을 제공하는지 평가해야 합니다.
        3. **사용 편의성, 성능 및 확장성:** 직관적인 API와 문서를 제공하는지, 그리고 숨겨진 API 호출로 지연 시간을 유발하지 않고 트래픽 증가에 따라 확장 가능한지 고려해야 합니다.
    - A12.
        - *명시적 피드백(Explicit Feedback)**은 사용자가 '좋아요/싫어요', '별점' 등 시스템의 요청에 대해 직접적으로 제공하는 피드백입니다.
        - *암시적 피드백(Implicit Feedback)**은 사용자의 행동을 통해 간접적으로 추론하는 피드백입니다. 대화형 인터페이스에서는 사용자가 응답 생성을 중간에 멈추거나(부정적), 대화를 길게 이어가는 것(긍정적 또는 부정적일 수 있음) 등이 예시가 될 수 있습니다.
    - **A13.**
        1. **조기 종료(Early Termination):** 사용자가 응답 생성을 중간에 중단하거나 앱을 종료하는 것은 대화가 잘 진행되지 않고 있다는 신호일 수 있습니다.
        2. **오류 수정(Error Correction):** 사용자가 "아니, 내 말은..."이나 "다시 확인해 봐"라고 말하며 수정을 요청하는 것은 모델의 응답이 틀렸거나 불충분하다는 신호입니다.
        3. **감정 표현(Sentiment):** 사용자의 메시지에서 좌절, 실망 등의 부정적 감정이 드러나거나, 반대로 긍정적인 감정이 드러나는 것을 통해 만족도를 파악할 수 있습니다.
    - A14.
        - *관대함 편향(Leniency Bias)**은 사용자가 갈등을 피하거나 귀찮음을 덜기 위해 실제보다 더 긍정적인 평가(예: 5점 만점에 5점)를 내리는 경향입니다. 이를 완화하기 위해서는 낮은 등급에 대한 부정적인 느낌을 줄이고 구체적인 선택지를 제공하는 것이 좋습니다. 예를 들어, 단순한 숫자 등급 대신 "불평할 것은 없지만 훌륭하지도 않음"과 같이 구체적인 문장으로 된 선택지를 제시할 수 있습니다.
    - A15.
        - *퇴행적 피드백 루프(Degenerate Feedback Loop)**는 모델의 예측 결과가 사용자 피드백에 영향을 주고, 이 피드백이 다시 모델 학습에 반영되어 초기 편향이 증폭되는 현상입니다 . 예를 들어, 추천 시스템이 상위에 노출한 콘텐츠가 더 많은 클릭을 받아 계속해서 추천되는 현상이 있습니다. 대화형 AI에서는 모델이 사용자의 의견에 무조건 동조하는 **아첨꾼(Sycophancy)**이 되어, 정확성보다 사용자가 듣고 싶어 하는 말을 하도록 학습되는 부작용을 낳을 수 있습니다.

## 회고

템플릿

- 템플릿(복사해서 사용)
    - Keep: 스터디간 좋았고 계속해서 유지하고 싶은 나의 습관이나 학습전략
    - Problem: 스터디간 어려웟던 점이나 아쉬웠던점
    - Try: Problem을 극복하기 위해서 다음 스터디에서 해볼만한 개선안
- 임정
    - Keep
        - [학습 관련] 데이터 관련 챕터는 정말 좋았다. ML에서의 AI로 관점을 더 확장시킬 수 있는 좋은 단원이였음
        - 팀장 없이 스스로 돌아가는 시스템을 만든것, 나의 부재를 채울 수 있었다. (NotebookLM)
    - Problem: 이론적인 부분만 한다는게 늘 아쉬움, 1시간내 할 수 있는것이 정해져 있다. 아예 시간을 더 배분해서 해야할까?
    - Try
        - n8n이나 간단한 langchain/graph로 개념증명(PoC)을 하는 시간을 가지면 어떨까? 개념증명의 정의가 어렵고, 각 챕터별 발제자의 난이도가 올라갈 수 있을 것 같다.
        - 노션이 접근성이 좋긴하지만 이제 Github 같은 오픈 프로젝트로 넘기는게 추후 자료증빙이나 공유에도 편할 것 같다.
- 효진
    
    Keep: 매주 정해진 분량을 읽고 노션에 정리한 것
    - 이해한 내용으로만 끝나는게 아니라 발표하면서 한번 더 정리하고 풀어서 설명을 하면서 두번 복습하게 되고 좀더 깊이 이해하는데 많은 도움이 되었음
    - 단순 이해가 아니라 “왜 이런게 필요하지?”를 개인적으로 질문하면서 읽은 점이 책을 이해하는데 많은 도움이 되었음
    - 스터디원들끼리 각자 이해한 방식으로 설명해보는 과정에서 개념이 더 명확해졌음
    
    Problem: 
    - 시스템 관점 설명이 많다 보니 처음엔 추상적으로 느껴진 부분이 많았음
    - 용어가 한 번에 이해되기보다는 검색해보거나 이해해야 했음(이건 부족한 저의 문제이니 남탓은 못함ㅜ 직접 챗지피티랑 제민이한테 물어보면서 많이 배웠음)
    - 실제 서비스 경험이 없으면 “왜 필요한지” 감이 잘 안 오는 챕터들도 있었음
    
    Try: 
    - 각 장마다 “이게 실제 서비스에서 언제 필요해지는지”를 참고 예시 모델을 보면 더욱 도움이 될것 같음
    
    - 뭐 하나 만들어 보고싶음
    
- 도현
    1. Keep: 스터디간 좋았고 계속해서 유지하고 싶은 나의 습관이나 학습전략
        - 최종 프로젝트 당시 3장, 4장(LLM 평가 부분) 내용을 프로젝트에 바로 적용하면서 도움이 되었다. 프로젝트를 수행할 때 항상 관련 reference 중 특히 잘 정리된 이론서나 핸즈온 실무서를 먼저 조사하는 습관을 가지고 스터디를 진행했다. 내가 보는 책이 곧 내 수준을 결정하게 되는 것 같다. 앞으로도 우선순위에 맞게 필요한 책들을 독파해 가면 지속적인 성장을 성취할 수 있을 것이라고 생각한다.
            
            ![image.png](AI%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81%20%EC%8A%A4%ED%84%B0%EB%94%94/image%202.png)
            
            ![image.png](AI%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81%20%EC%8A%A4%ED%84%B0%EB%94%94/image%203.png)
            
            ![image.png](AI%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81%20%EC%8A%A4%ED%84%B0%EB%94%94/image%204.png)
            
            ![image.png](AI%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81%20%EC%8A%A4%ED%84%B0%EB%94%94/image%205.png)
            
    2. Problem: 스터디간 어려웟던 점이나 아쉬웠던점
        - 업무 관련해서 새로운 우선순위가 생겨서 5장부터는 책을 정독하지는 못했다.
    3. Try: Problem을 극복하기 위해서 다음 스터디에서 해볼만한 개선안
        - 그러나 추후 업무에 LLM, RAG, Agentic AI를 적용해야 하는 시간표가 있는데, 그때 가서 제대로 정독할 수 있을 거라고 생각한다.
        - LLM 관련 프로젝트를 진행하면서 내가 구현한 RAG/Agentic AI 핵심 로직은 API 개발까지 내가 구현해야 할 필요성과 책임감을 느꼈다. 최근 에이콘출판에서 AI/데이터사이언스 관점에서 쓰여진 API 책이 나왔다. 내용을 보니 도움이 많이 될 것 같다. 나중에 읽어볼 예정.
            
            [AI와 데이터 사이언스 API](http://www.acornpub.co.kr/book/9791161758374)
            
- 이승형
    - Keep: 매주 한단원씩 책을 읽는게 좋았음. 앞으로 의무적으로라도 책을 조금씩 읽고 싶다.
    - Problem: 번역서라 그런지 아니면 급하게 읽어서 그런지 내용이 이해가 잘 안되는 부분이 있었다
    - Try: 나중에 시간을 좀 투자해서 원서로 읽어보고 싶다
- 최유희
    - Keep: 스터디간 좋았고 계속해서 유지하고 싶은 나의 습관이나 학습전략
        - **구체적인 기간과 분량**을 정해서 읽으니까 명확한 목표 의식이 생기고, 확실히 혼자 읽을 때보다 완독률이 높아졌다고 할 수 있을 것 같습니다
        - 다른 분들이 정리한 내용을 보면서 내가 놓쳤던 부분도 한번 더 짚고 넘어갈 수 있어서 좋았습니다.
    - Problem: 스터디간 어려웠던 점이나 아쉬웠던 점
        - 한번 읽는 것만으로는 전체 내용을 완전히 내 것으로는 소화하지 못했다 라는 깊이에 대한 아쉬움이 남습니다.
        - 실제 사례나 제 프로젝트에 어떻게 적용할지 고민해보지 못했던 게 아쉽습니다.
    - Try: Problem을 극복하기 위해서 다음 스터디에서 해볼만한 개선안
        - 문제를 풀때 확실히 머리속에 남는 게 많은 것 같아서 내 문제를 풀고나서 다른 문제들도 풀어보면서 체득하면 좋을 것 같습니다.
        - 실제로 해당 개념이 적용된 프로젝트나 다른 읽을 거리를 읽어보고 팀원들과 공유해보는 것도 좋을 것 같습니다.
        
- 홍현경
    
    keep: **강제성을 통한 학습 연속성 확보 -** 이어드림이 끝난 후 ai관련 공부에 대해 헤이해질 때마다 매주 일요일 스터디를 통해 AI 공부의 흐름을 유지할 수 있었던거 같음. 스터디가 끝난 후에도 특정 시간을 정해 이 분야에 대해 계속 학습을 이어가고 싶음.
    
    problem: 전반적인 책의 내용을 다 이해하는 것 보다는 내가 푼 문제만 이해를 하는거 같다.
    
    try:  그래도 개인 참여 방식이라 내가 푼 문제라도 지식을 들고 갈 수 있어 문제를 정해서 각자 풀고 돌아가면서 발표는 하는건 좋은 것 같다. 하지만 다른 사람의 답은 잘 안듣거나 그냥 흘려듣게 되는거 같은데 어떤걸 시도하는게 좋을까 제미나이에 물어봄→ 스터디 마지막 5~10분 동안 각자 발표한 내용에서 짧은 퀴즈를 하나씩 내고 다 같이 맞히는 시간을 가집니다. 맞히기 위해서라도 다른 사람의 설명을 집중해서 듣게 된다고 추천해줌.
