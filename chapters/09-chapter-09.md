# 09단원

    
    ### **💡 문제 출제**
    
    - **1. 모델 추론 최적화가 필요한 근본적인 이유가 무엇인가?**
        
        <aside>
        💡
        
        - **지연 시간(latency)이 실제 서비스 가치에 직접적인 영향을 미치기 때문**
            
            모델의 예측 성능이 아무리 뛰어나더라도 추론 속도가 느릴 경우, 실제 사용자 환경에서는 응답 지연으로 인해 결과의 정확성과 무관하게 서비스 가치가 감소함
            
        - **추론 비용이 서비스의 비용 대비 효율(ROI)을 결정하기 때문**
            
            모델은 한 번 학습하지만 배포된 AI 시스템에서는 추론이 사용자 요청마다 반복되므로 전체 시스템 비용에서 가장 큰 비중을 차지하는 단계는 추론 단계임. 추론 비용이 높을 경우 대규모 서비스 운영이 어려워짐
            
        - **추론은 학습보다 훨씬 더 빈번하게 발생하는 단계이기 때문**
            
            모델 학습은 상대적으로 드물게 수행되는 반면, 추론은 서비스 운영 기간 동안 지속적으로 발생하므로 추론 단계의 비효율은 곧 시스템 전체의 비효율로 이어짐
            
        </aside>
        
    - **2. 추론 과정에서 발생하는 두 가지 주요 연산 병목 현상을 설명하세요**
        
        <aside>
        💡
        
        - **연산 제약(Compute-bound) 병목**
            
            모델 추론 과정에서 대규모 행렬 곱셈(Matrix Multiplication)과 같은 연산이 많아 GPU 또는 CPU의 연산 처리 능력이 성능의 한계가 되는 경우임. 이 경우 연산량이 많아 계산 속도가 추론 지연의 주요 원인이 됨
            
        - **메모리 대역폭 제약(Memory bandwidth-bound) 병목**
            
            모델 파라미터나 중간 결과를 메모리에서 연산 장치로 가져오는 과정에서 메모리와 프로세서 간 데이터 전송 속도(대역폭)가 제한되어 성능이 저하되는 경우임. 대규모 모델에서는 메모리 접근 속도가 추론 성능의 주요 병목이 됨
            
        
        책에서는 추론 병목을 계산이 느린 경우(Compute-bound)와 메모리에서 데이터 가져오는 게 느린 경우(Memory bandwidth-bound)로 구분하고 있음
        
        </aside>
        
    - **3. 트랜스포머 기반 언어 모델의 추론 단계인 ‘Prefill’과 ‘Decode’는 각각 어떤 병목 현상에 해당하나요?**
        
        <aside>
        💡
        
        - **Prefill 단계 → 연산 제약(Compute-bound) 병목**
            
            Prefill 단계에서는 입력 시퀀스 전체에 대해 한 번에 attention 및 행렬 연산이 수행됨. 이 과정에서 대규모 행렬 곱셈이 집중적으로 발생하므로 GPU/CPU의 연산 처리 능력이 추론 성능의 주요 병목이 됨
            
        - **Decode 단계 → 메모리 대역폭 제약(Memory bandwidth-bound) 병목**
            
            Decode 단계에서는 토큰을 하나씩 생성하며 이전 토큰들의 key-value 캐시를 반복적으로 메모리에서 읽어옴. 이로 인해 연산량 자체보다는 메모리 접근과 대역폭이 성능의 주요 병목이 됨
            
        </aside>
        
    - **4. 사용자 경험 측면에서 중요한 두 가지 지연 시간 지표인 TTFT와 TPOT의 차이점을 설명하세요.**
        
        <aside>
        💡
        
        1. TTFT(Time to First Token)
        
        : 사용자가 질문을 보낸 후 첫 번째 토큰이 생성될 때까지의 시간. 프리필(prefill) 단계에 해당하며 사용자가 체감하는 초기 반응 속도를 결정한다.
        
        1. TPOT(Time Per Output Token)
        
        : 첫 번째 토큰 생성 이후 각 출력 토큰이 생성되는 평균 시간. 디코딩(decode) 단계에 해당하며 사용자가 글을 읽는 속도(텍스트 생성 속도)에 영향을 준다.
        
        1. 차이점
        
        : TTFT는 시스템이 응답을 시작하는 기다림의 시간을, TPOT는 응답 시작 후 정보가 전달되는 흐름의 속도를 의미한다.
        
        개인적으로는 TTFT는 길어도 되지만 TPOT가 길면 굉징히 답답함..
        
        </aside>
        
    - **5. 단순한 처리량(Throughput)과 굿풋(goodput)의 차이는 무엇인가요?**
        
        <aside>
        💡
        
        처리량(Throughput): 시스템이 단위 시간당 처리할 수 있는 전체 작업의 양
        
        굿풋(Goodput): 단순히 많이 처리하는 것이 아니라, 사용자가 정의한 서비스 품질 기준(Service Level Objective, SLO)를 충족한 유효한 처리량
        
        차이점: 유효성과 SLO의 충족 여부
        
        </aside>
        
    - **6. GPU 활용도를 측정할 때 nvidia-smi에서 보여주는 수치보다 MFU가 더 정확한 효율 지표인 이유는 무엇인가요?**
        
        <aside>
        💡
        
        nividia-smi의 활용도(Utilization)는 특정 시간 동안 하나 이상의 커널이 GPU에서 실행 중인지 여부만 나타내므로, 단순한 메모리 읽기/쓰기 작업만으로도 100%가 될 수 있어 실제 계산 효율을 왜곡한다. 즉, nividia-smi는 GPU의 가동 여부만 측정할 뿐, 연산의 밀도는 측정하지 못한다.
        
        예시- 100초를 기준으로 예를 들면, gpu가 가벼운 메모리 복사 작업에 연산량의 1%를 100초 동안 실행했다면 nividia-smi에는 gpu 활용도가 100%로 나온다(낮은 MUF).
        
        반면에, MUF(Model FLOPs Utilization)는 하드웨어의 이론적 최대 연산 성능(Peak FLOPs) 대비 실제 모델 계산에 사용된 연산량의 비율을 측정하므로, 하드웨어가 실제 계산에 얼마나 효율적으로 사용되고 있는지 더 정확하게 보여준다.
        
        </aside>
        
    - **7. CPU와 비교하여 GPU가 머신러닝 워크로드, 특히 행렬 연산에 최적화된 하드웨어 구조적 특징은 무엇인가요?**
        
        <aside>
        💡
        
        1. CPU: 복잡한 명령어를 처리하는 능력은 강력하지만 소수의 코어만 가짐
        2. GPU: 복잡한 일을 처리하는 능력은 약하지만 작은 수천개의 코어로 이루어짐, 복잡한 기능은 다 빼고 산술만 할 수 있게 작게 만들어짐
        
        >> 그렇다면 왜 행렬 연산(ML)에 GPU가 유리할까?
        
         
        
        $\begin{pmatrix} a & b \\ c & d \end{pmatrix} \times \begin{pmatrix} e & f \\ g & h \end{pmatrix}$
        
        CPU는 이걸 순서대로 계산하지만 GPU는 수천 개의 코어들이 동시에 계산하기 때문에 전체적인 산술 연산 데이터 처리량에서 GPU가 CPU를 압도하게 되는 것임.
        
        </aside>
        
    - **8. 모델 압축 기법 중 'Pruning(가지치기)'의 두 가지 방식에 대해 설명하세요.**
        
        <aside>
        💡
        
        - 프루닝의 핵심 아이디어: 큰 모델 안에 전체 모델의 동작을 담을 수 있는 파라미터의 부분집합이 존재하지 않을까?
        - 프루닝의 장점: 모델 저장 공간도 줄고 연산도 빨라짐
        - 프루닝의 두 가지 방식
            1. 구조적 프루닝: 신경망 노드 전체를 제거하는 것, 아키텍처를 바꾸고 파라미터 개수를 줄임(제거 단위: 레이어 덩어리)
            2. 비구조적 프루닝: 원래 모양을 유지하되 예측에 도움되지 않는 파라미터를 찾아서 0으로 설정(제거 단위: 개별 가중치)
        
        ** 하지만 집필 시점에는 실제로 프루닝을 쓰는 경우가 많지 않았음 
        
        : 원본 모델 아키텍쳐에 대한 이해가 필요해서 하기가 어렵고, 다른 방법보다 성능 향상도 훨씬 적은 경우가 많기 때문임, 또 희소 모델을 만드는데 모든 하드웨어 아키텍쳐가 그 희소성의 이점을 잘 활용하도록 설계되어 있지는 않기 때문임.
        
        </aside>
        
    - **9. 'Speculative Decoding(투사적 디코딩)'의 기본 작동 원리는 무엇인가요?**
        
        <aside>
        💡
        
        자기 회귀 언어 모델은 토큰을 하나씩 차례대로 생성하는데 이 과정은 느릴 뿐만 아니라 비용도 많이 듬.
        
        그래서 투사적 디코딩(더 빠르지만 성능이 낮은 모델을 사용해 토큰 시퀀스를 생성한 다음, 이를 목표 모델이 검증하는 방식)을 사용함.
        
        - 기본 작동 원리
            1. 초안 모델(가벼운 모델)이 K개의 토큰 시퀀스를 생성
            2. 목표 모델(거대 모델)이 이 K개의 생성된 토큰을 병렬로 검증(이미 써져 있는 글자가 맞는지 확인할때 GPU를 가지고 동시에 한번에 계산할 수 있음)
            3. 목표 모델이 초안 시퀀스를 왼쪽부터 순서대로 검증, 처음으로 예측이 엇갈리는 지점 바로 앞까지의 토큰들만 수락함. 
            4. 문장이 완성될 때까지 위의 과정을 반복한다. 
        </aside>
        
    - **10. 'KV 캐시(KV Cache)'란 무엇이며, 왜 추론 시에만 사용되나요?**
        
        <aside>
        💡
        
        1. **KV 캐시**는 트랜스포머(Transformer) 기반의 대규모 언어 모델(LLM)이 텍스트를 생성할 때, **이전에 계산했던 데이터를 재사용하기 위해 메모리에 저장해두는 기술**.
        
        → 다음 단어를 생성할 때, 임시 저장해두는 ‘중간 계산 저장소’
        
        2. 왜 추론(Inference) 시에만 쓰나요?
        
        - **학습은 '동시적'이기 때문:** 학습할 때는 정답 문장이 이미 다 주어져 있습니다. GPU가 문장 전체를 **'한꺼번에(병렬)'** 처리하므로, 앞 단어의 계산 결과를 기다렸다가 저장할 필요가 없습니다.
        - **추론은 '순차적'이기 때문:** 추론은 단어를 하나씩 순서대로 만들어야 합니다. "A → B → C"를 만들 때, C를 만들려면 A와 B의 정보가 다시 필요한데, 매번 처음부터 다시 계산하면 너무 느려집니다. 그래서 미리 계산한 A, B의 KV 값을 '기억(캐싱)'해두는 것입니다.
        
        </aside>
        
    - **11. Multi-Query Attention(MQA)과 Grouped-Query Attention(GQA)은 어떻게 KV 캐시의 메모리 점유율을 줄이나요?**
        
        <aside>
        💡
        
        기존 방식(MHA)이 모든 Query마다 전용 Key와 Value를 가졌다면, MQA와 GQA는 이 **Key와 Value를 서로 나눠 쓰게(공유)** 하여 저장 용량을 줄임.
        
        - **MQA (전체 공유):** 모든 Query가 **단 1개**의 KV만 공유합니다. 메모리는 가장 적게 쓰지만(최대 90% 이상 절감), 성능이 조금 떨어질 수 있습니다.
        - **GQA (그룹 공유):** Query를 몇 개씩 묶어 **그룹별로 1개**의 KV를 공유합니다. 메모리 절약과 모델 성능 사이의 균형을 맞춘 '황금 밸런스' 방식입니다.
        
        **왜 메모리가 줄어드나요?**
        
        - **물리적 개수 감소:** 저장해야 할 Key, Value 벡터의 개수 자체가 헤드 수만큼 줄어듭니다. (예: 32개 저장할 것을 1개나 8개만 저장)
        - **중복 제거:** 똑같은 정보를 여러 번 저장하지 않고 하나만 저장한 뒤 돌려쓰기 때문에, 남는 GPU 메모리에 더 긴 문장(Context)을 담거나 **더 많은 사용자**의 요청을 동시에 처리할 수 있습니다
        </aside>
        
    - **12. 배치(Batching) 방식 중 'Continuous Batching(연속 배치)'이 'Static Batching'보다 효율적인 이유는 무엇인가요?**
        
        <aside>
        💡
        
        연속 배치 방식이 정적 배치 방식보다 효율적인 이유는 언어모델의 응답 길이가 서로 다를 때 발생하는 유휴 자원 문제를 해결하기 때문이다.
        
        —-
        정적 배치의 비효율성
        
        - 불필요한 대기: 정적 배치는 고정된 수의 요청을 묶어서 한 번에 처리한다. 따라서 어떤 요청을 10개의 토큰만 생성하면 끝나지만 어떤 요청은 1000개의 토큰을 생성해야 할 수도 있다. 이럴 경우 10개짜리 요청은 1000개짜리 요청이 완료될 때까지 결과를 반환하지 못하고 대기해야 한다.
        
        - 자원 낭비: 짧은 요청을 처리한 연산자원은 같은 배치의 긴 요청이 끝날 때까지 작업을 하지 않고 놀게 된다.
        
        —-
        연속 배치의 효율성
        
        - 즉각적인 반환: 배치 내의 특정 요청 처리가 완료되면 다른 긴 요청이 끝나기를 기다리지 않고 해당 사용자에게 즉각 응답을 반환한다.
        
        - 지속적 자원 활용: 요청이 완료되어 비게 된 자원에 새로운 요청을 즉시 투입한다.
        
        </aside>
        
    - **13. 추론 서버에서 'Prefill'과 'Decode' 단계를 서로 다른 인스턴스로 분리(Decoupling)하여 얻는 이점은 무엇인가요?**
        
        <aside>
        💡
        
        자원 경합을 제거하여 전체적 처리량과 지연 시간 성능을 최적화 할 수 있다.
        
        —-
        1. 병목현상 분리를 통한 간섭 제거: 프리필과 디코드는 서로 다른 컴퓨팅 자원을 요구하기 때문에 한 인스턴스에서 같이 실행하면 비효율적인 경쟁이 발생한다.
        
        - 프리필: 입력 토큰 전체를 한 번에 병령로 처리한다. 연산량이 매우 많아 연산 제한 특성을 가진다.
        
        - 디코드: 토큰을 하나씩 순차적으로 생성한다. 연산량은 낮지만 메모리에서 데이터를 얼마나 빨리 가져오는지가 중요한 메모리 대역폭 제한 특성을 가진다.
        
        이 두 작업을 분리하지 않는다면 새로운 요청이 들어와 프리필 작업을 수행하는 순간 대량의 연산 작업을 독점한다. 이로 인해 이미 진행중이던 다른 요청들의 디코드 작업이 연산 자원을 할당받지 못해 일시적으로 느려지는 현상이 발생한다. (토큰 생성 속도 저하)
        —-
        2. 처리량 증가 및 지연시간 준수
        
        - 처리량 증가:각 단계가 자신에게 최적화된 자원을 사용하므로 더 많은 요청을 처리할 수 있음.
        
        - 지연 시간 요구사항 충족: 프리필 작업이 디코드 작업을 방해하지 않으므로 응답이 생성되는 속도를 일정하게 유지하여 지연시간 목표를 준수하기 수월함.
        —-
        3. 유연한 자원 배분
        
        애플리케이션의 특성에 맞춰 프리필 인스턴스와 디코드 인스턴스의 비율을 조절할 수 있음.
        
        - 긴 문맥 처리가 중요한 경우 입력이 길어 프리필 부하가 크기 때문에 프리필 인스턴스 비율을 높여 초기 응답 시간(TTFT)을 줄일 수 있음.
        
        - 빠른 생성이 중요한 경우: 출력이 길어 디코드 부하가 크다면 디코드 인스턴스의 비율을 높여 토큰 생성 속도(TPOT)을 최적화할 수 있음.
        
        </aside>
        
    - **14. ‘Prompt Caching'이 특히 효과적인 사용 사례(Use Case) 두 가지를 예로 드세요.**
        
        <aside>
        💡
        
        </aside>
        
    - **15. 모델 병렬화 전략 중 'Tensor Parallelism'과 'Pipeline Parallelism'의 주요 차이점은 무엇인가요?**
        
        <aside>
        💡
        
        </aside>
        
    
    ### 📝 예시 답안
    
    1. 모델을 더 빠르고(Faster), 더 저렴하게(Cheaper) 만들기 위해서입니다. 모델이 너무 느리면 사용자에게 무용지물이 될 수 있고, 너무 비싸면 투자 대비 수익(ROI)을 맞출 수 없기 때문입니다.
    
    2. 연산 자체에 시간이 걸리는 **Compute-bound**와, 메모리와 프로세서 간의 데이터 전송 속도에 제약을 받는 **Memory bandwidth-bound**가 있습니다.
    
    3. 입력 토큰을 병렬로 처리하는 **Prefill 단계는 Compute-bound**이며, 토큰을 하나씩 생성하는 **Decode 단계는 Memory bandwidth-bound**입니다.
    
    4. **TTFT(Time to First Token)**는 쿼리 송신 후 첫 번째 토큰이 나올 때까지 걸리는 시간이며, **TPOT(Time per Output Token)**는 첫 토큰 이후 각 출력 토큰이 생성되는 간격의 시간입니다.
    
    5. Throughput은 단순히 초당 생성되는 토큰 수를 의미하지만, **Goodput**은 그중에서도 서비스 수준 목표(SLO, 예: 지연 시간 제한)를 만족하는 요청의 수만을 측정합니다.
    
    6. `nvidia-smi`는 단순히 GPU가 작업을 수행 중인 시간의 비율만 보여주지만, **MFU**는 칩의 이론적 최대 연산 능력(FLOP/s) 대비 실제로 수행된 연산의 비율을 보여주기 때문에 실제 연산 효율성을 더 잘 반영합니다.
    
    7. CPU는 소수의 강력한 코어로 순차적 처리에 능한 반면, **GPU는 수천 개의 작은 코어로 구성되어 병렬 처리에 최적화**되어 있습니다. 머신러닝의 핵심인 행렬 연산은 고도의 병렬화가 가능하기 때문에 GPU가 유리합니다.
    
    8. 신경망의 노드 전체를 제거하여 구조를 바꾸는 방식과, 덜 중요한 파라미터를 0으로 설정하여 모델을 희소(Sparse)하게 만드는 방식이 있습니다.
    
    9. 작고 빠른 '초안 모델(Draft model)'이 여러 토큰을 먼저 생성하고, 원래의 '타겟 모델'이 이를 병렬로 한꺼번에 검증하여 수용 여부를 결정하는 방식입니다.
    
    10. 이전 단계에서 계산된 Key와 Value 벡터를 저장해 재사용하는 메모리 공간입니다. 훈련 시에는 모든 토큰을 한 번에 알 수 있어 필요 없지만, **추론 시에는 토큰을 순차적으로 생성하므로 중복 계산을 피하기 위해 필수적**입니다.
    
    11. 모든 쿼리 헤드가 하나의 Key-Value 쌍을 공유(MQA)하거나, 헤드 그룹별로 공유(GQA)함으로써 저장해야 할 KV 쌍의 개수를 크게 줄여 메모리 사용량을 절감합니다.
    
    12. Static Batching은 모든 요청이 완료될 때까지 기다려야 하지만, **Continuous Batching은 개별 요청이 끝나는 즉시 결과를 반환하고 그 자리에 새 요청을 채워 넣을 수 있어** 하드웨어 활용도와 응답 속도가 모두 향상됩니다.
    
    13. 두 단계의 연산 특성(Compute-bound vs Memory-bound)이 다르기 때문에, 자원 경쟁을 방지하고 각 단계에 최적화된 리소스를 할당하여 전체적인 처리량과 지연 시간을 개선할 수 있습니다.
    
    14. 매번 포함되는 긴 **시스템 프롬프트**가 있는 경우, 또는 동일한 문서에 대해 여러 번 질문하는 **RAG 기반 챗봇**이나 **긴 대화 기록**이 있는 경우에 효과적입니다.
    
    15.  **Tensor Parallelism**은 단일 연산(예: 행렬 곱셈)을 여러 장치로 쪼개어 병렬로 실행하여 지연 시간을 줄이며, **Pipeline Parallelism**은 모델의 레이어들을 여러 장치에 나누어 배치하여 데이터가 흐르듯이 처리하게 함으로써 처리량을 높입니다.
    
