# 06단원

    
    ## 💡 Study Questions
    
    - **컨텍스트 길이(Context Length)가 계속 확장되고 있음에도 불구하고, RAG 패턴이 여전히 중요한 이유는 무엇인지 설명하시오.**
        1. 데이터의 양이 컨텍스트 확장 속도보다 더 빠르게 증가
        2. 비용과 속도: 컨텍스트가 길어질 수록 비용과 응답 속도가 느려짐
        3. 모델의 집중력 문제: 컨텍스트가 너무 길어지면 모델이 중요한 정보를 놓치거나 엉뚱한 부분에 집중알 수 있음
    - **용어 기반 검색(Term-based retrieval)과 임베딩 기반 검색(Embedding-based retrieval)의 차이점을 비교하고, 각각의 장단점을 서술하시오.**
        1. 용어 기반 검색
        - 키워드 기반 검색. 문서에 특정 단어가 얼마나 자주 등장하는지(TF-IDF, BM25) 따져서 검색
            - 장점: 구축과 검색 속도가 빠르고 비용이 저렴함. 특정 제품명, 에러 코드와 같은 정확한 단어를 찾을 때 유리함
            - 단점: 단어의 의미를 고려하지 않기 때문에, 문맥을 파악하지 못하거나 동의어를 처리하기 어려움
        1. 임베딩 기반 검색
        - 의미 기반 검색. 텍스트를 의미를 담은 ‘밀집 벡터’로 변환하여 벡터 데이터베이스에 저장하고 질문과 의미적으로 가까운 내용을 검색함
            - 장점: 단어가 정확히 일치하지 않아도 질문의 의도나 문맥을 파악해 관련된 문서를 잘 찾아냄.(’트랜스포머’를 검색하면 변압기와 영화를 구분할 수 있음)
            - 단점: 벡터를 생성하고 검색하는 과정에서 비용이 높고 속도가 느려짐. 특수용어와 고유 명사 검색에 약함
    - **TF-IDF 알고리즘의 작동 원리를 설명하고, BM25가 이를 어떻게 개선했는지 기술하시오.**
        1. TF(Term Frequency): 특정 문서에 단어가 얼마나 자주 등장하는지 나타냄. 많이 등장할수록 해당 문서는 그 단어와 연관성이 높음.
        2. IDF(Inverse Document Frequency): 특정 단어가 전체 문서 집합에서 얼마나 희귀한지를 나타냄. ‘the’, 나 ‘and’처럼 모든 문서에 흔하게 등장하는 단어 대신 문서 군 전체에서 드물게 등장하는 단어에 더 높은 가중치를 부여함. 최종 점수는 이 두 값을 곱하여 계산
        
        BM25 (Best matching 25)는 TF-IDF를 개선한 알고리즘으로 가장 큰 차이는 ‘문서 길이 정규화’. 기존 TF-IDF는 문서 길이가 길어지면 단어가 등장할 확률이 자연스럽게 높아짐. BM25는 문서의 길이를 고려하여 점수를 조정해서 단순히 길이가 긴 문서가 무조건 상위 랭크되는 문제를 해결
        
    - **임베딩 기반 검색(Semantic Retrieval)의 전체 워크플로우를 인덱싱(Indexing)과 쿼리(Querying) 단계로 나누어 상세히 설명하시오.**
        
        **1. 인덱싱 :** 데이터를 빠르게 검색할 수 있도록 처리하는 과정
        
        - **데이터 분할:** 문서가 너무 길면 모델의 컨텍스트 제한을 초과할 수 있으므로, 각 문서를 관리 가능한 크기의 청크로 나눔.
        - **임베딩 생성:** **임베딩 모델**을 사용하여 분할된 각 데이터 청크를 고차원 벡터인 임베딩으로 변환
        - **벡터 데이터베이스 저장:** 생성된 임베딩 벡터들을 벡터 데이터베이스에 저장, 이때 벡터 검색이 빠르고 효율적으로 이루어질 수 있도록 벡터들을 인덱싱하여 보관.
        
        **2. 쿼리:** 사용자의 질문에 대해 가장 관련성이 높은 데이터를 찾아내는 과정
        
        - **쿼리 임베딩:** 사용자의 쿼리를 인덱싱 단계에서 사용했던 것과 **동일한 임베딩 모델**을 사용하여 벡터로 변환
        - **벡터 검색:** 리트리버는 벡터 데이터베이스에서 쿼리 임베딩과 가장 가까운 *k*개의 데이터 청크를 찾아냄.
    - **하이브리드 검색(Hybrid Search)의 개념과 이를 구현하기 위한 RRF(Reciprocal Rank Fusion) 알고리즘에 대해 설명하시오.**
        
        **1. 하이브리드 검색:** 용어 기반 검색과 임베딩 기반 검색을 결합한 형태를 의미
        
        - **필요성:** 용어 기반 검색은 속도가 빠르고 특정 제품명이나 에러 코드와 같은 고유 명사 검색에 강점이 있지만, 단어의 의미적 맥락을 파악하지 못함. 반면, 임베딩 기반 검색(시맨틱 검색)은 질문의 의도를 잘 이해하지만 키워드가 가려질 수 있는 단점이 있음. 하이브리드 검색은 이 두 방식의 장점을 모두 취하여 검색의 정확도를 높임.
        - **구현 방식:**
        
        ◦ **순차적 방식:** 먼저 저렴하고 빠른 용어 기반 검색으로 후보군을 뽑은 후, 정교한 임베딩 기반 검색(리랭킹)으로 최종 순위를 매기는 방식
        
        ◦ **병렬 방식(앙상블):** 두 검색기를 동시에 실행하여 각각의 결과 목록을 얻은 뒤, 이를 하나로 통합하는 방식입니다. 이때 순위 통합을 위해 RRF 알고리즘이 사용됨
        
        **2. RRF 알고리즘:**  여러 검색기가 생성한 **서로 다른 순위 목록을 하나의 최종 순위로 통합**하기 위한 알고리즘
        
        - **핵심 원리:** 각 문서가 각 검색 결과에서 차지한 순위의 역수를 합산하여 최종 점수를 산출
        - **상세 공식:** 하이브리드 검색과 RRF를 활용하면 키워드 매칭의 정확성과 의미적 유사성을 동시에 확보할 수 있어, 더욱 강력한 검색 시스템을 구축할 수 있음.
    - **문서 청킹(Chunking) 전략이 검색 성능에 미치는 영향을 설명하고, 청크 크기(Chunk Size) 결정 시 고려해야 할 트레이드오프(Trade-off)에 대해 논의하시오.**
        
        1.청킹 전략이 검색 성능에 미치는 영향
        
        - 문서를 무작위로 분할하면 맥락이 단절될 수 있으므로, 청크 간 중첩(Overlap)을 통해 문맥을 보존해야 한다.
        - 검색 목적에 맞는 청킹 방식(Q&A 단위, 코드 구조 기반 분할 등)은 검색 정밀도를 향상시킨다.
        - 작은 청크는 컨텍스트 창 내에 다양한 정보를 포함할 수 있어 검색 결과의 다양성과 답변 품질을 높인다.
        
        2. 청크 크기 결정 시 고려해야 할 트레이드오프
        
        - 정보 다양성 vs 맥락 유지: 작은 청크는 정보 다양성이 높으나 맥락 유실 위험이 있고, 큰 청크는 맥락 유지에는 유리하나 활용 가능한 정보 범위가 제한된다.
        - 검색 정확도 vs 계산 비용: 청크 크기를 줄일수록 벡터 수가 증가하여 임베딩·저장 비용과 검색 지연이 증가한다.
        - 모델 제약: 청크 크기는 모델의 최대 토큰 제한을 고려해야 하며, 특정 모델에 최적화된 청킹은 모델 변경 시 재인덱싱이 필요하다.
        
        결론
        모든 상황에 적용 가능한 최적의 청크 크기는 존재하지 않으며, 데이터 특성과 사용자 질의를 고려해 실험적으로 결정해야 한다.
        
    - **쿼리 재작성(Query Rewriting)이 필요한 상황을 예시와 함께 설명하고, 이를 해결하는 프로세스를 기술하시오.**
        - **쿼리 재작성이 필요한 상황**
            1. **대화 맥락 의존 질문**
                
                사용자가 이전 대화를 전제로 짧게 질문할 경우, 단독 쿼리로는 의미가 불명확해 정확한 검색이 어렵다.
                
                예: “John Doe는 언제 구매했지?” 이후 “Emily Doe는 어때요?”
                
            2. **대명사 및 개체 불명확성**
                
                질문에 대명사나 생략된 대상이 포함되어 참조 대상이 명확하지 않은 경우 재작성이 필요하다.
                
                예: “그의 아내는?” → ‘그’가 누구인지 먼저 식별해야 함.
                
        - **쿼리 재작성 해결 프로세스**
            1. 사용자의 현재 질문과 이전 대화 기록을 함께 수집한다.
            2. 생성 모델에 대화 맥락을 반영하여 질문을 재작성하도록 프롬프트를 제공한다.
            3. 맥락 없이도 의미가 통하는 독립적인 쿼리를 생성한다.
            4. 재작성된 쿼리를 기반으로 리트리버를 통해 문서 검색을 수행한다.
        - **효과**
            
            쿼리 재작성은 검색 정확도를 높이고, 잘못된 추론이나 환각 발생 가능성을 줄인다.
            
    - **문맥적 검색(Contextual Retrieval)을 위해 청크를 보강하는 방법들을 설명하고, 특히 Anthropic이 제안한 방식에 대해 서술하시오.**
        
        1️⃣ 문맥적 검색을 위한 청크 보강 방법
        
        1. 메타데이터 추가
        
        각 청크에 문서 제목, 섹션(장) 이름, 작성 목적 등의 정보를 함께 저장
        
        해당 청크가 **문서의 어디에서 나온 내용인지** 쉽게 파악 가능
        
        2. 요약 정보 추가
        
        문서 전체 또는 상위 단락의 요약을 청크에 포함
        
        청크 하나만 보더라도 **전체 흐름을 이해**할 수 있음
        
        3. 인접 청크 정보 활용
        
        앞·뒤 청크의 핵심 내용을 일부 포함
        
        문장이 중간에서 잘려도 **맥락 단절을 완화**
        
        ---
        
        ### 2️⃣ Anthropic이 제안한 문맥적 검색 방식
        
        Anthropic은 각 청크 앞에
        
        “이 청크가 문서 전체에서 어떤 역할을 하는지 설명하는 문장”을 생성한 후,
        
        그 설명과 청크를 함께 임베딩하는 방식을 제안했다.
        
        예시:“이 텍스트는 고객 구매 이력을 설명하는 문서 중 결제 내역을 다룬 부분이다.”
        
        이렇게 하면 청크가 **혼자서도 충분한 의미를 가지게 되어**,
        
        검색 시 더 정확하고 관련성 높은 결과를 얻을 수 있다.
        
        ---
        
        ### 3️⃣ 정리
        
        문맥적 검색을 위해서는 단순히 문서를 나누는 것보다, 각 청크에 **배경 설명과 문서 내 위치 정보를 보강**하는 것이 중요하다. Anthropic 방식은 이를 생성 모델로 자동화한 대표적인 문맥 강화 전략이다.
        
    - **테이블 형식의 데이터(Tabular Data)를 처리하기 위한 RAG 워크플로우를 설명하고, Text-to-SQL 패턴이 어떻게 작동하는지 기술하시오.**
        
        1) 테이블 데이터에서 RAG가 필요한 이유
        
        테이블 형식 데이터는 행(row)과 열(column)로 이루어져 있어 일반 텍스트처럼 임베딩해서 검색하기 어렵다.따라서 **자연어 질문을 SQL로 변환해 직접 데이터베이스를 조회**하는 방식이 더 효과적이다. 이때 사용되는 대표적인 접근이 **Text-to-SQL 기반 RAG**이다.
        
        2) 테이블 데이터를 처리하는 RAG 워크플로우
        
        🔹 1단계: 사용자 질문 입력
        
        사용자는 자연어로 질문한다. 예: “지난달 서울 지역 매출 합계는 얼마야?”
        
        🔹 2단계: 스키마 정보 제공
        
        LLM에게 테이블 구조(컬럼명, 타입, 관계)를 함께 제공한다.→ 어떤 테이블에 어떤 데이터가 있는지 이해시키기 위함
        
        🔹 3단계: Text-to-SQL 변환
        
        LLM이 자연어 질문을 **SQL 쿼리로 변환**한다.
        
        예:
        
        ```sql
        SELECTSUM(sales)
        FROM orders
        WHERE region='Seoul'
        AND order_dateBETWEEN'2024-03-01'AND'2024-03-31';
        ```
        
        🔹 4단계: 데이터베이스 조회
        
        생성된 SQL을 실제 데이터베이스에 실행해 결과를 가져온다.
        
        🔹 5단계: 결과 후처리 및 응답 생성
        
        조회 결과를 다시 자연어로 변환해 사용자에게 설명한다.
        
        ---
        
        3) Text-to-SQL 패턴의 작동 방식
        
        - Text-to-SQL은 **검색(Retrieval)** 대신 **구조적 질의(Query Execution)**를 사용한다.
        - 임베딩으로 문서를 찾는 것이 아니라 👉 질문 → SQL → DB 실행 → 결과 반환 흐름을 따른다.
        - 이 과정에서 LLM은
            - 질문 의도 파악, 필요한 컬럼 선택, 조건(WHERE), 집계(SUM, COUNT 등) 생성을 담당한다.
        
        ---
        
        4) 장점과 주의점
        
        ✅ 장점
        
        - 정확한 수치 계산 가능
        - 최신 데이터 반영 가능
        - 대규모 테이블에도 효율적
        
        ⚠️ 주의점
        
        - 잘못된 SQL 생성 위험 → 검증 필요
        - 스키마 설명이 부실하면 오류 증가
        - 권한 관리 및 SQL Injection 방지 필요
        
        ---
        
        5) 정리
        
        테이블 데이터 RAG에서는 문서를 검색하는 대신, **Text-to-SQL을 통해 데이터베이스를 직접 조회**하는 방식이 핵심이다. 이 패턴은 수치 기반 질문이나 분석 질의에 특히 강력하며, 스키마 제공과 SQL 검증이 성공의 핵심 요소다.
        
    - **AI 에이전트(Agent)의 정의를 '환경(Environment)'과 '행동(Action)'의 관점에서 설명하고, 도구(Tools)가 에이전트의 능력에 미치는 영향을 서술하시오.**
        
        AI Agent: **자신의 환경을 인지**하고 그 환경에 **대응하여 행동**할 수 있는 모든 것
        
        환경은 에이전트가 작동하는 영역으로, 에이전트의 사용 사례에 의해 정의된다. 예를 들어, 자율주행 자동차 에이전트에게 도로 시스템이 곧 환경이 된다.
        
        행동은 에이전트가 환경 내에서 수행할 수 있는 작업의 집합을 의미한다.
        
        결과적으로 에이전트는 자신이 처한 환경을 인식하고, 그 안에서 목적을 달성하기 위해 적절한 행동을 취하는 주체라고 정의할 수 있다.
        
        도구가 에이전트의 능력에 미치는 영향
        
        : 도구는 에이전트가 수행할 수 있는 행동의 집합을 확장시킨다. 도구는 에이전트가 환경을 인지하는 능력을 강화하기도 한다(웹 검색 도구). 또한 계산기, 코드 인터프리터, 이미지 생성 도구 등 에이전트의 성능상 약점을 보완하고 기능적 확장을 가능하게 하기도 한다. 그리고 외부 도구(API)를 통해 에이전트가 현실의 다양한 작업을 자동화하는 능력을 갖게 할 수 있다.
        
    - **에이전트 시스템에서 계획(Planning)과 실행(Execution)을 분리해야 하는 이유와 그 이점을 설명하시오.**
        
        에이전트를 설계할 때 계획을 수행하면서 예기치 못한 오류와 실수가 발생할 수 있다. 이러한 경우 실행 과정에서 과도한 비용과 많은 시간이 소요될 위험이 있다. 따라서 계획과 실행을 분리하여 실행 전 계획을 검토하는 과정이 필수적이다.
        
        계획과 실행을 분리하면 계획을 실행하기 전 사전 검증이 가능하다. 또한 계획을 병렬적으로 생성하여 평가자가 가장 유망한 계획을 선택하게 함으로써 작업의 성공률을 높일 수 있다. 그리고 계획과 실행이 분리된 구조에서 각 단계마다 reflection 과정을 삽입하여 목표 달성 여부를 확인하고 실수를 바로잡을 수 있다.
        
    - **에이전트의 계획 수립 시 사용할 수 있는 다양한 제어 흐름(Control Flows)의 유형들을 나열하고 각각을 설명하시오.**
        1. 순차형 - 작업 간 의존성에 따라 차례로 실행
        2. 병렬형 - 여러 작업을 동시에 수행하여 효율을 높임
        3. 조건문 - 이전 단계 결과에 따라 수행할 작업을 선택
        4. 반복문 - 특정 조건이 충족될 때까지 동일한 작업을 반복
    - **ReAct 프레임워크와 Reflexion 프레임워크를 중심으로 에이전트의 성찰(Reflection) 및 오류 수정(Error Correction) 메커니즘을 설명하시오.**
        - ReAct: 각 단계에서 에이전트는 자신의 생각을 설명하고(계획),행동을 취한다음 관찰 결과를 분석(성찰)하는단계를 반복하며 이는 에이전트가 작업이 완료됐다고 판단할때까지 계속된다.
        - Reflexion:  성찰은 두 모듈로 결과를 평가하는 평가자와 무엇이 잘못되었는지 스스로 과정을 되짚어보는 성찰 모듈로 이루어짐. 각 단계에서 평가와 성찰 후 에이전트는 새로운 궤적을 제안함.
    - **에이전트에게 적합한 도구(Tool)를 선택하고 최적화하기 위한 전략들에 대해 논의하시오.**
        - 도구가 많을수록 에이전트의 능력은 향샹되지만 효율적으로 사용하기는 어려워진다. 모델의 컨택스트 한계도 초과하는 위험이 존재.
            - 여러 도구 조합으로 에이전트 성능 비교
            - 특정 도구를 제거했을대 성능 하락을 비교
            - 자주 실수하는 도구를 찾기
            - 도구 호출 분포를 시각화하여 많이 사용되는 도구와 사용되지 않는 도구를 파악
    - **에이전트 시스템에서 발생할 수 있는 주요 실패 모드(Failure Modes)를 계획(Planning), 도구(Tool), 효율성(Efficiency) 측면으로 나누어 설명하시오.**
        - 계획:
            - 도구 사용 실패: 유효하지 않은 도구, 유효하지 않는 파라미터, 잘못된 파라미터 값
            - 목표 달성 실패
            - 성찰 오류
        - 도구 실패
            - 각단계를 코드로 옮기는 과정에서
            - 적절한 도구의 부재
        - 효율성을 측정하는 방법
            - 작업을 완료하는데 평균적인 단계를 측정
            - 비용 측정
            - 각 행동이 걸리는 시간과 비용
    - **AI 모델을 위한 세 가지 메모리 메커니즘(내부 지식, 단기 메모리, 장기 메모리)을 정의하고, 각각의 역할과 정보 관리 전략을 설명하시오.**
        - 내부 지식: 모든 모델이 접근 가능
        - 단기 메모리: 컨텍스트, 속도는 빠르나 용량이 한정
        - 장기 메모리: 외부 데이터 소스
    
    ---
    
    - 📚 예시 답안
        
        ### 1. 컨텍스트 길이와 RAG의 중요성
        
        - **데이터 무한 확장성:** 모델의 컨텍스트 윈도우가 길어져도 기업의 데이터 증가 속도를 따라잡기 어렵습니다.
        - **성능 최적화:** 컨텍스트가 길어질수록 모델이 정보의 중간 부분을 놓치는 'Lost in the Middle' 현상이 발생하거나 잘못된 정보에 집중할 가능성이 커집니다.
        - **비용 및 지연 시간:** 입력 토큰 수가 늘어날수록 API 비용이 증가하고 응답 속도(Latency)가 느려집니다.
        - **정확도:** RAG는 쿼리와 가장 관련 있는 정보만 선별하여 전달하므로 모델의 효율성과 답변 품질을 동시에 높일 수 있습니다.
        
        ### 2. 용어 기반 검색 vs 임베딩 기반 검색
        
        - **용어 기반 검색 (Sparse Vector)**
        - **특징:** 키워드 매칭(Lexical) 방식.
        - **장점:** 인덱싱/쿼리 속도가 빠름, 특정 고유 명사나 에러 코드 검색에 강력함.
        - **단점:** 의미적 유사성을 파악하지 못함 (동의어, 문맥 파악 불가).
        - **임베딩 기반 검색 (Dense Vector)**
        - **특징:** 벡터화를 통한 의미적(Semantic) 검색.
        - **장점:** 질문의 의도를 파악하고 유의어를 검색할 수 있어 유연함.
        - **단점:** 비용 발생, 키워드 일치도가 중요한 검색에서 성능이 저하될 수 있음.
        
        ### 3. TF-IDF와 BM25
        
        - **TF-IDF:**
        - **TF(단어 빈도):** 문서 내 단어 출현 횟수가 높을수록 중요도 상승.
        - **IDF(역문서 빈도):** 흔한 단어(the, a)의 가중치를 낮추고 희귀 단어의 가중치를 높임.
        - **BM25 (Best Matching 25):**
        - **개선점:** TF-IDF의 단점인 '문서 길이' 문제를 해결.
        - **정규화:** 문서의 평균 길이를 고려하여, 단순히 내용이 길어서 단어가 많이 포함된 문서가 높은 점수를 받는 것을 방지합니다.
        
        ### 4. 임베딩 기반 검색 워크플로우
        
        - **인덱싱(Indexing) 단계:**
        1. **Chunking:** 문서를 적절한 크기로 분할.
        2. **Embedding:** 임베딩 모델을 통해 벡터로 변환.
        3. **Storage:** 벡터 데이터베이스(VectorDB)에 저장.
        - **쿼리(Querying) 단계:**
        1. **Vectorization:** 사용자 질문을 벡터로 변환.
        2. **Retrieval:** 유사도(Similarity) 기반 top-k 청크 검색.
        3. **Generation:** 검색된 컨텍스트를 LLM에 전달하여 최종 응답 생성.
        
        ### 5. 하이브리드 검색과 RRF
        
        - **하이브리드 검색:** 키워드 검색과 벡터 검색을 결합하여 각 방식의 단점을 보완하는 기법.
        - **RRF (Reciprocal Rank Fusion):**
        - 서로 다른 검색 결과 리스트를 하나로 통합하는 알고리즘.
        - 각 문서의 순위(Rank)에 역수를 취해 점수를 합산하여 최종 순위를 결정합니다.
        
        ### 6. 청킹 전략과 트레이드오프
        
        - **영향:** 청크의 크기는 검색의 **정확도**와 **문맥 보존** 사이의 균형을 결정합니다.
        - **트레이드오프:**
        - **작은 청크:** 더 세밀한 정보 검색이 가능하나 문맥이 끊길 위험이 있음.
        - **큰 청크:** 문맥 파악은 유리하나 관련 없는 노이즈가 섞이고 컨텍스트 윈도우를 빨리 채움.
        - **해결책:** 청크 간 일정 부분을 겹치게 하는 **Overlap** 전략을 사용하여 정보 단절을 방지합니다.
        
        ### 7. 쿼리 재작성 (Query Rewriting)
        
        - **필요성:** 대화의 맥락(Context)이 없으면 이해하기 어려운 모호한 질문을 해결하기 위함.
        - **예시:** "어제 본 보고서 다시 보여줘" → "2025년 12월 18일 작성된 매출 보고서 보여줘"로 변환.
        - **프로세스:** 이전 대화 이력과 현재 질문을 LLM에 전달하여, 검색에 최적화된 독립적인 질문으로 다시 작성하게 합니다.
        
        ### 8. 문맥적 검색과 Anthropic의 방식
        
        - **문제점:** 잘게 쪼개진 청크는 원본 문서의 핵심 주제를 놓칠 수 있음.
        - **Anthropic 제안 방식 (Contextual Retrieval):**
        - 각 청크를 인덱싱할 때, 해당 청크가 원본 문서에서 어떤 맥락을 가지는지 설명하는 짧은 텍스트(50~100 토큰)를 생성하여 청크 앞에 붙입니다.
        - 이를 통해 검색 성능을 획기적으로 향상시킵니다.
        
        ### 9. 테이블 데이터 RAG와 Text-to-SQL
        
        - **워크플로우:**
        1. **Text-to-SQL:** 자연어 질문을 SQL 쿼리로 변환 (스키마 정보 포함).
        2. **Execution:** DB에서 쿼리를 실행해 로우 데이터(Raw Data) 추출.
        3. **Synthesis:** 추출된 데이터와 질문을 결합해 최종 답변 생성.
        - 이 방식은 정형 데이터에 대해 벡터 검색보다 훨씬 정확한 수치 계산과 필터링을 가능하게 합니다.
        
        ### 10. 에이전트의 정의와 도구
        
        - **정의:** 환경을 **인식(Perceive)**하고 목표 달성을 위해 **행동(Action)**을 선택하는 자율적인 시스템.
        - **환경:** 에이전트가 활동하는 영역 (OS, 웹브라우저, 특정 소프트웨어 등).
        - **도구(Tools):** 에이전트가 행동을 수행하는 수단 (API 호출, 계산기, 검색기 등). 도구의 범위가 곧 에이전트의 능력치를 결정합니다.
        
        ### 11. 계획과 실행의 분리
        
        - **이유:** 모델이 생각과 동시에 행동하면 오류가 발생할 확률이 높고 수정이 어렵습니다.
        - **이점:**
        - **효율성:** 불필요한 API 호출 방지 및 비용 절감.
        - **안정성:** 실행 전 계획을 검토(Review)하거나 수정할 기회를 가짐.
        
        ### 12. 에이전트 제어 흐름 유형
        
        - **순차적(Sequential):** 작업 A 완료 후 B 실행.
        - **병렬(Parallel):** 독립적인 작업들을 동시에 수행하여 속도 향상.
        - **조건문(If/Else):** 특정 조건 만족 여부에 따라 경로 변경.
        - **반복문(Loop):** 목표를 달성할 때까지 특정 단계 반복.
        
        ### 13. ReAct와 Reflexion
        
        - **ReAct:** Thought(추론)와 Action(행동)을 번갈아 수행하며 실시간 관찰(Observation)을 통해 다음 단계 결정.
        - **Reflexion:** 실패한 결과에 대해 '왜 실패했는지'를 스스로 분석(Self-Reflection)하고, 이를 메모리에 저장하여 다음 시도에 반영하는 사후 수정 메커니즘.
        
        ### 14. 도구 선택 및 최적화 전략
        
        - **Ablation Study:** 특정 도구를 뺐을 때 성능이 얼마나 떨어지는지 확인하여 필수 도구 선별.
        - **도구 전이(Tool Transition):** 자주 함께 사용되는 도구들을 묶어 하나의 고성능 도구로 단순화.
        - **문서화 최적화:** LLM이 도구를 잘 이해할 수 있도록 도구의 설명(Description)을 정교하게 다듬기.
        
        ### 15. 에이전트 실패 모드
        
        - **계획 실패:** 목표와 무관한 계획 수립, 할루시네이션으로 인한 잘못된 파라미터 전달.
        - **도구 실패:** 도구가 에러를 반환하거나, 에이전트가 예상치 못한 형식의 데이터를 응답할 때.
        - **효율성 문제:** 정답은 맞혔으나 너무 많은 단계를 거쳐 비용과 시간이 과다 소모됨.
        
        ### 16. AI 모델의 세 가지 메모리
        
        - **내부 지식(Internal):** 모델 학습 시 내재화된 파라미터 정보 (정적임).
        - **단기 메모리(Short-term):** 현재 대화의 컨텍스트(Context Window) 내 정보.
        - **장기 메모리(Long-term):** 벡터 DB나 외부 저장소에 기록되어 필요할 때마다 꺼내 쓰는 정보 (RAG).
