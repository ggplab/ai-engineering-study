# 01단원

    
    ### 최유희
    
    - 자기회귀(Autoregressive) 언어 모델과 마스킹(Masked) 언어 모델의 훈련 방식과 주요 용도를 비교 설명하세요.
        
        <aside>
        💡
        
        자기 회귀는 직접 라벨링하지 않고 모델이 스스로 추론해서 라벨링 하는 것?ㅎㅎ.. 
        
        </aside>
        
        - 죄송합니다
            - 마스크 언어 모델: 누락된 토큰 전후 컨텍스트를 사용해 시퀀스의 어느 위치에 누락된 토큰을 예측하도록 학습, 기본적을 빈칸을 채울 수 있도록 학습됨 (감정분석, 텍스트 분류처럼 새로운 텍스트를 만들지 않는 작업에 주로 사용, 코드 디버기처럼 모델이 앞뒤 코드를 모두 이해해서 오류를 찾아야 하는 전체적인 컨텍스트 이해가 필요한 작업에도 유용)
            - 자기회귀 모델: 이전 토큰들만 보고 시퀀스의 다음 토큰을 예측하도록 학습됨(텍스트 생성 분야에 주로 사용)
    - 전통적인 지도 학습(Supervision) 방식의 한계는 무엇이었으며, 언어 모델이 '자기 지도 학습(Self-supervision)'을 통해 이 한계를 극복하고 LLM으로 확장될 수 있었던 핵심 원리를 설명하세요.
        
        <aside>
        💡
        
        어텐션 알고리즘?.. 
        
        </aside>
        
        - 분명히 읽었는데.. 죄송합니다 22
            
            레이블이 있는 데이터를 사용해 알고리즘을 학습하는 과정은 비용도 많이 들고 시간도 오래 걸림. 자기 지도 학습은 언어 모델이 레이블링 없이도 텍스트 시퀀스를 통해 학습할 수 있음. 그래서 방대한 양의 학습 데이터를 구축할 수 있기 때문에 이를 통해 언어모델을 LLM으로 확장할 수 있다 . 
            
    - LLM(대형 언어 모델)이 파운데이션 모델(Foundation Model)로 개념이 확장된 이유를 '데이터 모달리티'와 '모델의 목적성'이라는 2가지 측면에서 설명하세요.
        
        <aside>
        💡
        
        모르겠음 
        
        </aside>
        
    
    ### 김도현
    
    - AI 엔지니어링이 최근 몇 년간 폭발적으로 성장하게 된 3가지 핵심 요인을 설명하세요.
        
        <aside>
        💡
        
        Chat-GPT 출시 이후 다양한 파운데이션 모델의 등장 → 파운데이션 모델을 활용한 다양한 애플리케이션 개발
        
        </aside>
        
        <aside>
        ✅
        
        1. 범용 AI 능력
        
        : 거대 언어 모델은 기존 작업을 더 잘 수행하는 성능이 향상되었을 뿐만 아니라 **더 다양한 태스크를 수행**할 수 있다. 이전에는 불가능하다고 생각되던 작업도 파운데이션 모델을 활용하여 수행할 수 있게 되었다. 이에 따라 파운데이션 모델의 유용성과 범용성이 부각되면서 사용자의 수가 증가하고, AI 애플리케이션에 대한 수요도 증가하게 되었다.
        
        1. AI 투자 증가
        
        : Chat-GPT 등장 이후 기업의 AI에 대한 투자가 증가하였다. 많은 기업들이 AI를 자사 제품과 프로세스에 적용하고, 실적 발표에 AI를 언급하고 있다. 이에 따라 AI 애플리케이션 개발이 성장하고 있다.
        
        1. AI 애플리케이션 개발에 대한 낮아진 진입 장벽
        
        : 파운데이션 벤더 업체에서 **API를 제공**하기 때문에 AI 애플리케이션 개발에 AI 모델을 쉽게 사용할 수 있게 되었다. 여기에 더해 AI를 통해 애플리케이션 개발에 도움을 받을 수 있게 되면서 AI 애플리케이션 개발을 이전보다 더 쉽게 할 수 있게 되었다.
        
        </aside>
        
    - 전통적인 ML 엔지니어링과 대비되는 'AI 엔지니어링'의 핵심 정의는 무엇이며, 왜 'Ops'가 아닌 '엔지니어링'이라는 용어를 사용하는 것이 적절한지 설명하세요.
        
        <aside>
        💡
        
        - 전통적인 ML 엔지니어링 - 모델 자체를 개발
        - AI 엔지니어링 - 이미 존재하는 모델을 활용
        - AI 엔지니어링에는 전통적인 ML 엔지니어링에서 사용한 개념만으로는 설명할 수 없는 요인(프롬프트 엔지니어링, 컨텍스틀 구성, 평가방식, 추론 최적화, 데이터셋 엔지니어링, etc)들이 있기 때문에 AI 엔지니어링이라는 용어를 선택함.
        - 이는 또한 현업자 20명에 대한 설문조사를 바탕으로 한 것이기도 하다.
        </aside>
        
    - 기업 환경에서 AI 애플리케이션을 도입할 때, '내부 지향(Internal-facing)' 애플리케이션이 '외부 지향(External-facing)' 애플리케이션보다 더 빠르고 적극적으로 배포되는 경향이 있습니다. 그 이유를 위험성(risk) 측면에서 설명하세요.
        
        <aside>
        💡
        
        - 외부 지향 애플리케이션은 고객에게 제공하는 서비스이기 때문에 비용, 성능, 컴플라이언스 측면에서 고려해야할 사항이 더 까다롭다.
        - 반면에 사내에서 사용하는 애플리케이션 개발의 경우 이러한 고려사항으로부터 비교적 자유롭다.
        - 사내 AI 개발 역량을 준비하는 관점에서 위험이 비교적 적은 내부 지향 애플리케이션을 먼저 개발하는 회사도 있다.
        </aside>
        
    
    ### 홍현경
    
    - AI 애플리케이션을 기획할 때 AI가 수행하는 역할을 'Proactive(능동적)' 방식과 'Reactive(수동적)' 방식으로 구분하여 설명하고, 각각의 방식이 품질 기준(quality bar)과 지연 시간(latency) 요구사항에 어떻게 다른 영향을 미치는지 설명하세요.
        
        <aside>
        💡
        
        구글 노트북으로 찾아봐써요.. 
        
        - 핵심은 **'**사용자의 요청에 즉시 반응하느냐' 아니면 ‘요청 없이 미리 나서서 행동하느냐'의 차이
            - Reactive (수동적) 방식: AI가 사용자의 명확한 요청이나 질문에 대해 응답할 때를 말합니다. AI는 사용자의 입력에 반응하여 결과를 생성
            예시: 챗봇
            - Proactive(능동적) 방식:사용자 요청을 기다리지 않고 사용자에게 정보, 예측 또는 조언을 선제적으로 제공
            예시: Google 지도에서 제공하는 교통 정보 알림
            - 지연 시간 (Latency) 요구사항에 미치는 영향
                
                 Reactive: 신속하게 발생 필요
                
                 Proactive:미리 계산(precomputed)가능. 덜중요
                
            - 품질 기준 (Quality Bar) ****요구사항에 미치는 영향
                
                Reactive: 사용자가 직접 요청한거라 응답이 틀려도 사용자가 상황을 이해하고 요청을 수정할 여지가 있음
                Proactive: 사용자가 요청하지도 않았는데 AI가 나타나서 잘못된 정보나 예측을 제공하면, 사용자는 그 기능을 '성가시거나 방해된다고 여길 수 있어 높아야됨
                
        </aside>
        
    - AI 시스템에 인간의 개입(Human-in-the-Loop)을 점진적으로 줄여나가는 'Crawl-Walk-Run' 3단계 전략에 대해 설명하세요.
        
        <aside>
        💡
        
        1. Crawl (인턴): 인간 개입이 필수적.AI는 제안을 생성하는 보조 역할,  인간이 최종결정
        2. Walk (정직원):AI가 내부 직원과 직접 상호작용. AI는 내부 워크플로우에서 직접 작업을 수행
        3. Run(자율운영시스템) :자동화 수준이 최고로 증가. 
        
        외부 사용자와 직접 상호작용, 인간의 개입 없이 광범위한 작업을 자율적으로 처리
        
        </aside>
        
    - 파운데이션 모델 시대에 AI 스타트업이 확보할 수 있는 3가지 경쟁 우위(moat)는 무엇이며, 이 중 스타트업에게 가장 중요한 '데이터 우위(data advantage)'는 어떻게 확보될 수 있는지 설명하세요.
        
        <aside>
        💡
        
        춘추전국시대라서 다 모름.. 그래서 스타트업이 결정을 빨리할 수 있어서 그냥 시도해보고 버릴건 버리고 취할건 취하는 선택을 빨리함으로써 우위를 차지?
        
        </aside>
        
    
    ### 임정
    
    - AI 제품 개발 시 '0-60은 쉽지만 60-100은 매우 어렵다'는 '마지막 1마일(Last Mile) 문제'가 발생하는 이유를, '데모'와 '제품'의 차이점을 중심으로 설명하세요.
        
        <aside>
        💡
        
        본문책 1.3.2  기대치 설정
        
        - AI 모델의 파라미터는 이미 충분히 커서 General 한 문제를 대부분 풀수 있음. 하지만 다운스트림 태스크(국소적인 문제)로 갈수록 성능 향샹에 어려움을 겪을 수 있음
        - 단순히 오픈소스모델을 가져다 쓰거나 api 이용하여 모델을 개발할때의 데모는 개발 시간 대비 효과가 극대화되지만 제품모드로 들어가면 할루시네이션과 같은 고질적인 문제를 개선하는데 시간을 많이 쓰게됨
        </aside>
        
        <aside>
        ✅
        
        **10. AI 제품 개발 시 '0-60은 쉽지만 60-100은 매우 어렵다'는 '마지막 1마일(Last Mile) 문제'가 발생하는 이유를, '데모'와 '제품'의 차이점을 중심으로 설명하세요.**
        
        파운데이션 모델은 기본 성능이 뛰어나기 때문에, 주말 동안에도 멋진 '데모'를 만드는 것은 매우 쉽습니다.
        
        하지만 이 데모를 수익성 있는 '제품'으로 만드는 것은 완전히 다른 차원의 문제입니다. '마지막 1마일 문제'는 바로 이 지점에서 발생합니다.
        
        - **데모 (0-60):** 초기 데모는 80%의 경험을 빠르게 달성할 수 있습니다. 이는 개발자가 성공을 과신하게 만들 수 있습니다.
        - **제품 (60-100):** 나머지 20%를 채우는 데는 훨씬 더 많은 시간이 걸립니다. LinkedIn의 사례에서 80% 달성에 1개월이 걸렸지만, 95%를 넘기기까지 추가로 4개월이 더 걸렸습니다. 이 구간에서는 AI의 **환각(hallucinations) 현상을 처리**하고, 다양한 엣지 케이스(product kinks)를 해결하며, 신뢰성을 1%씩 어렵게 올려야 하기 때문입니다.
        </aside>
        
    - AI 엔지니어링(AIE)이 전통적인 ML 엔지니어링(MLE)과 구별되는 3가지 주요 차이점을 (1) 모델 개발 방식, (2) 모델 규모 및 자원, (3) 평가의 복잡성 측면에서 설명하세요.
        
        <aside>
        💡
        
        (1) 모델 개발 방식: MLE은 모델을 파인튜닝(하이퍼파라미터 튜닝)하는데 시간을 투자하는 반면, AI 모델은 자체적으로 모델을 만들거나, 파인튜닝, 프롬프트엔지니어링 3가지 개요에 대해서 나눠서 기여한다.
        (2) 모델 규모 및 자원: 모델 자체의 규모가 매우 커져서 이를 수행하는 고성능 연산장치(GPU)가 필요하고 모델을 탑재하는 GPU 자체의 RAM 크기가 커야한다.
        
        (3) 평가의 복잡성: MLE 측면에서는  회귀라면 MSE,MAPE,MAE를 분류라면 f1-score, AUC-ROC를 정량적인 측정으로도 충분하지만 AI 모델은 나오는 결과물이 이미지,자연어 등에 대해서 다양하고, 정성적인 평가가 필요한 부분이기 때문에 평가가 MLE과 달리 더 복잡해진다.
        
        </aside>
        
        <aside>
        ✅
        
        **11. AI 엔지니어링(AIE)이 전통적인 ML 엔지니어링(MLE)과 구별되는 3가지 주요 차이점을 (1) 모델 개발 방식, (2) 모델 규모 및 자원, (3) 평가의 복잡성 측면에서 설명하세요.**
        
        AIE와 MLE는 다음과 같은 3가지 핵심 영역에서 큰 차이를 보입니다.
        
        1. **모델 개발 방식 (Adapt vs. Train):**
            - **MLE:** 애플리케이션을 위해 **모델을 처음부터 훈련**해야 했습니다.
            - **AIE:** 다른 누군가(예: OpenAI)가 훈련한 **기존 모델을 활용(적응)**합니다. AIE는 모델링 및 훈련보다 '모델 적응(adaptation)'에 중점을 둡니다.
        2. **모델 규모 및 자원 (Scale & Compute):**
            - **AIE:** 훨씬 더 크고, 더 많은 계산 리소스를 소비하며, 더 높은 지연 시간을 유발하는 모델을 다룹니다.
            - **결과:** 이로 인해 AIE에서는 효율적인 훈련 및 **추론 최적화(inference optimization)**가 훨씬 더 중요해졌으며, GPU 및 대규모 클러스터 작업 능력이 중요해졌습니다.
        3. **평가의 복잡성 (Open-ended Evaluation):**
            - **MLE:** 전통적인 ML 작업은 대부분 '닫힌(close-ended)' 출력을 가집니다. (예: '스팸' 또는 '아님'). 정답이 명확하여 평가가 비교적 쉽습니다.
            - **AIE:** 파운데이션 모델은 '열린(open-ended)' 출력을 생성합니다. (예: 에세이 작성). 하나의 프롬프트에도 수많은 정답이 가능하므로, 정답 목록(ground truth)을 만드는 것이 불가능하며 **평가가 훨씬 더 어렵습니다**.
        </aside>
        
    - AI 엔지니어링에서 모델을 특정 작업에 적응시키는 두 가지 주요 접근 방식, 즉 (1) 프롬프트 기반 기법과 (2) 파인튜닝 기법의 작동 방식과 장단점을 비교 설명하세요.
        
        <aside>
        💡
        
        (1) 프롬프트 기반
        
        (장점): 쉽고 누구나 적용할 수 있다.
        
        (단점): 도메인이 뚜렷한(의학, 세무, 법학)등에 대한 다운스트림 태스크에 최적화가 불가능한 정도이다.
        
        (2) 파인튜닝
        
        (장점): 프롬프트 기반의 단점을 그대로 극복한다. 파운데이션 모델을 확보하여 일반적인 성능을 끌어내고, 다운스트림 태스크에 대하여 전문화, 시킬 수 있다.
        
        (단점): 프롬프트기반과 달리 파라미터의 업데이트가 필요하기 때문에 컴퓨터 리소스가 든다. 파인튜닝을 하기 위한 데이터셋의 구비가 필수적이며 이는 비용의 증가로 이어진다.
        
        </aside>
        
        <aside>
        ✅
        
        **12. AI 엔지니어링에서 모델을 특정 작업에 적응시키는 두 가지 주요 접근 방식, 즉 (1) 프롬프트 기반 기법과 (2) 파인튜닝 기법의 작동 방식과 장단점을 비교 설명하세요.**
        
        모델 적응 기법은 모델 가중치(weights)를 업데이트하는지 여부에 따라 나뉩니다.
        
        - **프롬프트 기반 기법 (Prompt-based Techniques):**
            - **작동 방식:** 모델 가중치를 변경하지 않습니다. 대신, 모델에 입력되는 프롬프트(지침 및 컨텍스트)를 정교하게 설계하여 원하는 행동을 유도합니다.
            - **장점:** 시작하기 쉽고 적은 데이터로도 가능하며, 다양한 모델을 빠르게 실험해 볼 수 있습니다.
            - **단점:** 복잡한 작업이나 엄격한 성능 요구사항을 맞추기에는 한계가 있을 수 있습니다.
        - **파인튜닝 (Finetuning):**
            - **작동 방식:** 모델 가중치를 **업데이트**합니다.  특정 작업에 대한 고품질 데이터셋을 사용하여 모델 자체를 변경(추가 학습)합니다.
            - **장점:** 모델의 품질, 지연 시간, 비용을 크게 개선할 수 있습니다. 모델이 훈련 중에 접하지 못한 새로운 작업을 학습시킬 수 있습니다.
            - **단점:** 더 복잡하고 더 많은 데이터가 필요합니다.
        </aside>
        
    
    ## 김효진
    
    - 'Pre-training'과 'Finetuning'은 모두 모델 가중치를 변경하는 작업입니다. 이 두 용어의 개념적 차이와 리소스 요구량의 차이를 설명하세요.
        
        <aside>
        💡
        
        둘 다 가중치를 바꾼다.
        
        Pre-training은….대규모 비지도(또는 자기지도) 학습 단계로, 모델이 언어·패턴·지식의 기본 구조를 스스로 익히는 과정이다. 인터넷 전체 같은 방대한 데이터를 사용하며, 수조 개의 파라미터를 가진 모델을 수주~수개월 동안 수천 대의 GPU로 학습시킨다
        
        막대한 데이터·시간·GPU 필요 → 대형 연구소/기업 중심
        
        Finetuning은 이미 학습된 모델을 특정 목적()에 맞게 다시 세밀하게 조정하는 단계, 실습때 해본적 있습니다!
        
        상대적으로 적은 자원으로 가능 → 기업·개인도 수행 가능
        
        </aside>
        
    - AI 엔지니어링 워크플로우가 전통적인 ML 엔지니어링보다 풀스택(Full-Stack) 엔지니어링에 더 가까워지는 이유는 무엇이며, 이로 인해 개발 프로세스 순서(예: 제품, 데이터, 모델)가 어떻게 변화했는지 설명하세요.
        
        <aside>
        💡
        
        ㅠㅠ……….모범답안으로 대체하겠습니다. 읽었는데 이해가 잘 안가네요ㅠㅠㅠㅠ
        
        ---
        
        </aside>
        
        <aside>
        ✅
        
        - **풀스택에 가까워지는 이유:** AIE는 '모델 개발' 자체보다 '애플리케이션 개발'과 **'인터페이스'**를 강조합니다. 이는 Python 중심의 전통적인 MLE와 달리, JavaScript API(예: LangChain.js, Vercel AI SDK)에 대한 지원이 증가하는 현상에서도 나타납니다. 이로 인해 웹 개발 또는 풀스택 배경을 가진 엔지니어들이 AIE 분야로 더 많이 유입되고 있습니다.
        </aside>
        
        - **개발 프로세스의 변화:** 가장 큰 변화는 강력한 모델이 '이미 준비되어 있다'는 것입니다.
            - **전통적인 MLE:** [데이터 수집] → [모델 훈련] → [제품 개발] 순서였습니다.
            - **AI 엔지니어링:** [제품(데모) 우선 개발] → [사용자 데이터 확보] → [모델 조정/개선] 순서로 바뀌었습니다.
        
        이 새로운 워크플로우는 아이디어를 빠르게 데모로 만들고, 피드백을 받아 반복(iterate)할 수 있는 풀스택 엔지니어에게 유리합니다
        
        ---
        
    
    ## 이승형
    
    - AIE가 MLE보다 '평가(Evaluation)'를 훨씬 더 어렵고 중요하게 만드는 근본적인 이유는 무엇이며, 이것이 모델 성능 비교(예: Gemini vs. GPT-4 사례)에 어떤 영향을 미치는지 설명하세요.
        
        
    - AI 엔지니어링 스택의 3가지 레이어(애플리케이션 개발, 모델 개발, 인프라)를 설명하고, ChatGPT 등장 이후 어떤 레이어에서 가장 큰 성장이 나타났는지 이유와 함께 설명하세요.
        
        
    
    ## 모범답안
    
    **1. 자기회귀(Autoregressive) 언어 모델과 마스킹(Masked) 언어 모델의 훈련 방식과 주요 용도를 비교 설명하세요.**
    
    두 모델은 토큰을 예측하는 방식에서 근본적인 차이가 있습니다.
    
    - **자기회귀 언어 모델 (Autoregressive LM):**
        - **훈련 방식:** 이전 토큰들(context)만을 바탕으로 **다음 토큰**을 예측하도록 훈련됩니다.  예를 들어, "My favorite color is"가 주어지면 "blue"를 예측합니다.
        - **주요 용도:** 한 번에 하나씩 순차적으로 토큰을 생성할 수 있어, 챗봇이나 기사 작성과 같은 **텍스트 생성(Text Generation)** 작업에 주로 사용됩니다.
    - **마스킹 언어 모델 (Masked LM):**
        - **훈련 방식:** 문장 중간의 일부 토큰을 무작위로 가리고(masking), **앞뒤 주변 토큰들**을 모두 활용하여 가려진 **누락 토큰**을 예측하도록 훈련됩니다.  (예: "My favorite [MASK] is blue" -> "color" 예측)
        - **주요 용도:** 문맥을 양방향으로 이해해야 하는 비생성(non-generative) 작업, 예컨대 **감성 분석, 텍스트 분류, 코드 디버깅** 등에 유용합니다.
    
    **2. 전통적인 지도 학습(Supervision) 방식의 한계는 무엇이었으며, 언어 모델이 '자기 지도 학습(Self-supervision)'을 통해 이 한계를 극복하고 LLM으로 확장될 수 있었던 핵심 원리를 설명하세요.**
    
    - **지도 학습의 한계:** 지도 학습은 '레이블이 지정된 데이터'를 필요로 합니다. 예를 들어, 사기 탐지 모델을 만들려면 수많은 거래 내역에 '사기', '정상'이라는 레이블을 인간이 직접 달아야 합니다. 이 레이블링 작업은 **비용이 매우 비싸고 시간도 오래 걸리는 데이터 병목 현상**을 유발했습니다.
    - **자기 지도 학습의 원리:** 자기 지도 학습은 이 병목 현상을 해결했습니다. 언어 모델링의 경우, **입력 데이터(텍스트) 자체에서 레이블을 추론**할 수 있습니다. 예를 들어, "I love street food"라는 문장만 있으면, <BOS>, I, love"를 입력(context)으로, "street"을 출력(label)으로 하는 학습 샘플을 자동으로 생성할 수 있습니다.
    - **LLM으로의 확장:** 이 방식 덕분에 책, 블로그, 웹사이트 등 레이블이 없는 방대한 텍스트 데이터를 학습에 모두 활용할 수 있게 되었습니다.  이는 모델이 수십억 개의 파라미터를 가진 LLM으로 확장(scale up)될 수 있게 만든 결정적인 계기가 되었습니다.
    
    **3. LLM(대형 언어 모델)이 파운데이션 모델(Foundation Model)로 개념이 확장된 이유를 '데이터 모달리티'와 '모델의 목적성'이라는 2가지 측면에서 설명하세요.**
    
    - **데이터 모달리티 (Data Modality):** LLM은 기본적으로 텍스트(Text) 데이터에 국한됩니다. 반면, 파운데이션 모델은 텍스트를 넘어 **이미지, 비디오, 오디오 등 여러 데이터 양식(Multimodal)을 함께 이해**합니다. 예를 들어 GPT-4V는 텍스트와 이미지를 동시에 입력받아 처리할 수 있습니다.
    - **모델의 목적성 (Generality):** 과거의 ML 모델과 LLM은 종종 특정 작업(예: 번역 전용, 감성 분석 전용)을 위해 개발되었습니다. 하지만 파운데이션 모델은 매우 큰 규모와 방대한 데이터 학습을 통해 **범용성(General-purpose)**을 갖추게 되었습니다. 이 모델들은 특정 작업에 국한되지 않고 다양한 작업을 즉시 수행할 수 있으며 , RAG나 파인튜닝 등을 통해 특정 애플리케이션에 맞게 조정(adapt)될 수 있습니다.
    
    **4. AI 엔지니어링이 최근 몇 년간 폭발적으로 성장하게 된 3가지 핵심 요인을 설명하세요.**
    
    AI 엔지니어링은 다음 세 가지 요인이 복합적으로 작용하여 급성장했습니다.
    
    1. **범용 AI 역량의 등장:** 파운데이션 모델은 기존 작업(예: 번역)을 더 잘할 뿐만 아니라, 이전에는 불가능했던 새로운 작업(예: 고품질 이미지 생성, 복잡한 추론)까지 가능하게 했습니다. 이로 인해 AI의 수요와 사용자 기반이 폭발적으로 증가했습니다.
    2. **AI 투자 급증:** ChatGPT의 성공은 AI에 대한 막대한 투자를 유도했습니다. AI 애플리케이션 개발 비용이 저렴해지고 시장 출시가 빨라지면서 ROI(투자 수익)가 매력적으로 변했고, 기업들은 경쟁적으로 AI를 도입하기 시작했습니다.
    3. **낮은 진입 장벽:** 'MaaS(Model as a Service)' 형태의 API(예: OpenAI API)가 보편화되면서, 개발자들이 인프라 구축 없이도 강력한 모델에 즉시 접근할 수 있게 되었습니다. 또한 프로그래밍 언어가 아닌 **평범한 영어(자연어)**로 모델을 제어(프롬프트 엔지니어링)할 수 있게 되어, AI 비전공자나 코딩 경험이 없는 사람도 AI 앱을 개발할 수 있게 되었습니다.
    
    **5. 전통적인 ML 엔지니어링과 대비되는 'AI 엔지니어링'의 핵심 정의는 무엇이며, 왜 'Ops'가 아닌 '엔지니어링'이라는 용어를 사용하는 것이 적절한지 설명하세요.**
    
    - **AI 엔지니어링의 정의:** AI 엔지니어링은 **미리 준비된(readily available) 파운데이션 모델을 기반으로(on top of) 애플리케이션을 구축하는 프로세스**를 의미합니다. 이는 모델을 '처음부터 개발'하는 전통적인 ML 엔지니어링과는 구별됩니다. AI 엔지니어링은 이미 존재하는 강력한 모델을 '활용'하고 '조정(adapt)'하는 데 중점을 둡니다.
    - **'엔지니어링' 용어의 적절성:** 'Ops'(MLOps, LLMOps 등)는 주로 모델의 운영 및 배포 측면을 강조합니다. 하지만 파운데이션 모델 기반 작업의 핵심은 모델을 원하는 대로 작동하도록 **'조정(tweaking)'**하는 것입니다. 즉, 프롬프트 엔지니어링, RAG(검색 증강 생성), 파인튜닝 등을 통해 모델의 동작을 설계하고 개선하는 **'엔지니어링'** 활동이 중심이 됩니다.
    
    **6. 기업 환경에서 AI 애플리케이션을 도입할 때, '내부 지향(Internal-facing)' 애플리케이션이 '외부 지향(External-facing)' 애플리케이션보다 더 빠르고 적극적으로 배포되는 경향이 있습니다. 그 이유를 위험성(risk) 측면에서 설명하세요.**
    
    기업들은 AI 도입 시 위험성이 낮은 애플리케이션을 선호하는 경향이 있으며, 이것이 내부 지향 앱이 선호되는 주된 이유입니다.
    
    - **위험 최소화:** 내부 지향 애플리케이션(예: 내부 문서 요약, 직원용 지식 관리 봇)은 직원들만 사용합니다.  만약 AI가 잘못된 답변(환각)을 생성하거나 실수를 하더라도, 그 영향이 기업 내부로 한정되며 통제하기 쉽습니다.
    - **높은 외부 위험:** 반면, 외부 지향 애플리케이션(예: 고객 응대 챗봇, 외부 공개용 추천 알고리즘)은 고객에게 직접 노출됩니다. 여기서 발생하는 오류는 **데이터 프라이버시 침해, 규정 준수(compliance) 문제, 또는 치명적인 브랜드 이미지 손상**과 같은 심각한 위험을 초래할 수 있습니다.
    
    따라서 기업들은 위험을 최소화하면서 AI 엔지니어링 전문성을 쌓기 위해, 통제 가능한 내부 애플리케이션을 먼저 배포하고 안정화하는 전략을 선택합니다.
    
    **7. AI 애플리케이션을 기획할 때 AI가 수행하는 역할을 'Proactive(능동적)' 방식과 'Reactive(수동적)' 방식으로 구분하여 설명하고, 각각의 방식이 품질 기준(quality bar)과 지연 시간(latency) 요구사항에 어떻게 다른 영향을 미치는지 설명하세요.**
    
    - **Reactive (수동적) 방식:**
        - **설명:** 사용자의 명시적인 요청이나 특정 행동에 **반응**하여 AI가 응답을 생성하는 방식입니다.  (예: 사용자가 챗봇에게 질문을 입력할 때)
        - **특징:** 사용자가 요청 후 기다리고 있으므로, **지연 시간(latency)이 매우 중요**합니다. 사용자가 AI의 핵심 기능에 의존하는 경우가 많아 정확도도 중요하지만, 때로는 실수가 허용되기도 합니다.
    - **Proactive (능동적) 방식:**
        - **설명:** 사용자가 요청하지 않았음에도 AI가 유용하다고 판단하는 기회에 **먼저** 응답(알림, 제안 등)을 보여주는 방식입니다.  (예: 구글맵의 선제적인 교통 상황 알림)
        - **특징:** 미리 응답을 계산해 둘 수 있으므로 **지연 시간은 상대적으로 덜 중요**합니다.  하지만 사용자가 요청하지 않은 정보이므로, **품질 기준(quality bar)이 매우 높아야** 합니다. 품질이 낮으면 사용자는 이를 방해나 스팸으로 간주할 수 있습니다.
    
    **8. AI 시스템에 인간의 개입(Human-in-the-Loop)을 점진적으로 줄여나가는 'Crawl-Walk-Run' 3단계 전략에 대해 설명하세요.**
    
    'Crawl-Walk-Run'은 AI 자동화 수준을 점진적으로 높여나가는 Microsoft의 프레임워크입니다.
    
    1. **Crawl (기어가기):** AI 시스템의 초기 단계로, **인간의 개입이 필수적**입니다. 예를 들어, AI가 고객 응대 답변 초안을 생성하면, 인간 상담원이 이를 검토하고 수정한 뒤 고객에게 발송합니다.
    2. **Walk (걷기):** AI의 성능이 검증되면, **내부 직원과의 상호작용을 허용**합니다. AI가 단순 요청에 대해서는 내부 직원에게 직접 응답하고, 복잡한 문제만 인간에게 라우팅합니다.
    3. **Run (달리기):** AI의 신뢰도가 충분히 높아지면, **외부 사용자와의 직접적인 상호작용**을 포함한 완전 자동화 단계로 나아갑니다. 이 단계에서는 AI가 인간의 개입 없이 대부분의 요청을 처리합니다.
    
    이 전략은 AI의 품질이 향상됨에 따라 점진적으로 자동화 수준을 높여 위험을 관리하는 방식입니다.
    
    **9. 파운데이션 모델 시대에 AI 스타트업이 확보할 수 있는 3가지 경쟁 우위(moat)는 무엇이며, 이 중 스타트업에게 가장 중요한 '데이터 우위(data advantage)'는 어떻게 확보될 수 있는지 설명하세요.**
    
    AI 분야의 3가지 일반적인 경쟁 우위는 **기술(Technology), 데이터(Data), 그리고 ~~유통~~(Distribution)**입니다.
    
    파운데이션 모델 시대에는 대부분의 회사가 유사한 핵심 기술(예: OpenAI API)을 사용하고, 유통망은 대기업(예: Google, Microsoft)이 장악하고 있습니다. 따라서 **데이터 우위**가 스타트업에게 가장 중요한 차별화 요소가 됩니다.
    
    스타트업은 다음과 같은 '데이터 플라이휠(Data Flywheel)'을 통해 이 우위를 확보할 수 있습니다.
    
    1. 시장에 빠르게 제품을 출시합니다.
    2. 사용자가 제품을 사용하는 과정에서 **고유한 사용 데이터(usage data)**를 수집합니다.
    3. 이 데이터를 분석하여 사용자의 행동 패턴과 제품의 문제점을 파악합니다.
    4. 이 인사이트를 바탕으로 데이터 수집 및 훈련 프로세스를 개선하여 **제품을 지속적으로 향상**시킵니다.
    5. 개선된 제품은 더 많은 사용자를 유치하고, 이는 다시 더 많은 고유 데이터를 생성하는 선순환을 만듭니다.
    
    파운데이션 모델은 기본 성능이 뛰어나기 때문에, 주말 동안에도 멋진 '데모'를 만드는 것은 매우 쉽습니다.
    
    하지만 이 데모를 수익성 있는 '제품'으로 만드는 것은 완전히 다른 차원의 문제입니다. '마지막 1마일 문제'는 바로 이 지점에서 발생합니다.
    
    - **데모 (0-60):** 초기 데모는 80%의 경험을 빠르게 달성할 수 있습니다. 이는 개발자가 성공을 과신하게 만들 수 있습니다.
    - **제품 (60-100):** 나머지 20%를 채우는 데는 훨씬 더 많은 시간이 걸립니다. LinkedIn의 사례에서 80% 달성에 1개월이 걸렸지만, 95%를 넘기기까지 추가로 4개월이 더 걸렸습니다. 이 구간에서는 AI의 **환각(hallucinations) 현상을 처리**하고, 다양한 엣지 케이스(product kinks)를 해결하며, 신뢰성을 1%씩 어렵게 올려야 하기 때문입니다.
    
    **11. AI 엔지니어링(AIE)이 전통적인 ML 엔지니어링(MLE)과 구별되는 3가지 주요 차이점을 (1) 모델 개발 방식, (2) 모델 규모 및 자원, (3) 평가의 복잡성 측면에서 설명하세요.**
    
    AIE와 MLE는 다음과 같은 3가지 핵심 영역에서 큰 차이를 보입니다.
    
    1. **모델 개발 방식 (Adapt vs. Train):**
        - **MLE:** 애플리케이션을 위해 **모델을 처음부터 훈련**해야 했습니다.
        - **AIE:** 다른 누군가(예: OpenAI)가 훈련한 **기존 모델을 활용(적응)**합니다. AIE는 모델링 및 훈련보다 '모델 적응(adaptation)'에 중점을 둡니다.
    2. **모델 규모 및 자원 (Scale & Compute):**
        - **AIE:** 훨씬 더 크고, 더 많은 계산 리소스를 소비하며, 더 높은 지연 시간을 유발하는 모델을 다룹니다.
        - **결과:** 이로 인해 AIE에서는 효율적인 훈련 및 **추론 최적화(inference optimization)**가 훨씬 더 중요해졌으며, GPU 및 대규모 클러스터 작업 능력이 중요해졌습니다.
    3. **평가의 복잡성 (Open-ended Evaluation):**
        - **MLE:** 전통적인 ML 작업은 대부분 '닫힌(close-ended)' 출력을 가집니다. (예: '스팸' 또는 '아님'). 정답이 명확하여 평가가 비교적 쉽습니다.
        - **AIE:** 파운데이션 모델은 '열린(open-ended)' 출력을 생성합니다. (예: 에세이 작성). 하나의 프롬프트에도 수많은 정답이 가능하므로, 정답 목록(ground truth)을 만드는 것이 불가능하며 **평가가 훨씬 더 어렵습니다**.
    
    **12. AI 엔지니어링에서 모델을 특정 작업에 적응시키는 두 가지 주요 접근 방식, 즉 (1) 프롬프트 기반 기법과 (2) 파인튜닝 기법의 작동 방식과 장단점을 비교 설명하세요.**
    
    모델 적응 기법은 모델 가중치(weights)를 업데이트하는지 여부에 따라 나뉩니다.
    
    - **프롬프트 기반 기법 (Prompt-based Techniques):**
        - **작동 방식:** 모델 가중치를 변경하지 않습니다. 대신, 모델에 입력되는 프롬프트(지침 및 컨텍스트)를 정교하게 설계하여 원하는 행동을 유도합니다.
        - **장점:** 시작하기 쉽고 적은 데이터로도 가능하며, 다양한 모델을 빠르게 실험해 볼 수 있습니다.
        - **단점:** 복잡한 작업이나 엄격한 성능 요구사항을 맞추기에는 한계가 있을 수 있습니다.
    - **파인튜닝 (Finetuning):**
        - **작동 방식:** 모델 가중치를 **업데이트**합니다.  특정 작업에 대한 고품질 데이터셋을 사용하여 모델 자체를 변경(추가 학습)합니다.
        - **장점:** 모델의 품질, 지연 시간, 비용을 크게 개선할 수 있습니다. 모델이 훈련 중에 접하지 못한 새로운 작업을 학습시킬 수 있습니다.
        - **단점:** 더 복잡하고 더 많은 데이터가 필요합니다.
    
    **13. 'Pre-training'과 'Finetuning'은 모두 모델 가중치를 변경하는 작업입니다. 이 두 용어의 개념적 차이와 리소스 요구량의 차이를 설명하세요.**
    
    두 용어 모두 모델 가중치를 변경하는 '훈련(Training)'의 단계이지만, 시작점과 목적, 리소스 소모량에서 큰 차이가 있습니다.
    
    - **Pre-training (사전 훈련):**
        - **개념:** 모델 가중치가 무작위로 초기화된 상태, 즉 **처음부터(from scratch)** 모델을 훈련하는 것을 의미합니다. LLM의 경우, 방대한 텍스트로 '다음 단어 맞추기' 같은 범용적인 작업을 학습합니다.
        - **리소스:** 전체 훈련 단계 중 **가장 많은 리소스(데이터 및 컴퓨팅)**를 소모합니다. InstructGPT의 경우 전체 자원의 98%가 사전 훈련에 사용되었습니다.
    - **Finetuning (미세 조정):**
        - **개념:** **이전에 훈련된 모델**의 가중치를 가져와서 특정 작업에 맞게 계속 훈련하는 것을 의미합니다.  (예: 사전 훈련된 GPT를 의료 데이터로 파인튜닝)
        - **리소스:** 모델이 이미 사전 훈련을 통해 일정 수준의 지식을 갖고 있으므로, 일반적으로 사전 훈련보다 **훨씬 적은 데이터와 컴퓨팅 리소스**를 필요로 합니다.
    
    **14. AI 엔지니어링 워크플로우가 전통적인 ML 엔지니어링보다 풀스택(Full-Stack) 엔지니어링에 더 가까워지는 이유는 무엇이며, 이로 인해 개발 프로세스 순서(예: 제품, 데이터, 모델)가 어떻게 변화했는지 설명하세요.**
    
    - **풀스택에 가까워지는 이유:** AIE는 '모델 개발' 자체보다 '애플리케이션 개발'과 **'인터페이스'**를 강조합니다. 이는 Python 중심의 전통적인 MLE와 달리, JavaScript API(예: LangChain.js, Vercel AI SDK)에 대한 지원이 증가하는 현상에서도 나타납니다. 이로 인해 웹 개발 또는 풀스택 배경을 가진 엔지니어들이 AIE 분야로 더 많이 유입되고 있습니다.
    - **개발 프로세스의 변화:** 가장 큰 변화는 강력한 모델이 '이미 준비되어 있다'는 것입니다.
        - **전통적인 MLE:** [데이터 수집] → [모델 훈련] → [제품 개발] 순서였습니다.
        - **AI 엔지니어링:** [제품(데모) 우선 개발] → [사용자 데이터 확보] → [모델 조정/개선] 순서로 바뀌었습니다.
    
    이 새로운 워크플로우는 아이디어를 빠르게 데모로 만들고, 피드백을 받아 반복(iterate)할 수 있는 풀스택 엔지니어에게 유리합니다.
    
    **15. AIE가 MLE보다 '평가(Evaluation)'를 훨씬 더 어렵고 중요하게 만드는 근본적인 이유는 무엇이며, 이것이 모델 성능 비교(예: Gemini vs. GPT-4 사례)에 어떤 영향을 미치는지 설명하세요.**
    
    - **평가가 어려운 이유:** 근본적인 이유는 파운데이션 모델의 **'열린(open-ended)' 특성** 때문입니다.
        - 전통적인 MLE 작업(예: 사기 탐지)은 '참/거짓'처럼 정답(ground truth)이 명확합니다.
        - 하지만 AIE 작업(예: 챗봇 응답)은 하나의 질문에 대해 수많은 좋은 답변이 존재할 수 있으므로, 정답 목록을 만드는 것이 불가능합니다.
    - **성능 비교에 미치는 영향 (Gemini 사례):** 평가가 어렵기 때문에 '어떻게 평가했는가'가 모델의 성능 수치를 좌우합니다. 2023년 구글은 Gemini가 MMLU 벤치마크에서 GPT-4보다 낫다고 발표했습니다.
        - 하지만 이는 Gemini에게는 32개의 예시(CoT@32)를 주고, GPT-4에게는 5개의 예시만 주는 등 **서로 다른 프롬프트 엔지니어링 기법**을 사용한 결과였습니다.
        - 동일하게 5-shot으로 비교했을 때는 GPT-4의 성능이 더 높았습니다. 이는 프롬프트 기법(평가 방법)의 작은 차이가 모델 성능 수치를 크게 왜곡할 수 있음을 보여줍니다.
    
    **16. AI 엔지니어링 스택의 3가지 레이어(애플리케이션 개발, 모델 개발, 인프라)를 설명하고, ChatGPT 등장 이후 어떤 레이어에서 가장 큰 성장이 나타났는지 이유와 함께 설명하세요.**
    
    AI 스택은 3개의 계층으로 구성됩니다.
    
    1. **애플리케이션 개발 (Application Development):** 최상위 레이어로, AI 인터페이스, 프롬프트 엔지니어링, 컨텍스트 구성(RAG 등), 평가를 다룹니다.
    2. **모델 개발 (Model Development):** 중간 레이어로, 모델링, 훈련, 파인튜닝, 추론 최적화, 데이터셋 엔지니어링 등을 다룹니다.
    3. **인프라 (Infrastructure):** 가장 낮은 레이어로, 모델 서빙, 컴퓨팅 및 데이터 관리, 모니터링 등을 포함합니다.
    
    **가장 큰 성장이 나타난 레이어:** GitHub 리포지토리 분석에 따르면, 2023년(Stable Diffusion 및 ChatGPT 등장 이후)에 **'애플리케이션(Applications)'**과 **'애플리케이션 개발(AI Engineering)'** 레이어에서 가장 폭발적인 증가가 나타났습니다.
    
    **이유:** 강력한 파운데이션 모델이 API 등을 통해 '미리 준비된' 상태가 되면서, 개발자들이 인프라나 모델 개발에 대한 부담 없이 **즉시 애플리케이션을 만들 수 있게 되었기 때문**입니다. 반면, 서빙이나 모니터링 같은 핵심 인프라 요구사항은 기존과 크게 달라지지 않아 성장이 상대적으로 더뎠습니다.
    
