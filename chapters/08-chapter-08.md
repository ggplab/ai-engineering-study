# 08단원

    
    ### **💡 문제 출제**
    
    - **1. 데이터 중심(Data-centric) AI와 모델 중심(Model-centric) AI의 접근 방식을 비교 설명하십시오.**
        
        <aside>
        💡
        
        - **모델 중심(Model-centric) AI:** 데이터셋은 고정된 것으로 간주하고, **모델의 아키텍처, 크기, 또는 훈련 기법을 개선**하여 성능을 높이는 데 집중합니다. "주어진 데이터에서 최상의 성능을 내는 모델은 무엇인가?"를 고민합니다.
        - **데이터 중심(Data-centric) AI:** 모델 아키텍처는 고정한 채, **데이터의 품질과 구성을 개선**하여 시스템의 성능을 최적화하는 방식입니다. "모델의 성능을 극대화하기 위해 어떤 데이터가 필요한가?"를 고민합니다.
        - **차별화 요소:** 모델이 점차 범용화됨에 따라 **데이터의 품질과 다양성**이 모델 성능을 가르는 핵심 차별화 요소로 부상하고 있습니다.
        - **상호 관계:** 두 방식은 서로 배타적인 것이 아니며, 기술적 진보를 위해 **모델과 데이터 모두에 대한 지속적인 개선**이 병행되어야 합니다.
        
        **요약하자면**, 모델 중심 AI가 **'레시피와 조리기구(모델)'** 개발에 집중한다면, 데이터 중심 AI는 '식재료의 신선도와 품질(데이터)'을 높여 요리의 맛을 끌어올리는 것과 같음
        
        </aside>
        
    - **2.파인튜닝을 위한 고품질 데이터가 갖추어야 할 6가지 주요 특성을 나열하고 각각 설명하십시오.**
        
        <aside>
        💡
        
        1. **관련성 (Relevant):** 학습 데이터는 모델이 수행하고자 하는 작업과 직접적으로 관련이 있어야 합니다. 예를 들어, 현대 법률 질문에 답하는 모델을 학습시키기 위해 19세기의 법률 데이터를 사용하는 것은 부적절할 수 있습니다.
        
        2. **작업 요구사항과의 정렬 (Aligned with task requirements):** 데이터의 주석(Annotation)은 작업의 요구사항과 일치해야 합니다. 예를 들어, 작업이 사실적 일관성, 창의성, 또는 간결함을 요구한다면 주석 역시 그 특성을 정확히 반영하고 있어야 합니다. 단순히 '정확함'을 넘어 사용자가 원하는 구체적인 스타일과 정렬되는 것이 중요합니다.
        
        3. **일관성 (Consistent):** 여러 예시나 서로 다른 작업자들 사이에서 주석의 기준이 동일해야 합니다. 기준이 일관되지 않으면(예: 같은 품질의 에세이에 다른 점수를 부여함) 모델이 학습하는 데 혼란을 줄 수 있습니다. 명확한 가이드라인을 갖추는 것이 이를 보장하는 핵심입니다.
        
        4. **정확한 형식 (Correctly formatted):** 모든 데이터 예시는 모델이 기대하는 형식을 따라야 합니다. 불필요한 HTML 태그, 일관되지 않은 대소문자 표기, 잘못된 숫자 형식 등은 모델의 학습을 방해할 수 있으므로 제거하거나 수정해야 합니다.
        
        5. **충분한 고유성 (Sufficiently unique):** 데이터셋 내에 중복된 예시가 없어야 합니다. 중복 데이터는 데이터 분포를 왜곡하여 모델에 편향을 심어줄 수 있고, 테스트 세트 오염을 유발하며, 계산 자원을 낭비하게 만듭니다.
        
        6. **준수성 (Compliant):** 데이터는 개인정보 보호법(PII) 등 관련 법규와 내부 윤리 정책을 준수해야 합니다. 예를 들어, 개인 식별 정보가 포함된 데이터를 모델 학습에 사용해서는 안 됩니다.
        
        이러한 특성들을 갖춘 데이터는 양이 적더라도 노이즈가 섞인 대량의 데이터보다 모델 성능 개선에 훨씬 더 효과적일 수 있음
        
        </aside>
        
    - **3.데이터 커버리지(Data Coverage) 확보를 위해 고려해야 할 다양성의 차원 3가지를 설명하십시오.**
        
        <aside>
        💡
        
        - **작업(Task) 다양성**
            
            모델이 수행해야 할 다양한 작업 유형을 포함해야 함
            
            질의응답, 요약, 번역, 분류, 추론 등 서로 다른 태스크를 포함함으로써 모델이 다양한 문제 유형에 일반화될 수 있음
            
        - **주제(Topic / Domain) 다양성**
            
            금융, 기술, 패션, 교육 등 다양한 주제 영역의 데이터를 포함해야 함
            
            이를 통해 특정 도메인에 편향되지 않고 실제 사용자 질문 분포를 폭넓게 커버할 수 있음
            
        - **입력 및 출력 형식(Instruction / Output Format) 다양성**
            
            짧은 질문과 긴 지시문, 자연어 응답, yes/no 답변, JSON과 같은 구조화된 출력 등 다양한 표현과 형식을 포함해야 함
            
            이를 통해 모델이 다양한 사용자 표현 방식과 응답 요구에 안정적으로 대응할 수 있음
            
        </aside>
        
    - **4.데이터 수량 증가에 따른 '수확 체감(Diminishing returns)' 현상의 의미와 시사점을 설명하십시오.**
        
        <aside>
        💡
        
        - **의미**
            
            데이터 수량이 증가할수록 모델 성능은 향상되지만 일정 시점 이후에는 동일한 양의 데이터를 추가해도 성능 개선 폭이 점점 감소하는 현상을 의미함
            
            초기에는 적은 데이터 증가로도 큰 성능 향상을 얻을 수 있으나 데이터가 많아질수록 추가 데이터의 효과는 제한적이 됨
            
        - **시사점**
            
            1) 무작정 데이터 양을 늘리는 것보다 데이터 품질과 다양성이 더 중요해질 수 있음
            
            2) 성능이 정체되는 구간에서는 데이터 수량 확대보다 데이터 구성 개선(다양성, 커버리지)이 효과적임
            
        
               3) 추가 데이터 확보에는 비용이 들기 때문에 성능 향상이 거의 없는 구간에서는 비용 대비 효율을 고려한 데이터 전략이 필요함
        
        → 따라서 데이터 수량 증가는 중요하지만 일정 수준 이후에는 품질·다양성 중심의 데이터 전략으로 전환해야 함
        
        </aside>
        
    - **5.AI 엔지니어링에서 '데이터 플라이휠(Data Flywheel)'이 작동하는 단계를 설명하십시오.**
        
        <aside>
        💡
        
        데이터 플라이휠이란? 
        
        서비스 사용으로 생성된 데이터를 모델 개선에 활용하고 개선된 모델이 다시 더 많은 사용자와 고품질 데이터를 만들어내는 선순환 구조
        
        - **1단계: 서비스 사용을 통한 데이터 및 피드백 수집**
            
            실제 AI 서비스를 사용하는 과정에서 사용자 입력, 행동 로그, 피드백과 같은 데이터가 자연스럽게 생성됨
            
            이 데이터는 실제 사용 환경을 반영한다는 점에서 매우 높은 가치를 가짐
            
        - **2단계: 수집된 데이터를 활용한 모델 개선**
            
            수집된 데이터를 정제하고 이를 활용해 모델을 파인튜닝하거나 평가·개선함
            
            이 과정에서 모델은 사용자 요구와 실제 사용 패턴에 더 잘 맞도록 발전함
            
        - **3단계: 개선된 모델을 통한 서비스 품질 향상 및 데이터 증가**
            
            성능이 향상된 모델은 더 나은 사용자 경험을 제공하고 사용자 수 증가 및 더 많은 고품질 데이터 유입으로 이어짐
            
        </aside>
        
    - **6.데이터 증강(Data Augmentation)과 데이터 합성(Data Synthesis)의 차이점을 정의와 예시를 들어 비교하십시오.**
        
        <aside>
        💡
        
        1. 데이터 증강
        
        : 기존의 실제 데이터를 변형하여 새로운 데이터를 만드는 것
        
        EX) 고양이 사진을 좌우로 뒤집어 새로운 이미지 생성
        
        1. 데이터 합성
        
        : 실제 데이터의 속성을 모방하여 가상의 데이터를 생성하는 것
        
        EX) 원본 데이터 → Diffusion 모델 학습 → 랜덤 노이즈 입력 → 원본 데이터와 통계적 특성이 유사한 합성 데이터 생성
        
        </aside>
        
    - **7.데이터 생성 시 '시뮬레이션(Simulation)' 기법의 중요성을 안전성과 효율성 측면에서 설명하십시오.**
        
        <aside>
        💡
        
        1. 안정성
        
        : 시뮬레이션 기법은 현실 세계에서 데이터를 수집할 때 발생할 수 있는 사고나 물리적 손상의 위험을 방지하여 안정성을 확보할 수 있다.
        
        1. 효율성
        
        : 자율주행이나 로봇 공학처럼 비용이 많이 드는 실험을 가상 환경에서 반복적으로 수행할 수 있게 하여 데이터 수집의 효율성을 극대화할 수 있다.
        
        </aside>
        
    - **8. AI를 활용한 데이터 합성 기법 중 **'역지시(Reverse Instruction)'**가 작동하는 방식을 설명하십시오.**
        
        <aside>
        💡
        
        역지시(Reverse Instruction) 기법은 소설이나 위키피디아 아티클과 같이 이미 존재하는 고품질의 장문 콘텐츠를 가져와서, AI로 하여금 해당 내용을 결과값으로 도출할 수 있는 Instruction을 역으로 생성하는 방법이다.
        
        이 방법은 이미 검증된 고품질의 인간 작성 콘텐츠를 답변으로 사용하기 때문에, AI가 답변을 직접 생성할 때 발생할 수 있는 환각 오류를 피하면서 고품질의 학습 데이터를 확보할 수 있는 장점이 있다.
        
        ```markdown
        '정답: 고품질의 텍스트' → Instruction 생성 → (입력 프롬프트, 정답) instructive learning 데이터 쌍 생성 → 모델 학습
        ```
        
        </aside>
        
    - **9.Llama 3의 코딩 데이터 합성 파이프라인에서 '자율적 오류 수정' 과정이 어떻게 이루어지는지 설명하십시오.**
        
        <aside>
        💡
        
        - 임정
            - ??어디 문단에 있는걸까.. 책 p455
        - **모범답변**: 모델이 생성한 코드 솔루션이 유닛 테스트나 린터(Linter) 검증을 통과하지 못할 경우, **실패 메시지와 오류 내용을 다시 모델에게 프롬프트로 전달**합니다. 모델은 이 피드백을 바탕으로 코드를 스스로 수정하며, 이 과정을 **최종 검증을 통과할 때까지 반복**하여 고품질의 검증된 데이터만 데이터셋에 포함시킵니다.
        </aside>
        
    - **10.~~합성~~ 데이터 품질 검증을 위한 '기능적 정확성'과 'AI 심사위원(judge as LLM)' 방식의 차이를 비교 설명하십시오.**
        
        <aside>
        💡
        
        - 임정
            - 기능적 정확성: 코딩처럼 기능적으로 평가할 수 있는 문제에 적용
            - AI 검증기: 위 방식이 불가능하다면, 범용 AI 평가자나 특화된 채점기를 사용함. 1~5점으로 점수를 매기거나 좋음/나쁨 으로 평가하는 것. 혹은 실제/합성 데이터를 섞어서 어느것이 합성데이터인지 블라인드 테스트를 해볼 수 도 있음
        - **모범 답변:** **기능적 정확성**은 코드 실행 결과나 수학 정답처럼 객관적 지표로 성공 여부를 즉시 확인할 수 있는 작업에 사용됩니다. 반면, **AI 심사위원**은 정답이 고정되지 않은 개방형 응답의 논리성이나 유용성을 평가하기 위해 강력한 모델(예: GPT-4)을 활용하여 점수를 매기거나 분류하는 방식입니다.
        </aside>
        
    - **11.'모델 붕괴(Model Collapse)' 현상의 정의와 이를 방지하기 위한 핵심 방안을 제시하십시오.**
        
        <aside>
        💡
        
        - 임정
            - AI가 생성한 콘텐츠(자동수익화 블로그, 쇼츠자동화)를 기반으로 훈련된 생성형 AI 모델의 성능이 저하되는 현상. 2023년 Shumailov et all 에서 처음 명명. VAE, GMM, LLM 모델등에서 일어날 수 있음
            - 원인:  데이터 불균형을 가지고 있는 데이터셋으로 합성데이터를 만들면 희귀한 클래스가 점차 없어지는 것 과 동일
            - 해결방안: 실제 데이터와 섞기(명확한 답은 없음)
        - **모범 답변:** 모델 붕괴란 모델이 생성한 데이터로만 반복 학습할 경우, 확률이 낮은 **희귀한 패턴은 잊어버리고 보편적인 패턴만 과잉 학습하여 모델의 다양성과 성능이 점차 퇴화**하는 현상입니다. 이를 방지하기 위해서는 학습 데이터에 **AI가 만든 데이터뿐만 아니라 실제 인간이 생성한 데이터를 일정 비율로 섞어서** 학습시켜야 합니다.
        </aside>
        
    - **12.'모델 증류(Model Distillation)'의 개념과 이를 통해 얻을 수 있는 이점을 두 가지 측면에서 설명하십시오.**
        
        <aside>
        💡
        
         모델 증류는 작은 모델(학생)이 큰 모델(교사)의 행동을 모방하도록 훈련시키는 방법. 작은 모델은 처음부터 학습하거나 사전 학습된 모델을 미세 조정 하여 교사 모델이 생성한 데이터나 행동을 학습한다.
        
        이점
          1. 배포 효율성 및 비용 절감: 작은 모델은 메모리를 적게 차지하고 추론 속도가 빠르다
          2. 성능 유지 밎 최적화: 학생 모델이 교사 모델보다 훨씬 가볍지만 교사 모델의 언어 이해 능력을 상당 부분 유지할 수 있다. 그리고 단순 모방을 넘어 교사 모델보다 더 강력한 학생 모델을 만들 수도 있다.
        
        </aside>
        
    - **13.데이터 처리 과정에서 '수동 검사(Manual Inspection)'의 중요성을 가치적 측면에서 서술하십시오.**
        
        <aside>
        💡
        
        개발자가 데이터를 직접 확인하면서 자동화 도구의 한계를 보완하거나 데이터의 이해도를 높여서 나중에 발생할 수 있는 복잡한 문제를 예방할 수 있음.
        
        </aside>
        
    - **14.데이터 중복 제거(Deduplication)가 모델 성능 향상과 자원 효율성 측면에 미치는 영향을 설명하십시오.**
        
        <aside>
        💡
        
        1. 편향 방지 및 성능 저하 예방: 중복된 데이터는 데이터 분포를 왜곡시켜 편향을 강화함. 또한 중복된 데이터로 학습된 모델은 더 작은 중복되지 않은 데이터로 학습된 모델과 비슷한 성능을 보임.
        2. 자원 효율성: 중복된 데이터로 모델을 훈련시키는 것은 실질적 성능 향상은 없고 시간과 컴퓨팅 자원의 낭비임. 중복된 데이터 제거로 전체 데이터 양을 줄여서 처리 시간 단축 가능.
        </aside>
        
    - **15.데이터 정제 과정에서 '노이즈(Noise)'의 예시 3가지와 그것이 모델에 미치는 부정적 영향을 설명하십시오.**
        
        <aside>
        💡
        
        </aside>
        
    - **16. 파인튜닝 데이터 포맷팅(Formatting) 시 실제 추론 환경과의 일관성이 중요한 이유를 서술하십시오.**
        
        <aside>
        💡
        
        </aside>
        
    
    ### 📝 예시 답안
    
    **1. 데이터 중심(Data-centric) AI와 모델 중심(Model-centric) AI의 접근 방식을 비교 설명하세요.**
    
    - **답변:** 모델 중심 AI는 모델의 아키텍처, 크기, 또는 훈련 알고리즘을 개선하여 성능을 높이는 데 집중하는 방식입니다. 반면, **데이터 중심 AI는 모델을 고정한 채 데이터 자체의 품질을 개선(데이터 정제, 고품질 데이터셋 구축, 샘플 추가 등)하여 성능을 최적화**하는 데 주력합니다. 최근에는 모델이 범용화되면서 데이터가 성능의 핵심 차별화 요소로 부상하고 있습니다.
    
    **2. 파인튜닝을 위한 고품질 데이터가 갖추어야 할 6가지 주요 특성을 나열하고 각각 설명하세요.**
    
    - **답변:** 고품질 데이터는 다음 6가지를 만족해야 합니다. ① **관련성(Relevant)**: 학습 데이터가 타겟 작업과 직접적으로 연관되어야 합니다. ② **정렬(Aligned)**: 주석이 작업 요구사항(예: 사실 관계, 스타일)과 일치해야 합니다. ③ **일관성(Consistent)**: 여러 주석가나 샘플 간에 판단 기준이 동일해야 합니다. ④ **정확한 형식(Correctly formatted)**: 모델이 기대하는 토큰 및 채팅 템플릿 형식을 준수해야 합니다. ⑤ **고유성(Unique)**: 중복이 없어 특정 패턴에 편향되지 않아야 합니다. ⑥ **준수성(Compliant)**: 개인정보 보호법 등 법적/윤리적 정책을 지켜야 합니다.
    
    **3. 데이터 커버리지(Data Coverage) 확보를 위해 고려해야 할 다양성의 차원 3가지를 설명하세요.**
    
    - **답변:** 첫째, **작업 유형의 다양성**으로 요약, 질의응답, 번역 등 모델이 수행할 다양한 작업이 포함되어야 합니다. 둘째, **주제 다양성**으로 패션, 금융, 기술 등 사용자가 질문할 수 있는 광범위한 도메인을 다뤄야 합니다. 셋째, **형식의 다양성**으로 짧은 답변부터 긴 답변, JSON 출력 등 예상되는 모든 응답 스타일을 포함해야 모델의 견고함이 유지됩니다.
    
    **4. 데이터 수량 증가에 따른 '수확 체감(Diminishing returns)' 현상의 의미와 시사점을 설명하세요.**
    
    - **답변:** 수확 체감이란 데이터셋이 커질수록 동일한 양의 데이터를 추가했을 때 얻어지는 성능 향상 폭이 점차 줄어드는 현상을 의미합니다. 예를 들어, 초기 1,000개의 샘플은 큰 성능 향상을 가져오지만, 이미 100만 개가 있는 상태에서의 추가 1,000개는 미미한 영향만 줄 수 있습니다. 따라서 **데이터 확보 비용 대비 성능 이득을 분석하여 최적의 투입 시점을 결정**하는 것이 중요합니다.
    
    **5. AI 엔지니어링에서 '데이터 플라이휠(Data Flywheel)'이 작동하는 단계를 단계별로 설명하세요.**
    
    - **답변:** 1단계로 실제 서비스에서 **사용자가 생성한 데이터와 피드백을 수집**합니다. 2단계로 이 데이터를 정제하여 **모델을 다시 훈련(파인튜닝)**합니다. 3단계로 개선된 모델이 더 나은 서비스를 제공함으로써 **더 많은 사용자와 고품질 데이터를 유입**시킵니다. 이 순환 구조는 시간이 흐를수록 경쟁자가 따라잡기 힘든 강력한 경쟁 우위(데이터 해자)를 만들어냅니다.
    
    **6. 데이터 증강(Data Augmentation)과 데이터 합성(Data Synthesis)의 차이점을 정의와 예시를 들어 비교하세요.**
    
    - **답변:** **데이터 증강**은 기존의 실제 데이터를 변형하여 새 샘플을 만드는 기법으로, 문장에서 단어를 동의어로 교체하거나 이미지를 회전시키는 것이 예시입니다. 반면, **데이터 합성**은 실제 데이터 없이 규칙이나 AI 모델을 이용해 인위적으로 데이터를 생성하는 과정으로, 템플릿을 이용한 가짜 영수증 생성이나 LLM을 이용한 새 시나리오 작성이 포함됩니다.
    
    **7. 데이터 생성 시 '시뮬레이션(Simulation)' 기법의 중요성을 안전성과 효율성 측면에서 설명하세요.**
    
    - **답변:** 안전성 측면에서 자율주행이나 로보틱스처럼 **현실에서 수집하기 위험하거나 비용이 막대한 데이터(사고 상황 등)를 가상 환경에서 안전하게 대량 생성**할 수 있게 해줍니다. 효율성 측면에서는 인간이 생각하지 못한 최적의 행동 시퀀스를 AI가 스스로 탐색하고 학습 데이터로 활용하게 함으로써 학습 속도를 극대화할 수 있습니다.
    
    **8. AI를 활용한 데이터 합성 기법 중 '역지시(Reverse Instruction)'가 작동하는 방식을 설명하세요.**
    
    - **답변:** 역지시는 먼저 **고품질의 결과물(책, 기사, 위키피디아 등)을 확보**한 뒤, AI 모델에게 **"이 결과물을 출력하게 만들려면 어떤 질문(지시어)을 해야 하는가?"라고 물어 지시어를 생성**하게 하는 방식입니다. 이는 AI가 답변까지 생성할 때 발생할 수 있는 환각 현상을 방지하면서 고품질의 (지시어, 응답) 쌍을 확보할 수 있다는 장점이 있습니다.
    
    **9. Llama 3의 코딩 데이터 합성 파이프라인에서 '자율적 오류 수정' 과정이 어떻게 이루어지는지 설명하세요.**
    
    - **답변:** 모델이 생성한 코드 솔루션이 유닛 테스트나 린터(Linter) 검증을 통과하지 못할 경우, **실패 메시지와 오류 내용을 다시 모델에게 프롬프트로 전달**합니다. 모델은 이 피드백을 바탕으로 코드를 스스로 수정하며, 이 과정을 **최종 검증을 통과할 때까지 반복**하여 고품질의 검증된 데이터만 데이터셋에 포함시킵니다.
    
    **10. 합성 데이터 품질 검증을 위한 '기능적 정확성'과 'AI 심사위원' 방식의 차이를 비교 설명하세요.**
    
    - **답변:** **기능적 정확성**은 코드 실행 결과나 수학 정답처럼 객관적 지표로 성공 여부를 즉시 확인할 수 있는 작업에 사용됩니다. 반면, **AI 심사위원**은 정답이 고정되지 않은 개방형 응답의 논리성이나 유용성을 평가하기 위해 강력한 모델(예: GPT-4)을 활용하여 점수를 매기거나 분류하는 방식입니다.
    
    **11. '모델 붕괴(Model Collapse)' 현상의 정의와 이를 방지하기 위한 핵심 방안을 제시하세요.**
    
    - **답변:** 모델 붕괴란 모델이 생성한 데이터로만 반복 학습할 경우, 확률이 낮은 **희귀한 패턴은 잊어버리고 보편적인 패턴만 과잉 학습하여 모델의 다양성과 성능이 점차 퇴화**하는 현상입니다. 이를 방지하기 위해서는 학습 데이터에 **AI가 만든 데이터뿐만 아니라 실제 인간이 생성한 데이터를 일정 비율로 섞어서** 학습시켜야 합니다.
    
    **12. '모델 증류(Model Distillation)'의 개념과 이를 통해 얻을 수 있는 이점을 두 가지 측면에서 설명하세요.**
    
    - **답변:** 모델 증류는 거대 모델(Teacher)의 출력을 작은 모델(Student)이 학습하게 하여 지식을 전달하는 기법입니다. 이점으로는 첫째, **비용 및 지연 시간 감소**로 작고 빠른 모델을 통해 거대 모델에 근접한 성능을 내면서 운영 비용을 절감할 수 있습니다. 둘째, 성능 유지 측면에서 특정 작업에 특화된 고성능 소형 모델을 구축할 수 있습니다.
    
    **13. 데이터 처리 과정에서 '수동 검사(Manual Inspection)'의 중요성을 가치적 측면에서 서술하세요.**
    
    - **답변:** 수동 검사는 자동화 도구가 놓칠 수 있는 **미묘한 오류 패턴이나 데이터의 질감(Texture)을 파악**할 수 있게 해줍니다. 저자 칩 후옌은 이를 **"가치 대 명성 비율이 가장 높은 활동"**이라고 표현하며, 데이터 분포를 직접 확인하는 15분이 수 시간의 시행착오를 줄여주고 모델의 강점과 약점에 대한 깊은 직관을 제공한다고 강조합니다.
    
    **14. 데이터 중복 제거(Deduplication)가 모델 성능 향상과 자원 효율성 측면에 미치는 영향을 설명하세요.**
    
    - **답변:** 성능 측면에서는 중복 데이터로 인한 **특정 패턴 편향을 방지하고 테스트 셋 오염을 막아** 모델의 일반화 능력을 높여줍니다. 자원 효율성 측면에서는 불필요한 데이터를 학습하는 데 소모되는 **연산 자원(GPU 시간 등)과 저장 공간을 절약**하여 전체적인 훈련 비용을 낮춥니다.
    
    **15. 데이터 정제 과정에서 '노이즈(Noise)'의 예시 3가지와 그것이 모델에 미치는 부정적 영향을 설명하세요.**
    
    - **답변:** 노이즈의 예로는 스크레이핑 시 섞여 들어온 **HTML 태그, 중복된 문단, 개인정보(PII)** 등이 있습니다. 이러한 노이즈는 모델이 불필요한 토큰에 집중하게 만들어 **정확도를 떨어뜨리고**, 입력 토큰 길이를 늘려 **비용을 상승**시키며, 안전 정책을 위반하는 모델을 만들 위험이 있습니다.
    
    **16. 파인튜닝 데이터 포맷팅(Formatting) 시 실제 추론 환경과의 일관성이 중요한 이유를 서술하세요.**
    
    - **답변:** 모델은 학습 시 경험한 데이터의 구조(공백, 특수 기호, 화살표 등)를 매우 정밀하게 학습하기 때문입니다. 학습 데이터의 포맷이 실제 추론 시 사용하는 프롬프트 템플릿과 단 하나라도 다를 경우(예: 추가 공백 등), **모델이 학습한 대로 작동하지 않고 성능이 급격히 저하되는 버그**가 발생할 수 있습니다.
    
